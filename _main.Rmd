--- 
title: "Online Companion to *Archaeological Network Science* by Brughmans and Peeples"
author: "Matthew A. Peeples and Tom Brughmans"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: references.bib
url: https://book.archnetworks.net
description: |
  This bookdown document accompanies the Cambridge Manuals in Archaeology book
  *Archaeological Network Science* by Tom Brughmans and Matthew A. Peeples.
link-citations: yes
---

# Welcome

**Note that this is a pre-release version of this document. Be aware that there are formatting issues and there may be lingering errors currently under investigation. Please check back here for updates in the coming months for the full "release" version of this document.**

**Cite this document as:**

* Peeples, Matthew A. and Tom Brughmans (2022). Online Companion to Archaeological Network Science by Brughmans and Peeples. https://archnetworks.net

For more information on the book and for other resrouces including downloadable archaeological network data, code, and tutorials see [archnetworks.net](https://archnetworks.net). 

***

This document serves as a companion to the Cambridge Manuals in Archaeology book *Archaeological Network Science* by Tom Brughmans and Matthew A. Peeples (2022). This document outlines methods for managing and analyzing network data, primarily using the R programming language. In the following sections we provide code and examples to replicate the analyses, techniques, and visualizations presented in the book as well as many other additional useful code snippets, hints, and information. This appendix has been written to expand upon specific topics covered in the book and you may find it useful to follow along with these examples as you read. Sections 2 through 7 in this document correspond to the topics and information covered in Chapters 2 through 7 of the book. You can use the table of contents on the left-hand side of your screen to jump directly to a particular topic. 

![Totally Real Cover image of *Archaeological Network Science*](images/Cover.jpg){width=40%}

This appendix assumes you have a basic familiarity with R and R studio. If you are a first time R user and need help getting R and R studio installed and up and running, we suggest you follow the basic [RYouWithMe!](https://rladiessydney.org/courses/ryouwithme/) tutorials by the R-Ladies Sydney or the [ModernDive](https://moderndive.netlify.app/1-getting-started.html) Statistical Inference via Data Science basic tutorial (McConville et al. 2021). If you already have a basic familiarity with R and want to go further, there are numerous additional resources online (many are completely free) to help you learn. Some resources we would recommend include *R for Data Science* ([Wickham and Grolemund 2017](https://r4ds.had.co.nz/)), *Advanced R* ([Wickham 2019](https://adv-r.hadley.nz/)), *the R Cookbook, 2nd edition* [(Long and Teetor 2019)](https://rc2e.com/)), and *R in Action* and the associated *Quick-R* website  [Kabacoff 2015](https://www.statmethods.net/). In addition to this [Ben Marwick](https://anthropology.washington.edu/people/ben-marwick) has created an excellent repository of [resources for using R in archaeology](https://github.com/benmarwick/ctv-archaeology) as well as an ever-growing list of archaeological publications that include R code. Reproducing published results is, in our experience, one of the best ways to learn advanced analytical techniques and data management in R. 


<!--chapter:end:index.Rmd-->

# Getting Started

This section provides downloadable files for the network datasets used in this online companion and in the book as well as information on the primary R packages used for analysis and visualization throughout this tutorial. We also provide very brief instructions for importing these data into R using R-studio and some guidance on setting up your R-studio working environment. For additional guidance see the resources provided in the introduction. 

## Datasets

In the analyses illustrated in this online appendix we use a number of real and simulated archaeological datasets to serve as examples for particular data types and techniques. Most of the datasets used here are provided in .csv (comma separated value) or .RData formats and can be downloaded so that you can follow along with these analyses on your own computer. We encourage you to explore these files and see how they are formatted as a guide for setting up your own datasets.

The data used here include a range of different network data formats and types. The primary datasets are described in detail in Brughmans and Peeples (2022) Chapter 2.8. Note that where spatial locations for archaeological sites are provided the locations have been randomly jittered up to 10 kilometers from their actual locations to maintain data security.

For the files below you can right click and "save as" to save them for use locally. Note that there are many additional datasets relating to the replication of particular figures in the book that are provided where the code for that particular figure occurs. If you'd like to just download everything at once [see the next section](#Everything)

### Just Give Me Everything {#Everything}

Hey, we get it. You're busy and just want all of the data in one convenient package. We provide all of the data used in the appendix here in a single .zip file for you to download. To follow along with the examples in this appendix you need to choose an R working directory and place the contents of the *.zip folder within it such that all of the individual files are contained within a folder called "data". Note that this includes all of the additional files that are required for reproducing particular figures as well.

[All_data.zip](All_data.zip) - A single compressed file containing all of the data files used in this appendix.

### Roman Road Networks 

The development of an elaborate road system is one of the most enduring legacies of the Roman Republic and Empire. Areas that came under Roman control were connected to Rome and important provincial centers through entirely new roads as well as redeveloped existing roads. From roughly the second century AD onward this resulted in an integrated terrestrial transport network connecting North-Africa, the Middle East, and western and southern Europe. Much of the subsequent development of transport systems in these regions built on this Roman system. 

Our primary source for roads of the entire Roman world is the Barrington Atlas of the Greek and Roman World (Talbert 2000) and their digitization by the Ancient World Mapping Center (2012). In many of our examples we will focus in particular on the roads of the Iberian Peninsula, which have been digitized in great detail by Pau de Soto (de Soto and Carreras 2021). In our analyses of the Roman road network ancient settlements are represented as nodes and the existence of a road between two settlements is represented by an edge. We also include the length of a road as an edge attribute.

* [Hispania_nodes](data/Hispania_nodes.csv) - NodeIDs and names for Roman era settlements in the Iberian Peninsula along with names and latitude and longitude locations in decimal degrees.
* [Hispania_roads](data/Hispania_roads.csv) - Edge list of road connections using NodeIDs from Hispania_nodes file. This file contains a "weight" variable defined for each edge which denotes the length of the road segment.

### Southwest Social Networks Project Ceramic Similarity Networks  

The Southwest Social Networks (SWSN) Project (and subsequent [cyberSW](https://cybersw.org) project) is a large collaborative effort focused on exploring methods and models for network analysis of archaeological data to better understand patterns of interaction, population movement, and demographic change across the U.S. Southwest and Mexican Northwest through time (ca. A.D. 800-1800; Borck et al. 2015; Giomi et al. 2021; Mills et al. 2013a; 2013b; 2015; 2018; Peeples and Haas 2013; Peeples et al. 2016; Peeples and Roberts 2013). During the interval considered by this project the region was inhabited largely by sedentary agricultural populations (though more mobile populations were also present throughout this period) with communities as large as several thousand people at the peak. The region is blessed with excellent archaeological preservation, a fine grained chronology anchored by dendrochronological dates, and nearly 150 years of focused archaeological research. 

The SWSN/cyberSW project team has gathered a massive database with information on the location and size of tens of thousands of archaeological sites and ceramic and other material cultural typological frequency data consisting of millions of objects to explore how patterns of material similarity, exchange, and technology change across time and space in the study area. These data as well as tools needed to analyze them are available in an online platform called [cyberSW (cyberSW.org)](https://cybersw.org). This online platform even allows you to explore these data directly in your internet browser. The size and complexity of the SWSN/cyberSW data make it a particularly good example for discussing the decision processes involved in visualizing and analyzing large networks. 

In several sections of this book we also use subsets of this larger dataset; the San Pedro Valley, and the Chaco World. The San Pedro Valley in southern Arizona is a well-studied portion of the SWSN study area (see Clark and Lyons 2012; Gerald 2019) that was an early focus of network methodological exploration by the team (Mills et al. 2013b). This data subset includes detailed ceramic typological frequency for all known major settlements across this region during the late pre-Hispanic period (ca. A.D. 1200-1450). The Chaco World is a large-scale social and political system that spanned much of the Colorado Plateau ca. A.D. 800-1150. This settlement system was marked by the construction of massive public architectural features known as great houses and great kivas. This subset of the database includes information on architecture and ceramic typological data for a large portion of the known Chacoan architectural complexes throughout the U.S. Southwest. The Chaco World has been a major focus of the SWSN/cyberSW project (Giomi et al. 2021; Giomi and Peeples 2019; Mills et al. 2018). 

In these networks, individual settlements are treated as nodes and edges are defined and weighted based on similarities in the ceramic wares recovered at those settlements. Ceramic data used to generate networks are apportioned into a sequence of 50-year chronological intervals using methods described in detail by Roberts and colleagues (2012) and Ortman (2016; see discussion in Mills et al. 2018) so that we are able to explore change through time. Site locations and other site attribute data are also considered in some examples. R implementations of these chronological apportioning methods are available on GitHub as well ([R implementation of Roberts et al. 2012](https://github.com/mpeeples2008/CeramicApportioning), [R implementation of Ortman 2016](https://github.com/mpeeples2008/UniformProbabilityDensityAnalysis)).

* [SWSN Attribute Data AD 1300-1350](data/AD1300attr.csv) - Attribute data for SWSN sites dating between AD 1300 and 1350 including site name, site sub-region (Macro), and jittered easting and northing UTM coordinates. 
* [SWSN Similarity Data AD 1300-1350](data/AD1300sim.csv) - Symmetric similarity matrix based on Brainerd-Robinson similarities for all SWSN sites dating between AD 1300 and 1350.
* [The Chaco World Attribute Data AD 1050-1100](data/AD1050attr.csv) - Attribute data for sites with Chacoan architectural features dating between AD 1050 and 1100 including site IDs, site names, site sub-regions, counts of different kinds of public architectural features, and jittered easting and northing site locations. 
* [The Chaco World Ceramic Data AD 1050-1100](data/AD1050cer.csv) - Ceramic count data by ware for sites with Chacoan architectural features dating between AD 1050 and 1100.
* [The Chaco World Network AD 1050-1100](data/AD1050net.csv) - Adjacency matrix of binarized network of ceramic similarity for sites with Chacoan architectural features dating between AD 1050 and 1100.
* [San Pedro Networks throgh Time](data/Figure6_20.Rdata) - An .RData file that contains igraph network objects for the San Pedro region ceramic similarity networks for AD1250-1300, AD1300-1350, and AD1350-1400.

### Cibola Region Technological Similarity Network  

The Cibola region along the Arizona and New Mexico border in the U.S. Southwest is a large and diverse physiographic region spanning the southern edge of the Colorado Plateau and the ancestral homeland of the contemporary Zuni (A:shiwi) people. Peeples and colleagues (Peeples 2011, 2018; Peeples et al. 2021) have explored patterns of technological similarity and communities of practice in this region at a series of sites dating ca. A.D. 1100-1350 through explorations of corrugated ceramic cooking pots. Corrugated pots, which are produced across much of the U.S. Southwest from at least the 9th through the 14th centuries, are coiled ceramic vessels where the coils used to make the vessel are never fully smoothed. Thus, these ceramics retain substantial amounts of evidence of the specific techniques used to produce them.

In the book we use data on ceramic technological production techniques to generate similarity networks originally published by Peeples (2011; 2018). In these networks each settlement is treated as a node with similarity metrics defining the weights of edges between pairs of sites based on an analysis of a number of metric and coded attributes of individual ceramic vessels. In addition to these material cultural data, we also have additional site attributes such as location and the types and frequency of public architectural features.

Ceramic technological data from Peeples (2018): Additional data and documentation from this project is available on tDAR [in this collection](https://core.tdar.org/project/427899/connected-communities-networks-identity-and-social-change-in-the-ancient-cibola-world). Nodes are defined as individual settlements with edges defined based on similarities in the technological attributes of cooking pots recovered at those settlements. For more details on the methods and assumptions used to define these networks see Peeples (2018, pg. 100-104). 

* [Cibola Ceramic Technological Clusters](data/Cibola_clust.csv) - Counts of ceramic technological clusters for sites in the Cibola region sample.
* [Cibola Site Attributes](data/Cibola_attr.csv) - Site location, public architectural feature types, and sub-region designations for sites in the Cibola region sample.
* [Cibola Binary Network Edge List](data/Cibola_edgelist.csv) - Binary edge list of Cibola technological similarity network.
* [Cibola Binary Network Adjacency Matrix](data/Cibola_adj.csv) - Binary adjacency matrix of Cibola technological similarity network.
* [Peeples2018.Rdata](data/Peeples2018.Rdata) - This file contains a number of objects in R format including the site attributes (site_info), a symmetric Brainerd-Robinson similarity matrix (ceramicBR), a binary network object in the statnet/network format (BRnet), and a weighted network object in the statnet/network format (BRnet_w) 

### Himalayan Visibility Networks 

Hundreds of forts and small fortified structures are located on mountain tops and ridges in the central Himalayan region of Garhwal in Uttarakhand (India). Despite being such a prominent feature of the history of the region that is interwoven with local folklore (Garhwal is derived from 'land of forts'), this fortification phenomenon has received very little research attention. It might have had its origins during the downfall of the Katyuri dynasty in the 11th century and continued up to the 15th century when the region was consolidated by the Parmar dynasty and possibly even later as attested by Mughal, Tibetan, and British aggressions.

In the book we use this research context as an example of spatial networks and more specifically visibility networks.This is made possible thanks to the survey of forts in the region performed in the context of the PhD project by Dr Nagendra Singh Rawat (2017). We use a catalog of 193 sites (Rawat et al. 2020, Appendix S1), and use the case of Chaundkot fort and its surroundings as a particular case study. Chaundkot fort is theorized to have been one of the key strongholds in the region and is also the only one to have been partly excavated (Rawat and Nautiyal 2020). In these case studies we represent strongholds as nodes, and the ability for a line-of-sight to exist between observers located at a pair of strongholds is represented by a directed edge. The length of each line-of-sight is represented by an edge attribute.

* [Himalayan Node data](data/Himalaya_nodes.csv) - Node attribute data for the Himalayan sites including locations in lat/long, elevation, site name/type, and descriptions of landscape features.
* [Himalayan Edge List](data/Himalaya_visiblity.csv) - Edge list data with information on connections among nodes within 25kms of each other with information on the distance and whether or not the target site is visible from the source. Note that only edges with "Visible = TRUE" should be included as activated edges.

### Archaeological Publication Networks 

Our knowledge and stories of past human behavior are as much shaped by the material remains we excavate, as they are by the actions and interactions of the archaeologists that study them. Aspects of these actions and interactions are formally represented in publications. Such papers can be co-authored, reflecting scientific collaboration networks and communities of practice. Authors cite other authors’ works to indicate explicitly that they were influenced by it or that it is related to the paper’s subject matter.

In previous work, we have turned the tools of archaeological network science on archaeological network researchers themselves (Brughmans 2013; Brughmans and Peeples 2017). We studied the co-authorship and citation practices of the more than 250 publications that have applied formal network methods to archaeological research topics from 1968 to the present. From a list of publications, an undirected co-authorship network can be made by representing individual authors as nodes, and connecting a pair of authors with an edge if they have been co-authors on one or more papers, with edge values representing the number of papers they co-authored. Moreover, a directed citation network can be made from the bibliographies of this list of publications. In a citation network, each node represents an individual publication which is connected to all other publications in its bibliography with a directed edge. The edge goes from the citing publication to the cited publication, so it represents the source and direction of academic influence as explicitly expressed in publication. We use networks of archaeological network research publications throughout this volume to illustrate concepts like the acyclic structure of citation networks.

* [Publication Networks Attribute Data](data/biblio_attr.csv) - Attribute data table including information on publications including a unique key identifier, publication type, publication title, publication date, and the author list separated by semi-colons.
* [Publication Networks Co-Authorship Incidence Matrix](data/biblio_dat.csv) - An incidence matrix with unique publications as rows and authors as columns.

### Iron Age Sites in Southern Spain

The Guadalquivir river valley in the south of Spain between present-day Seville and Córdoba was densely urbanized in the late Iron Age (early 5th c. BC to late 3rd c. BC). Many settlements were dotted along the rivers and the southern part of the valley (Fig. 2.6), and this settlement pattern was focused on nuclear settlements sometimes referred to as oppida. Some of these reveal defensive architecture and many are located on elevations. Previous studies of Iron Age settlements in the region have explored possible explanations for their locations (Keay and Earl 2011; Brughmans et al. 2014, 2015). Given their elevated locations, one theory that has received considerable attention was intervisibility. Could small settlements surrounding oppida be seen from them, and could oppida be located partly to allow for visual control over surrounding settlements? Did groups of Iron Age settlements tend to be intervisible, forming communities that were visible on a daily basis? Were there chains of intervisibility that allowed for passing on information from one site to another via visual smoke or fire signals, and did these chains follow the other key communication medium in the area: the navigable rivers? 

These questions have been explored in previous research using GIS and network methods, using a dataset of 86 sites and lines-of-sight connecting pairs of Iron Age settlements at distances up to 20km at which large fire and smoke signals would be visible (more about this dataset and research topic: Keay and Earl 2011; Brughmans et al. 2014, 2015). To account for errors in the Digital Elevation Model (DEM), a probabilistic line-of-sight analysis was performed that introduces random errors into the DEM which can have a blocking or enhancing effect on the lines-of-sight. The locations of these 86 sites and the network displayed in figure 2.9 are also available as Appendix A in Brughmans et al. 2014. These locations are used in Chapter 7 of the book to illustrate spatial network models that explore different geographical structures that might underlie the settlement pattern.

* [Guadalquivir settlement data](data/Guadalquivir.csv) - Site number and locations in decimal degrees for all sites in the Guadalquivir survey area.

## Importing Data in R

This section briefly describes how the data provided above (or your own data) can be imported in to R for further analyses. Before running the code below, however, you need to ensure that your R session is set to the correct working directory (the location where you placed the .csv files you just downloaded). To do that, go to the menu bar at the top and click Session > Set Working Directory > Choose Directory and navigate to the place on your hard drive where these files reside (alternatively you can hit Ctrl + Shift + H and then navigate to the appropriate directory). 

For this example we will read in the Cibola_edgelist.csv file and define an object called "EL1" which includes the data in that file using the read.csv() command. Note that in this case the file we want to read is in a sub-folder of our working directory called "data" so we need to use the "data/" prefix before the file name to correctly call that file. If you do not chose to use a sub-folder or if you call your folder something else, you will need to modify the "data/" section of the code.

```{r}
# read in data with first row representing column names (header=TRUE)
EL1 <- read.csv(file="data/Cibola_edgelist.csv", header=TRUE)
# look at the first few rows
head(EL1)
```

In addition to the .csv files, several examples in this book and several of the datasets above are provide as .RData files which can be read directly in R and can contain multiple R objects. These can be read directly into the R environment using the "load()" function. See the example below. Again note that you must specify the specific directory within the working directory where the file is located.

```{r, eval=F}
load("data/map.RData")
```

## Installing R Packages

In this appendix we rely on a number of pre-existing R packages. In order to use these packages in a new installation of R and R-studio, you first need to install them. Note that you will only need to do this once on a new installation of R. To install packages, you can click on the "Packages" tab in the window in the bottom right of R studio, then click the "Install" button at the top and type the names of the packages separated by commas. Alternatively you can install packages from the console by simply typing "install.packages("nameofpackagehere")" without the outer quotation marks. 

install.packages(c("statnet","tnet"))

We use a number of R packages in the modules here and in the book for manipulating and analyzing network data and for other general analyses and procedures. The most frequently used network packages include:

* [igraph (Csardi and Nepusz 2006)](https://igraph.org/) - analytical routines for simple graphs and graph analysis
* [statnet (Krivitsky et al. 2020)](http://statnet.org/) - A suite of packages designed for the management and statistical analysis of networks
* [intergraph (Bojanowski 2015)](https://cran.r-project.org/web/packages/intergraph/intergraph.pdf) - a set of routines for coercing objects between common network formats in R
* [ggraph (Pederson 2021)](https://CRAN.R-project.org/package=ggraph) - a powerful graph visualization package that is based off of the ggplot2 plotting format

In order to install all of the packages that will be used in this appendix, you can run the following chunk of code. Specific packages will be initialized along with the specific sections where they are required. Note that the code below will not reinstall packages already installed in your current version of R.

```{r, message=F, warning=F, eval=F}
packages <- c("igraph", "statnet", "intergraph", "tnet", "ggplot2",
              "deldir","rjson","d3r","cccd","RBGL","graph","BiocGenerics",
              "networkD3","visNetwork","GISTools","rgeos","maptools","sp",
              "ndtv","gridExtra","png","scales","ape","graphlayouts","igraphdata",
              "ggrepel","ggsn","tidyverse","edgebundle","superheat",
              "ggplotify","ggforce","colorspace","ggmap","sf","dplyr","ggpubr",
              "ggraph","ggplot2","reshape2","multinet","RColorBrewer","Rcpp",
              "vegan","intergraph","networkDynamic","scatterplot3d")

install.packages(setdiff(packages, rownames(installed.packages())))  
devtools::install_github("liamgilbey/ggwaffle")

```

Here is a list of all package versions used in the creation of this document:

```{r, eval=F}
        deldir          rjson            d3r           cccd           RBGL          graph   BiocGenerics      networkD3 
       "0.2-3"       "0.2.20"        "0.9.1"          "1.5"       "1.64.0"       "1.66.0"       "0.34.0"          "0.4" 
    visNetwork       GISTools          rgeos           MASS       maptools             sp           ndtv      animation 
       "2.0.9"        "0.7-4"        "0.5-5"       "7.3-54"        "1.0-2"        "1.4-5"       "0.13.0"          "2.6" 
     gridExtra            png         scales            ape   graphlayouts     igraphdata        ggrepel           ggsn 
         "2.3"        "0.1-7"        "1.1.1"        "5.4-1"        "0.7.1"        "1.0.1"        "0.9.1"        "0.5.0" 
       forcats        stringr          purrr          readr          tidyr         tibble      tidyverse       ggwaffle 
       "0.5.1"        "1.4.0"        "0.3.4"        "1.4.0"        "1.1.3"        "3.1.0"        "1.3.1"        "0.2.2" 
    edgebundle      superheat      ggplotify        ggforce     colorspace          ggmap             sf          dplyr
  "0.1.0.9000"        "1.0.0"        "0.0.7"        "0.3.2"        "2.0-2"        "3.0.0"        "1.0-0"        "1.0.5" 
        ggpubr           tnet       survival         ggraph        ggplot2       reshape2       multinet   RColorBrewer 
       "0.4.0"       "3.0.16"        "3.2-7"        "2.0.5"        "3.3.5"        "1.4.4"          "4.0"        "1.1-2" 
          Rcpp          vegan        lattice        permute     intergraph        statnet           tsna            sna 
       "1.0.7"        "2.5-7"      "0.20-41"        "0.9-5"        "2.0-2"       "2019.6"        "0.3.3"          "2.6" 
statnet.common     ergm.count          tergm networkDynamic           ergm        network         igraph 
       "4.5.0"        "4.0.2"        "4.0.1"       "0.11.0"        "4.0.1"       "1.17.1"        "1.2.6" 

```

## Suggested Workspace Setup

In order to follow along with the examples in the appendix it will be easiest if you set up your R working directory in a similar format to that used in creating it. Specifically, we suggest you create a new working directory and create an R studio project tied to that specific directory. Further, we suggest that you create a sub-folder of that working directory called "data" and place all of the files you downloaded above or from any other place in this appendix in that folder. Note that if you chose the "Just Give Me Everything" download you will have a .zip file that already contains a sub-folder called "data" so be sure you're not double nesting your folders (you want "working_directory/data" not "working_directory/data/data").

This document was created in R version 4.04 "Lost Library Book" and we suggest you run a current installation of R and R-studio. 

<!--chapter:end:01-data.Rmd-->

# Network Data {#NetworkData}

This section provides examples of many of the most common network formats and data types discussed in Chapter 3 of Brughmans and Peeples 2022. For most of the examples below we use the Cibola technological similarity network dataset (described in Chapter 2.8.3) because it is relatively small and easy to display in a variety of formats.

## Network Data Formats

This section follows Chapter 3.2 in Brughmans and Peeples (2022) to provide examples of the same network and attribute data in a variety of different data formats as well as code for converting among these formats in R. In these examples we will primarily be using the "igraph" package but will also provide examples using the "statnet" suite of packages (which includes "network," "sna," "ergm," and others). In order to be clear on which package we are using where we will use the package name in the function call (i.e., igraph::function_name or sna::function_name). See section 3.2 for more information.

Let's first get started by initializing all of the packages we will use in this section.

```{r, warning=F, message=F}
# initialize packages
library(igraph)
library(statnet)
library(intergraph)
library(vegan)
library(multinet)
```


### Edge List {#Edgelist}

The edge list is a very quick and easy way to capture network data. It simply lists the edges in the network one by one by node id: E=((n1,n2),(n1,n3),(n1,n4),...,(ni,nj)). For the purposes of data management it is usually easiest to create an edge list as a data frame or matrix where each row represents a pair of nodes with connections going from the node in one column to the node in the second column (additional columns can be used for edge weight or other edge attributes).

In this example, we import the Cibola dataset in this format as a data frame and then convert it to a network object for further analysis. You can download the [edgelist file here](data/Cibola_edgelist.csv) to follow along on your own. Since the edges in this network are undirected this will be a simple binary network, and we will use the "directed=FALSE" argument in the igraph::graph_from_edgelist function call.

```{r, warning=F, message=F}
# Read in edgelist file as dataframe
Cibola_edgelist <- read.csv(file="data/Cibola_edgelist.csv", header=TRUE) 

# Examine the first several rows
head(Cibola_edgelist) 

# Create graph object. The dataframe is converted to a matrix as that is required 
# by this specific function. Since this is an undirected network directed = FALSE.
Cibola_net <- igraph::graph_from_edgelist(as.matrix(Cibola_edgelist), directed=FALSE)

# Display igraph network object and then plot a simple node-link diagram
Cibola_net
set.seed(3523) # set random seed to ensure graph layout stays the same each time.
plot(Cibola_net)
```

### Adjacency List

The adjacency list consists of a set of rows, where the first node in each row is connected to all subsequent nodes in that same row. It is therefore more concise than the edge list (in which each relationship has its own row), but unlike the edge list it does not result in rows of equal length (each row in an edge list typically has two values, representing the pair of nodes). Adjacency lists are relatively rare in practice but can sometimes be useful formats for directly gathering network data in small networks and are supported by many network analysis software packages. 

In the following chunk of code, we convert the network object we created above into an adjacency list and examine a couple of the rows.

```{r, warning=F, message=F}
# Convert edge list to adjacency list using igraph function
adj_list <- igraph::as_adj_edge_list(Cibola_net)

# examine adjacency list for the site Apache Creek
adj_list$`Apache Creek`

# It is also possible to call specific nodes by number. In this case,
# site 2 is Casa Malpais
adj_list[[2]] 

```

The output for a particular node can be called by either referencing the name using the "$" call or by using 
"[[k]]" brackets where k is the row number of the node in question. The printed output is essentially a list of all of the edges incident on the node in question identified by the name of the sending and receiving node. Notice that the edge from Apache Creek--Casa Malpais shows up in both adjacency lists. That is because this is an undirected network so each pair of connected sites will be listed in each adjacency list.

### Adjacency Matrix

The adjacency matrix is perhaps the most common and versatile network data format for data analysis in network science (in sociology it is sometimes referred to as the sociomatrix). It is a symmetric matrix of size n x n, with a set of rows and columns denoting the nodes in that network. The node names or identifiers are typically used to label both rows and columns. When a pair of nodes is connected by an edge (i.e. when they are adjacent), the corresponding cell will have an entry. The diagonal of this matrix represents "self loops" and can variously be defined as connected or unconnected depending on the application. 

We can obtain an adjacency matrix object in R by converting our network object created above or by reading in a file directly with rows and columns denoting site and with 0 or 1 denoting the presence or absence of a relation. You can download the csv file to follow along on your own [here](data/Cibola_adj.csv).

```{r, warning=F, message=F}
# Convert to adjacency matrix then display
adj_mat <- igraph::as_adjacency_matrix(Cibola_net)
adj_mat

# Read in adjacency matrix and convert to network object for plotting
adj_mat2 <- read.csv(file="data/Cibola_adj.csv", header=T, row.names=1)
Cibola_net2 <- igraph::graph_from_adjacency_matrix(as.matrix(adj_mat2), mode="undirected")
set.seed(4352)
plot(Cibola_net2)
```

Note when you compare this network graph to the one produced based on the edge list there is an additional unconnected node (WS Ranch) that was not shown in the previous network. This is one of the advantages of an adjacency matrix is it provides a way of easily including unconnected nodes without having to manually add them or include self-loops.
 
### Incidence Matrix

An incidence matrix is most frequently used to define connections among different sets of nodes in a two-mode or bipartite network where the rows and columns represent two different classes of nodes and the presence/absence or value of an edge is indicated in the corresponding cell.

By way of example here we can read in the data that were used to generate the one-mode networks of ceramic technological similarity we have been examining so far. In the corresponding data frame, each row represents a site and each column represents a specific cluster of technological attributes in cooking pottery (see Peeples 2018, pg. 100-104 for more details) with the number in each cell representing the count of each technological cluster at each site.

After creating the network object we plot it as a simple two-mode network with color representing node class. We discuss plotting options in greater detail in the visualization section of this appendix.

```{r, warning=F, message=F}
# Read in two-way table of sites and ceramic technological clusters
Cibola_clust <- read.csv(file="data/Cibola_clust.csv", header=TRUE, row.names=1)
Cibola_clust
# Convert into a network object using the incidence matrix format. Note that 
# multiple=TRUE as we want this defined as a bipartite network.
Cibola_inc <- igraph::graph_from_incidence_matrix(Cibola_clust, directed=FALSE, multiple=TRUE)
Cibola_inc
set.seed(4543)
# Plot as two-mode network
plot(Cibola_inc, vertex.color = as.numeric(V(Cibola_inc)$type)+1)
```

### Node and Edge Information

Frequently we want to use other information about nodes and edges (node location, site type, edge weight, etc.) in our analyses and need to track these data in a separate attribute object or data column. One common way to do this is to simply create a data frame that contains the required attribute information and call specific data from this data frame when needed. As the following example shows, it is also possible to directly assign attributes to nodes or edges in a graph object and use those for subsequent analyses using the "V()" for vertices (nodes) and "E()" for edges calls within igraph.

In the following example we use [this file](data/Cibola_attr.csv) which includes basic attribute data by site (node) for all sites in the network we've been working with here. This file includes x and y coordinates for the sites, information on the presence/absence and shape of Great Kiva public architectural features at those sites, and the Region to which they have been assigned. 

```{r, warning=F, message=F}
# Read in attribute data and look at the first few rows.
Cibola_attr <- read.csv(file="data/Cibola_attr.csv", header=T)
head(Cibola_attr)

```

In order to assign an attribute to a particular node or edge we can use the V and E (vertex and edge) calls in igraph. For example, in the following example, we will assign a region variable to each node in the network we created above using the V function to assign a vertex attribute. You simply type the name of the network object in the parenthesis after V and use the "$" atomic variable symbol to assign a name to the attribute that will be associated with that network object.

```{r, warning=F, message=F}
# Assign a variable called "region" to the Cibola_net2 based on the
# column in the Cibola_attr table called "Region"
V(Cibola_net2)$region <- Cibola_attr$Region

# If we now call that attribute we get a vector listing each assigned value
V(Cibola_net2)$region
# This can further be used for plotting or other analyses by calling the variable as a factor
set.seed(43534)
plot(Cibola_net2, vertex.color=as.factor(V(Cibola_net2)$region))
```

## Types of Networks

This section roughly follows Brughmans and Peeples (2022) Chapter 3.3 to describe and provide examples in R format of many of the most common types of networks. In the examples below we will use the igraph R package but we also show how to use the statnet and network packages where applicable.

### Simple Networks 

Simple networks are unweighted and undirected one-mode networks. By way of example we will use the Cibola region [adjacency matrix file](data/Cibola_adj.csv) and convert it into a simple network using both igraph and statnet/network. Notice how in both examples we specify that this is an undirected network (mode="undirected" and directed=FALSE). 

```{r, warning=F, message=F}
# Read in raw adjacency matrix file
adj_mat2 <- read.csv(file="data/Cibola_adj.csv", header=T, row.names=1)

# Convert to a network object using igraph
simple_net_i <- igraph::graph_from_adjacency_matrix(as.matrix(adj_mat2), mode="undirected")
simple_net_i

# Covert to a network object using statnet/network
simple_net_s <- network::network(as.matrix(adj_mat2), directed=FALSE)
simple_net_s
```

Notice how the two formats differ in the way they internally store network data in R and the way they print output to the screen but that both show a total of 31 nodes (vertices) and 167 edges (for the igraph object the first row specifies node and edge numbers between the -- marks).

### Directed Networks

Sometimes relationships are directional, meaning they have an orientation. For example, the flow of a river is directed downstream. In such cases we can incorporate this information in our network data by distinguishing between the source and the target of an edge. 

By way of example here we will modify the Cibola network edge list to remove some number of edges at random to simulate directed network data. We will then convert these data into various network and matrix formats to illustrate how directed networks are stored and used in R.

```{r, message=F, warning=F}
# Read in edgelist file as dataframe
Cibola_edgelist <- read.csv(file="data/Cibola_edgelist.csv", header=TRUE) 

# Create a random sub-sample of 125 edges out of the total 167 using the "sample" function
set.seed(45325)
EL2 <- Cibola_edgelist[sample(seq(1,nrow(Cibola_edgelist)), 125, replace=FALSE),]

# Create graph object from the edge list using the directed=TRUE argument
# to ensure this is treated as a directed network object.
directed_net <- igraph::graph_from_edgelist(as.matrix(EL2), directed=TRUE)
directed_net

# View as adjacency matrix of direted network object
as_adjacency_matrix(directed_net)

# Plot network
set.seed(4353)
plot(directed_net)
```

Notice that when we look at the igraph network plot it has arrows indicating the direction of connection in the edge list. If you are making your own directed edge list, the sending node by default will be in the left column and the receiving node in the right column. In the adjacency matrix the upper and lower triangles are no longer identical. Again, if you are generating your own adjacency matrix, you can simply mark edges sent from nodes denoted as rows and edges received from the same nodes as columns. Finally, in the plot, since R recognizes this as a directed igraph object when we plot the network, it automatically shows arrows indicating the direction of the edge.

### Signed, Categorized, and Valued Networks

In many situations we want to add values to specific edges such as signs (sometimes called valences) or weights defining the strength or nature of relationships. There are a variety of ways that we can record and assign such weights or values to edges in R. The simplest way is to directly include that information in one of the formats described above such as an edge list or adjacency matrix. For example, we can add a third column to an edge list that denotes the weight or sign of each edge or can fill the cells in an adjacency matrix with specific values rather than simply 1s or 0s.

In this example, we will random generate edge weights for the Cibola network edge list and adjacency matrix to illustrate how R handles these formats.

```{r, warning=F, message=F}
# Read in edge list file as data frame
Cibola_edgelist <- read.csv(file="data/Cibola_edgelist.csv", header=TRUE) 
# Add additional column of weights as random integers between 1 and 4 for each edge
Cibola_edgelist$Weight <- sample(seq(1,4), nrow(Cibola_edgelist), replace=TRUE)

# Create weighted network object calling only the first two columns
weighted_net <- igraph::graph_from_edgelist(as.matrix(Cibola_edgelist[,1:2]), directed=FALSE)
# add edge attribute to indicate weight
E(weighted_net)$weight <- Cibola_edgelist$Weight

# Explore the first few rows of network object
head(get.data.frame(weighted_net))

# View network as adjacency matrix. Notice the attr="weight" command that 
# indicates which edge attribute to use for values in the matrix
as_adjacency_matrix(weighted_net, attr="weight")

# Plot the network
set.seed(574)
plot(weighted_net, edge.width=E(weighted_net)$weight)

```

Notice in the final plot that line thickness is used to indicate edges with various weights. We will explore further options for such visualizations in the network visualizations section of this appendix.

### Two-mode Networks and Affiliation Networks

Two-mode networks are networks where two separate categories of nodes are defined with a structural variable (edges) between these categories. In sociology, two-mode networks are often used for studying the affiliation of individuals with organizations, such as the presence of professionals on the boards of companies or the attendance of scholars at conferences (referred to as affiliation networks).

Two-mode network data are typically recorded in a two-way table with rows and columns representing two different classes of nodes and with individual cells representing the presence/absence or weight of edges between those classes of nodes. By way of example here we will return to the table of ceramic technological clusters by sites for the Cibola region data. The simplest way to create an unweighted two-mode network from these data is to create a network object directly from a two-way table as we saw above. In this example this will create an edge between each site and each technological cluster present there irrespective of relative frequency. 

```{r, warning=F, message=F}
# Read in two-way table of sites and ceramic technological clusters
Cibola_clust <- read.csv(file="data/Cibola_clust.csv", header=TRUE, row.names=1)
# Create network from incidence matrix based on presence/absence of a cluster at a site
Cibola_inc <- igraph::graph_from_incidence_matrix(Cibola_clust, directed=FALSE, multiple=TRUE)
Cibola_inc
set.seed(4537643)
# Plot as two-mode network
plot(Cibola_inc, vertex.color = as.numeric(V(Cibola_inc)$type)+1)
```

In this case since most clusters are present at most sites, this creates a pretty busy network that may not be particularly useful. An alternative to this is to define some threshold (either in terms of raw count or proportion) to define an edge between a node of one class and another. We provide an example here and build a function that you could modify to do this for your own data. In this function you can set the proportion threshold that you would like to used to define an edge between two classes of nodes. If the proportion of that cluster at that site is greater than or equal to that threshold an edge will be present.

```{r, warning=F, message=F}
# Define function for creating incidence matrix with threshold
two_mode <- function (x, thresh=0.25) {
  # Create matrix of proportions from x input into function
  temp <- prop.table(as.matrix(x), 1) 
  # Define anything with greater than or equal to threshold as present (1) 
  temp[temp>=thresh] <- 1 
  # Define all other cells as absent (0)
  temp[temp<1] <- 0 
  # Return the new binarized table as output of the function
return(temp)}

# Run the function and create network object
mod_clust <- two_mode(Cibola_clust, thresh=0.25) # thresh is set to 0.25 but could be any values from 0-1
# Examine the first few rows
head(mod_clust)
# Create a graph matrix from the new incidence matrix
two_mode_net <- igraph::graph_from_incidence_matrix(mod_clust, directed=FALSE, multiple=TRUE)

# Plot results
set.seed(4537)
plot(two_mode_net, vertex.color = as.numeric(V(Cibola_inc)$type)+1)
```

Notice how there are now far fewer ties and if you are familiar with the sites in question you might notice some clear regional patterning. 

It is also possible to create one-mode projections of the two-mode data here using simple matrix algebra. All you need to do is multiply a matrix by the transpose of that matrix. The results will be a adjacency matrix for whichever set of nodes represented the rows in the first matrix in the matrix multiplication. Here is an example using the "mod_clust" incidence matrix with threshold created above. In the resulting incidence matrix individual cells will represent the number of different edges in common between the nodes in question and can be treated like an edge weight. The diagonal of the matrix will be the total number of clusters that were present in a site assemblage.

```{r, warning=F, message=F}
# In R the command "%*%" indicates matrix multiplication and "t()" gives
# the transpose of the matrix within the parentheses.
# Lets first create a one-mode projection focused on sites
site_mode <- mod_clust %*% t(mod_clust)
site_net <- igraph::graph_from_adjacency_matrix(site_mode, mode="undirected", diag=FALSE)
plot(site_net)

# Now lets create a one-mode projection focused on ceramic technological clusters.
# Notice that the only change is we switch which side of the matrix multiplication
# we transpose.
clust_mode <- t(mod_clust) %*% mod_clust
clust_mode
clust_net <- igraph::graph_from_adjacency_matrix(clust_mode, mode="undirected", diag=FALSE)
plot(clust_net)
```

### Similarity Networks

Similarity networks simply refer to one-mode networks where nodes are defined as entities of interest with edges defined and/or weighted based on some metric of similarity (or distance) defined based on the features, attributes, or assemblage associated with that node. Such an approach is frequently used in archaeology to explore material cultural networks where nodes are contexts of interests (e.g., sites, excavation units, houses, etc.) and edges are defined or weighted based on similarities in the relative frequencies of artifacts or particular classes of artifacts recovered in those contexts.

There are many different ways to define and track similarity network data for use in R. In this example, we will show several methods using the affiliation data we used in the previous example. Specifically, we will define and weight edges based on similarities in the frequencies of ceramic technological clusters at sites in our Cibola region sample.

For most of these examples we will use the statnet package and the network package within it rather than igraph because statnet has a few additional functions that are useful when working with similarity data. In the following examples, we will first demonstrate several different similarity/distance metrics and then discuss approaches to binarization of these similarity networks and other options for working with weighted data.

#### Brainerd-Robinson Similarity {-}

The first metric we will explore here is a rescaled version of the Brainerd-Robinson (BR) similarity metric. This BR measure is commonly used in archaeology including in a number of recent (and not so recent) network studies. This measure represents the total similarity in proportional representation of categories and is defined as:

$$S = {\frac{2-\sum_{k} \left|x_{k} - y_{k}\right|} {2}}$$

where, for all categories $k$, $x$ is the proportion of $k$ in the first assemblage and $y$ is the proportion of $k$ in the second. We subtract the sum from 2 as 2 is the maximum proportional difference possible between two samples. We further divide the result by 2. This provides a scale of similarity from 0-1 where 1 is perfect similarity and 0 indicates no similarity. The chunk below defines the code for calculating this modified BR similarity measure. Note here we use a distance metric called "Manhattan Distance" built into the "vegan" package in R. This metric is identical to the Brainerd-Robinson metric.

```{r}
# Read in raw data
Cibola_clust <- read.csv(file="data/Cibola_clust.csv", header=TRUE, row.names=1)

# First we need to convert the ceramic technological clusters into proportions
clust_p <- prop.table(as.matrix(Cibola_clust), margin = 1) 

# The following line uses the vegdist function in the vegan package 
# to calculate the Brainard-Robinson similarity score. Since vegdist
# by default defines an unscaled distance we must subtract the results
# from 2 and then divide by 2 to get a similarity scaled from 0 to 1.
Cibola_BR <- (2-as.matrix(vegan::vegdist(clust_p, method='manhattan')))/2

# Lets look at the first few rows.
Cibola_BR[1:4,1:4]

```

At this point we could simply define this as a weighted network object where weights are equal to the similarity scores, or we could define a threshold for defining edges as present or absent. We will discuss these options in detail after presenting other similarity/distance metrics.

#### Morisita's Overlap Index {-}

Another measure that has been used for defining similarities among assemblages for archaeological similarity networks is Morisita's overlap index. This measure is a measure of the overlap of individual assemblages within a larger population that takes the size of samples into account. Specifically, the approach assumes that as sample size increases diversity will likely increase. This measure produces results that are very similar to the Brainerd-Robinson metric in practice in most cases but this measure may be preferred where there are dramatic differences in assemblage sizes among observations. 

Morisita's index is calculated as:

$$C_D=\frac{2 \Sigma^Sx_iy_i}{(D_x + D_y)XY}$$

Where:
$x_i$ is the number of rows where category $i$ is represented in the total $X$ from the population.
$y_i$ is the number of rows where category $i$ is presented in the total $Y$ from the population.
$D_x$ and $D_y$ are the Simpson's diversity index values for $x$ and $y$ respectively.
$S$ is the total number of columns.

This metric ranges from 0 (where no categories overlap at all) to 1 where the categories occur in the same proportions in both samples. Because this metric works on absolute counts we can run the vegdist function directly on the "Cibola_clust" object. Because we want a similarity rather than a distance (which is the default for this function in R) we subtract the results from 1. 

```{r}
# Calculate matrix of Morisita similarities based on the Cibola_clust two-way table.
Cibola_Mor <- 1-as.matrix(vegan::vegdist(Cibola_clust, method='morisita'))
Cibola_Mor[1:4,1:4]
```


#### $\chi^{2}$ Distance {-}

The next measure we will use is the $\chi^{2}$ distance metric which is the basis of correspondence analysis and related methods commonly used for frequency seriation in archaeology (note that this should probably really be called the $\chi$ distance since the typical form we use is not squared, but the name persists this way in the literature so that's what we use here). This measure is defined as:

$$\chi_{jk} = \sqrt{\sum \frac 1{c_{j}} 
({x_{j}-y_{j})^{2}}}$$

where $c_j$ denotes the $j_{th}$ element of the average row profile (the proportional abundance of $j$ across all rows) and $x$ and $y$ represent row profiles for the two sites under comparison. This metric therefore takes raw abundance (rather than simply proportional representation) into account when defining distance between sites. The definition of this metric is such that rare categories play a greater role in defining distances among sites than common categories (as in correspondence analysis). This measure has a minimum value of 0 and no theoretical upper limit. 

The code for calculating $\chi^{2}$ distances is defined in the chunk below and a new object called "Cibola_X" is created using this measure. It is sometimes preferable to rescale this measure so that it is bounded between 0 and 1. We create a second object called "Cibola_X01" which represents rescaled distances by simply dividing the matrix by the maximum observed value (there are many other ways to do this but this will be fine for our demonstration purposes). Again, we subtract these results from 1 to convert a distance to a similarity.

```{r, warning=F, message=F}
# Define function for calculating chi-squared distance
chi_dist <- function(x) {
  rowprof <- x/apply(x,1,sum) # calculates the profile for every row
  avgprof <- apply(x,2,sum)/sum(x) # calculates the average profile
  # creates a distance object of chi-squared distances
  chid <- dist(as.matrix(rowprof)%*%diag(1/sqrt(avgprof))) 
  # return the results
  return(as.matrix(chid))} 

# Run the script and then create the rescaled 0-1 version
Cibola_X <- chi_dist(Cibola_clust)
Cibola_X01 <- 1-(Cibola_X/max(Cibola_X))

Cibola_X01[1:4,1:4]
```

#### Creating Network Objects from Similarity Matrices {-}

Now that we have defined our three measures of similarity, the next step is to convert these into network objects that our R packages will be able to work with. We can do this by either creating binary networks (where ties are either present or absent) or weighted networks (which in many cases are simply the raw similarity/distance matrices we calculated above). We will provide examples of both approaches, starting with simple binary networks. There are many ways to define networks from matrices like those we generated above and our examples below should not been seen as an exhaustive set of procedures.

##### Creating binary network objects {-}

First, we will produce a network object based on our BR similarity matrix created above. In this example, we define ties as present between pairs of sites when they share more than 65% commonality (BR > 0.65) in terms of the proportions of ceramics recovered from pairs of sites. 

In the code below, the event2dichot function (from the "statnet" package) takes our matrix and divides it into 1s and 0s based on the cut off we choose. Here we're using and 'absolute' cut off meaning we're assigning a specific value to use as the cut off (0.65). We then send the output of this function to the network function just as before. 

```{r}
# Define our binary network object from BR similarity
BRnet <- network(event2dichot(Cibola_BR, method='absolute', thresh=0.65), directed=FALSE)
# Now let's add names for our nodes based on the row names of our original matrix
BRnet %v% 'vertex.names' <- row.names(Cibola_clust)
# look at the results.
BRnet

# plot network using default layout
set.seed(7564)
plot(BRnet)
```

In the next chunk of code we will use the $\chi^2$ distances to create binary networks. This time, we will not use an absolute value to define ties as present, but instead will define those similarities greater than 80 percent of all similarities as present. We will then once again plot just as above.

```{r fig.height=6,fig.width=10}
# Note we use 1 minus chacoX01 here so to convert a distance to a similarity
Xnet <- network(event2dichot(Cibola_X01, method='quantile', thresh=0.80), directed=FALSE)
# Once again add vertext names
Xnet %v% 'vertex.names' <- row.names(Cibola_clust)
# look at the results
Xnet

# plot network using default layout
set.seed(346)
plot(Xnet)
```

##### Creating Weighted Network Objects {-}

It is also possible to use R to create weighted networks where individual edges are valued. We have found that this works reasonably well with networks of co-presence or something similar (counts of mentions in texts or monuments for example) but this does not perform well when applied to large similarity or distance matrices (because every possible link has a value, the network gets unwieldy very fast). In the latter case, we have found it is often better to just work directly with the underlying similarity/distance matrix.

If you do, however, chose do create a weighted network object from a similarity matrix it only requires a slight modification from the procedure above. In the chunk of code below, we will simply add the arguments "ignore.eval=F" and "names.eval='weight'" to let the network function know we would like weights to be retained and we would like that attribute called 'weight'. We will apply this to the matrix of Morisita similarities defined above and then plot the result. 

```{r fig.height=6,fig.width=10}
# create weighted network object from co-occurrence matrix by adding the ignore.eval=F argument
Mor_wt <- network(Cibola_Mor, directed=FALSE, ignore.eval=FALSE, names.eval='weight')
Mor_wt %v% 'vertex.names' <- row.names(Cibola_Mor)
Mor_wt

# plot weighted network using default layout
set.seed(4634)
plot(Mor_wt)
```

The resulting network is nearly complete so it is a bit unwieldy for plotting but calculating network statistics on this weighted network can often still be useful as we will see in the exploratory analysis section.

#### Converting Among Network Object Formats {-}

In most of the examples in this document we have been using the igraph package but for the similarity networks we chose to use statnet due to the convenience of functions for working directly with similarity matrices. Not to worry as it is easy to convert one format to another and preserve all of the attributes using a package called intergraph. By way of example below we can covert the weighted network object we created in the previous step and convert it to a igraph object and view the attributes using the "asIgraph" function. If we wanted to go the other direction and covert a igraph object to a statnet/network object we would instead use "asNetwrok".

```{r, warning=F, message=F}
Mor_wt_i <- asIgraph(Mor_wt)
Mor_wt_i

# view first 10 edge weights to show that they are retained
E(Mor_wt_i)$weight[1:10]

```

### Ego Networks

When we aim to understand the relational environment within which an entity is embedded, because it is relevant for our research questions or because data collection challenges dictate this focus, archaeological network research can make use of so-called ego-networks: a type of network that includes a focal node (the so-called ego), the set of nodes the ego is connected to by an edge (the so-called alters) and the edges between this set of nodes. 

Extracting an ego-network from an existing igraph network object in R is very easy. Here we will extract and plot the ego-network for Apache Creek, the first site in the network files we created above. 

```{r, warning=F, message=F}
# Read in edgelist file as dataframe
Cibola_edgelist <- read.csv(file="data/Cibola_edgelist.csv", header=TRUE) 

# Create graph object. The dataframe is converted to a matrix as that is required 
# by this specific function. Since this is an undirected network directed = FALSE.
Cibola_net <- igraph::graph_from_edgelist(as.matrix(Cibola_edgelist), directed=FALSE)

# Extract ego-networks
ego_nets <- make_ego_graph(Cibola_net)

# Examine the first ego-network
ego_nets[[1]]

# Plot Apache Creek ego-network
set.seed(754)
plot(ego_nets[[1]])

# Plot Platt Ranch ego-network for comparison
set.seed(45367)
plot(ego_nets[[30]])
```

In these ego-networks, only nodes connected to the target nodes (Apache Creek in the first example and then Platt Ranch in the second) are shown and only edges among those included nodes are shown.

It is also possible to determine the size of ego-networks for an entire one-mode network using the "ego_size" function. The output of this function is a vector that can be further assigned as a network node attribute.

```{r}
ego_size(Cibola_net)

```


### Multilayer Networks

In the simplest terms, multilayer networks are networks where a single set of nodes are connected by two or more sets of edges that each represent a different kind of relationship among the nodes. This is a relatively new area of network science in archaeological network research but we expect this will likely change in the coming years. There are now new R packages which help manage and analyze multilayer network data.

The multinet package (Rossi and Vega 2021) is designed to facilitate the analysis of multilayer networks. In order to explore some of the possibilities here we use example data and analyses included in this package. Specifically, we will look at the famous network data on Florentine families in the 14th century where connections were defined in terms of both business and marriage.

```{r}
# create object with Florentine multilayer network data
florentine <- ml_florentine()

# Examine the data
florentine
summary(florentine)

# plot the data
plot(florentine)

```

The multinet network objects are essentially compatible with igraph and individual layers can be analyzed just like other igraph network objects. Where this multinet approach likely has greater utility is in conducting comparisons among layers or conducting analyses that take several layers into account simultaneously. A detailed exploration of this approach is beyond the scope of this document (but we provide a simple example below) and we suggest interested readers read the package information and tutorials associated with this package for more.

```{r}
# If we want to calculate degree centrality across multiple layers of a 
# multilayer network, the multinet package can help us do that directly
# and quite simply.
multinet::degree_ml(florentine)

# Similarly, we could apply cluster detection algorithms to all layers
# of a multilayer network simultaneously.
multinet::glouvain_ml(florentine)
```



<!--chapter:end:02-network-data-formats.Rmd-->

# Exploratory Network Analysis 

This section serves as a companion to Chapter 4 in Brughmans and Peeples 2022 and provides basic examples of the exploratory network analytical methods outlined in the book as well as a few others. 

## Example Network Objects

In order to facilitate the exploratory analysis examples in this section, we want to first create a set of igraph network objects that will serve our purposes across all of the analyses below. Specifically, we will generate and define:

* simple_net - A simple undirected binary network with isolates
* simple_net_noiso - A simple undirected binary network without isolates
* directed_net - A directed binary network
* weighted_net - An undirected weighted network
* sim_net_i - A similarity network with edges weighted by similarity in the igraph format
* sim_net - A similarity network with edges weighted by similarity in the statnet/network format
* sim_mat - A data frame object containing a weighted similarity matrix

Each of these will be used as appropriate to illustrate particular methods. 

In the following chunk of code we initialize all of the packages that we will use in this section and define all of the network objects that we will use (using the object names above). In these examples we will once again use the Cibola technological similarity data we used in the Network Data section previously. 

```{r, warning=F, message=F}
# initialize packages
library(igraph)
library(statnet)
library(intergraph)
library(vegan)

# read in csv data
Cibola_edgelist <- read.csv(file="data/Cibola_edgelist.csv", header=TRUE) 
Cibola_adj_mat <- read.csv(file="data/Cibola_adj.csv", header=T, row.names=1)

# Simple network with isolates
simple_net <- igraph::graph_from_adjacency_matrix(as.matrix(Cibola_adj_mat), mode="undirected")

# Simple network with no isolates
simple_net_noiso <- igraph::graph_from_edgelist(as.matrix(Cibola_edgelist), directed=FALSE)

#Create a directed network by subsampling edgelist
set.seed(45325)
EL2 <- Cibola_edgelist[sample(seq(1,nrow(Cibola_edgelist)), 125, replace=FALSE),]
directed_net <- igraph::graph_from_edgelist(as.matrix(EL2), directed=TRUE)

# Create a weighted undirected network by adding column of random weights to edgelist
Cibola_edgelist$Weight <- sample(seq(1,4), nrow(Cibola_edgelist), replace=TRUE)
weighted_net <- igraph::graph_from_edgelist(as.matrix(Cibola_edgelist[,1:2]), directed=FALSE)
E(weighted_net)$weight <- Cibola_edgelist$Weight

# Create a similarity network using the Brainerd-Robinson metric
Cibola_clust <- read.csv(file="data/Cibola_clust.csv", header=TRUE, row.names=1)
clust_p <- prop.table(as.matrix(Cibola_clust), margin = 1) 
sim_mat <- (2-as.matrix(vegan::vegdist(clust_p, method='manhattan')))/2
sim_net <- network(sim_mat, directed=FALSE, ignore.eval=FALSE, names.eval='weight')
sim_net_i <- asIgraph(sim_net)

```

## Calculating Network Metrics in R {#CalcMetric}

Although the calculations behind the scenes for centrality metrics, clustering algorithms, and other network measures may be somewhat complicated, calculating these measures in R using network objects is usually quite straight forward and typically only involves a single function and a couple of arguments within it. There are, however, some things that need to be kept in mind when applying these methods to network data. In this appendix, we provide examples of some of the most common functions you may use as well as a few caveats and potential problems.

One thing to keep in mind when working with R network data and using multiple packages at the same time is that different packages may have functions with the same name so it often is good practice to specify which package you mean to use directly in your code. For example, the function to calculate degree centrality in both igraph and sna (part of the statnet suite of packages) is simply "degree." If you type "degree(simple_net)" at the console, R will attempt to use the "degree" function from whichever package was called more recently. This may not be what you want. In order to avoid ambiguity, you can add the package name to the call like this "igraph::degree(simple_net)" since "simple_net" is an igraph object, this will work correctly and return results. On the other hand "sna::degree(simple_net)" would create an error as the sna version of the degree function expects a different format of network object. 

In addition to potential overlap in function names, another thing that you need to keep in mind is that certain network metrics require networks with specific properties and may produce unexpected results if the wrong kind of network is used. For example, closeness centrality is only well defined for binary networks that have no isolates. If you were to use the "igraph::closeness" command to calculate closeness centrality on a network with isolates, you would get results but you would also get a warning telling you "closeness centrality is not well-defined for disconnected graphs." For other functions if you provide data that does not meet the criteria required by that function you my instead get an error and have no results returned. In some cases, however, a function may simply return results and not provide any warning so it is important that you are careful when selecting methods to avoid providing data that violates assumptions of the method provided. Remember, that if you have questions about how a function works or what it requires you can type "?function_name" at the console with the function in question and you will get the help document that should provide more information. You can also include package names in the help call to avoid getting something unexpected (i.e., "?igraph::degree")

## Centrality

One of the most common kinds of exploratory network analysis involves calculating basic network centrality and centralization statistics. There are a wide array of methods available in R through the igraph and statnet packages. In this section we highlight a few examples as well as a few caveats to keep in mind.

### Degree Centrality

Degree centrality can be calculated using the "igraph::degree" function for simple networks with or without isolates as well as simple directed networks. This method is not, however, appropriate for weighted networks or similarity networks (because it expects binary values). If you apply the "igraph::degree" function to a weighted network object you will simply get the binary network degree centrality values. The alternative for calculating weighted degree for weighted and similarity networks is to simply calculate the row sums of the underlying similarity matrix (minus 1 to account for self loops) or adjacency matrix. For the degree function the returned output is a vector of values representing degree centrality which can further be assigned to an R object, plotted, or otherwise used. We provide a few examples here to illustrate. Note that for directed graphs you can also specify the mode as "in" for indegree or "out" for outdegree or "all" for the sum of both. 

Graph level degree centralization is equally simple to call using the centr_degree function. This function returns an object with multiple parts including a vector of degree centrality scores, the graph level centralization metric, and the theoretical maximum number of edges (n * [n-1]). This metric can be normalized such that the maximum centralization value would be 1 using the "normalize=TRUE" argument as we demonstrate below.

```{r, warning=F, message=F}
# simple network with isolates
igraph::degree(simple_net) 
# simple network no isolates
igraph::degree(simple_net_noiso) 

# directed network
igraph::degree(directed_net, mode="in") # indegree
igraph::degree(directed_net, mode="out") # outdegree

# weighted network - rowSums of adjacency matrix
rowSums(as.matrix(as_adjacency_matrix(weighted_net, attr="weight")))-1

# similarity network
rowSums(sim_mat)-1 # note we use the similarity matrix here and not the network object

# If you want to normalize your degree centrality metric by the number of nodes present
# you can do that by adding the normalize=TRUE command to the function calls above.
# for weighted and similarity networks you can simply divide by the number of nodes minus 1.
igraph::degree(simple_net, normalize=T)

# it is also possible to directly plot the degree distribution for a given network
# using the degree.distribution function. Here we embed that call directly in a 
# call for a histogram plot using the hist function
hist(igraph::degree.distribution(simple_net))

# graph level centralization
igraph::centr_degree(simple_net)

# to calculate centralization score for a similarity matrix, use the sna::centralization function
sna::centralization(sim_mat, normalize=TRUE, sna::degree)

```

If you are interested in calculating graph level density you can do this using the "edge_density" function. Note that just like the degree function above, this only works for binary networks and if you submit a weighted network object you will simply get the binary edge density value.

```{r, warning=F, message=F}
edge_density(simple_net_noiso)

edge_density(weighted_net)

```

### Betweenness Centrality

The betweenness functions work very much like the degree function calls above. Betweenness centrality in igraph can be calculated for simple networks with and without isolates, directed networks, and weighted networks. In the case of weighted networks or similarity networks, the shortest paths between sets of nodes are calculated such that the path of greatest weight is taken at each juncture. You can normalize your results by using "normalize=TRUE" just like you could for degree. The "igraph::betweenness" function will automatically detect if a graph is directed or weighted and use the appropriate method but you can also specify a particular edge attribute to use for weight if you perhaps have more than one weighting scheme. 

```{r}
# calculate betweenness for simple network
igraph::betweenness(simple_net)
# calculate betweenness for weighted network
igraph::betweenness(weighted_net, directed=FALSE)
# calculate betweenness for weighted network specifying weight attribute
igraph::betweenness(weighted_net, weights=E(weighted_net)$weight)

# calculate graph level centralization
centr_betw(simple_net)
```

### Eigenvector Centrality

The "igraph::eigen_centrality" function can be calculated for simple networks with and without isolates, directed networks, and weighted networks. By default scores are scaled such that the maximum score of 1. You can turn this scaling of by using the "scale=FALSE" argument. This function automatically detects whether a network object is directed or weighted but you can also call edge attributes to specify a particular weight attribute. By default this function outputs many other features of the analysis such as the number of steps toward convergence and the number of iterations but if you just want the centrality results you can use the atomic vector call to $vector.

```{r}
eigen_centrality(simple_net, scale=TRUE)$vector

eigen_centrality(weighted_net, weights=E(weighted_net)$weight, directed=FALSE, scale=FALSE)$vector
```

### Page Rank Centrality

The "igraph::page_rank" function can be calculated for simple networks with and without isolates, directed networks, and weighted networks. By default scores are scaled such that the maximum score is 1. You can turn this scaling off by using the "scale=FALSE" argument. This function automatically detects whether a network object is directed or weighted but you can also call edge attributes to specify a particular weight attribute. You can change the algorithm used to implement the page rank algorithm (see help for details) and can also change the damping factor if desired.

```{r, warning=F, message=F}
page_rank(directed_net, directed=TRUE)

page_rank(weighted_net, weights=E(weighted_net)$weight, directed=FALSE, algo="prpack")
```

### Closeness Centrality

The "igraph::closeness" function calculates closeness centrality and can be calculated for directed and undirected simple or weighted networks with no isolates. This function can also be used for networks with isolates, but you will receive an additional message suggesting that closeness is undefined for networks that are not fully connected. For very large networks you can use the "igraph::estimate_closeness" function with a cutoff setting that will consider paths of length up to cutoff to calculate closeness scores. For directed networks you can also specify whether connections in, out, or in both directions should be used.

```{r}
igraph::closeness(simple_net)

igraph::closeness(simple_net_noiso)

igraph::closeness(weighted_net, weights=E(weighted_net)$weight)

igraph::closeness(directed_net, mode="in")
```


### Hubs and Authorities

In directed networks it is possible to calculate hub and authority scores to identify nodes that are characterized by high indegree and high outdegree in particular. Because this is a measure that depends on direction it is only appropriate for directed network objects. If you run this function for an undirected network hub scores and authority scores will be identical. These functions can also be applied networks that are both directed and weighted. If you do not want all options printed you can use the atomic vector $vector call as well.

```{r}
igraph::hub_score(directed_net)$vector

igraph::authority_score(directed_net)$vector
```
## Triads and clustering

Another important topic in network science concerns considerations of the overall structure and clustering of connections across a network as a whole. There are a variety of methods which have been developed to characterize the overall degree of clustering and closure in networks, many of which are based on counting triads of various configurations. In this section, we briefly outline approaches toward evaluating triads, transitivity, and clustering in R.

### Triads

A triad is simply a set of three nodes and a description of the configuration of edges among them. For undirected graphs, there are four possibilities for describing the connections among those nodes (empty graph, 1 connection, 2 connections, 3 connections). For directed graphs the situation is considerably more complicated because ties can be considered in both directions and an edge in one direction isn't necessarily reciprocated. Thus there are 16 different configurations that can exist (see Brughmans and Peeples 2022: Figure 4.4).

One common method for outlining the overall structural properties of a network is to conduct a "triad census" which counts each of the 4 or 16 possible triads for a given network. Although a triad census can be conducted on an undirected network using the igraph::triad_census function, a warning will be returned along with 0 results for all impossible triad configurations so be aware. The results are returned as a vector of counts of each possible node configuration in an order outlined in the help document associated with the function (see ?triad_census for more).

```{r}
igraph::triad_census(directed_net)

igraph::triad_census(simple_net)
```

Often can be useful to visualize the motifs defined for each entry in the triad census and this can be done using the "graph_from_isomorphism_class()" function and a little bit of additional data wrangling and plotting using the ggraph and ggpubr packages. These packages are described in more detail in the visualization section of this appendix. 

```{r, warning=F, message=F, fig.height=12, fig.width=12}
library(ggraph)
library(ggpubr)

g <- list()
xy <- as.data.frame(matrix(c(0,0,1,0,0.5,0.5),nrow=3,ncol=2,byrow=T))

for (i in 0:15) {
  g_temp <- graph_from_isomorphism_class(size=3, number=i, directed=T)
  g[[i+1]] <- ggraph(g_temp, layout="manual",
                     x=xy[,1], y=xy[,2]) +
                geom_node_point(size=8,col="purple") +
                geom_edge_fan(arrow = arrow(length = unit(4, 'mm'), type="closed"),
                 end_cap = circle(6, 'mm'), start_cap = circle(6, 'mm'), 
                 edge_colour = "black") +
                theme_graph(plot_margin = margin(0,0,0,0),border=T,foreground="black")
}

# motifs ordered by order in triad_census function
ggarrange(g[[1]],g[[2]],g[[4]],g[[7]],
          g[[3]],g[[5]],g[[6]],g[[10]],
          g[[8]],g[[12]],g[[11]],g[[9]],
          g[[13]],g[[14]],g[[15]],g[[16]],
          nrow=4, ncol=4)
```


### Transitivity and Clustering

A network’s global average transitivity (or clustering coefficient) is the number of closed triads over the total number of triads in a network. This measure can be calculated using "igraph::transitivity" for simple networks with or without isolates, directed networks, and weighted networks. There are options within the function to determine the specific type of transitivity (global transitivity is the default) and for how to treat isolates. See the help document (?igraph::transitivity) for more details. If you want to calculate local transitivity for a particular node you can use the "type='local'" argument. This will return a NA value for nodes that are not part of any triads (isolates and nodes with a single connection).

```{r}
igraph::transitivity(simple_net, type="global")

igraph::transitivity(simple_net, type="local")

```

## Walks, Paths, and Distance

There are a variety of network metrics which rely on distance and paths across networks that can be calculated in R. There are a great many functions available and we highlight just a few here.

### Distance

In some cases, you may simply want information about the graph distance between nodes in general or perhaps the average distance. There are a variety of functions that can help with this including "igraph::distances" and "igraph::mean_distance." These work on simple networks, directed networks, and weighted networks.

```{r}
# Create matrix of all distances among nodes and view the first few rows and columns
igraph::distances(simple_net)[1:4, 1:4]

# Calculate the mean distance for a network
igraph::mean_distance(simple_net)
```

### Shortest Paths

If you want to identify particular shortest paths to or from nodes in a network you can use the "igraph::shortest_paths" function or alternatively the igraph::all_shortest_paths if you want all shortest paths originating at a particular node. To call this function you simply need to provide a network object and an id for the origin and destination of the path. The simplest solution is just to call the node number. This function works with directed and undirected networks with or without weights. Although it can be applied to networks with isolates, the isolates themselves will produce NA results. 

```{r}
# track shortest path from Apache Creek to Pueblo de los Muertos
igraph::shortest_paths(simple_net, from=1, to=21)

```

The output provides the ids for all nodes crossed in the path from origin to destination. 

### Diameter

The "igraph::diameter" function calculates the diameter of a network (the longest shortest path) and you can also use the "farthest_vertices" function to get the ids of the nodes that form the ends of that longest shortest path. This metric can be calculated for directed and undirected, weighted and unweighted networks, with or without isolates.

```{r}
igraph::diameter(directed_net, directed=TRUE)

igraph::farthest_vertices(directed_net, directed=T)
```

## Components and Bridges

Identifying fully connected subgraphs within a large network is a common analytical procedure and is quite straight forward in R using the igraph package. If you first want to know whether or not a given network is fully connected you can use the "igraph::is_connected" function to check. 

```{r}
igraph::is_connected(simple_net)

igraph::is_connected(simple_net_noiso)
```

You can also count components using the "count_components" function.

```{r}
igraph::count_components(simple_net)
```


### Identifying Components

If you want to decompose a network object into its distinct components you can use the "igraph::decompose" function which outputs a list object with each entry representing a distinct component. Each object in the list can then be called using [[k]] where k is the number of the item in the list.

```{r}
components <- igraph::decompose(simple_net, min.vertices = 1)

components

V(components[[2]])$name
```

In the example here this network is fully connected with the exception of 1 node (WS Ranch). When you run the decompose function it separates WS ranch into a component as an isolate with no edges.

### Cutpoints

A cutpoint is a node, the removal which creates a network with a higher number of components. There is not a convenient igraph function for identifying cutpoints but there is a function in the "sna" package within the "statnet" suite. Using the intergraph package we can easily convert an igraph object to an sna object (using the asNetwork function) within the call to use this function. 

The sna::cutpoint function returns the node id for any cutpoints detected. We can use the numbers returned to find the name of the node in question.

```{r}
cut_p <- cutpoints(asNetwork(simple_net))
cut_p

V(simple_net)$name[cut_p]

set.seed(4536)
plot(simple_net)
```

The example here reveals that Ojo Bonito is a cutpoint and if we look at the figure we can see that it is the sole connection with Baca Pueblo which would otherwise become and isolate and distinct component if Ojo Bonito were removed.

### Bridges

A bridge is an edge, the removal of which results in a network with a higher number of components. The function igraph::min_cut finds bridges in network objects for sets of nodes or for the graph as a whole. The output of this function includes a vector called $cut which provides the edges representing bridges. By default this function only outputs the cut value but you can use the argument value.only=FALSE to get the full output.

```{r}
min_cut(simple_net_noiso,value.only=FALSE)
```

As this example illustrates the edge between Ojo Bonito and Baca Pueblo is a bridge (perhaps not surprising as Ojo Bonito was a cut point).

## Cliques and Communities

Another very common task in network analysis involves creating cohesive sub-groups of nodes in a larger network. There are wide variety of methods available for defining such groups and we highlight a few of the most common here.

### Cliques

A clique as a network science concept is arguably the strictest method of defining a cohesive subgroup. It is any set of three or more nodes in which each node is directly connected to all other nodes. It can be alternatively defined as a completely connected subnetwork, or a subnetwork with maximum density. The function "igraph::max_cliques" finds all maximal cliques in a network and outputs a list object with nodes in each set indicated. For the sake of space here we only output one clique of the 24 that were defined by this function call.

```{r}
max_cliques(simple_net, min=1)[[24]]
```

Note in this list that the same node can appear in more than one maximal clique.

### K-cores

A k-core is a maximal subnetwork in which each vertex has at least degree k within the subnetwork. In R this can be obtained using the "igraph::coreness" function and the filtering by value as appropriate. This function creates a vector of k values which can then be used to remove nodes as appropriate or symbolize them in plots.

```{r}
# Define coreness of each node
kcore <- coreness(simple_net)
kcore

# set up colorscale
col_set <- heat.colors(max(kcore), rev=TRUE)
set.seed(2509)
plot(simple_net, vertex.color=col_set[kcore])
```

In the plot shown here the darker read colors represent higher maximal k-core values.

### Cluster Detection Algorithms

R allows you to use a variety of common cluster detection algorithms to define groups of nodes in a network using a variety of different assumptions. We highlight a few of the most common here.

#### Girvan-Newman Clustering

Girvan-Newman clustering is a divisive algorithm based on betweenness that defines a partition of network that maximizes modularity by removing nodes with high betweenness iteratively (see discussion in Brughmans and Peeples 2022 Chapter 4.6). In R this is referred to as the igraph::edge.betweenness.community function. This function can be used on directed or undirected networks with or without edge weights. This function outputs a variety of information including individual edge betweenness scores, modularity information, and partition membership. See the help documents for more information

```{r}
GN <- igraph::edge.betweenness.community(simple_net)
set.seed(4353)
plot(simple_net, vertex.color=GN$membership)
```

#### Walktrap Algorithm

The walktrap algorithm is designed to work for either binary or weighted networks and defines communities by generating a large number of short random walks and determining which sets of nodes consistently fall along the same short random walks. This can called using the "igraph::cluster_walktrap" function. The "steps" argument determines the length of the short walks and is set to 4 by default.

```{r}
WT <- igraph::cluster_walktrap(simple_net, steps=4)
set.seed(4353)
plot(simple_net, vertex.color=WT$membership)
```

#### Louvain Modularity

Louvain modularity is a cluster detection algorithm based on modularity. The algorithm iteratively moves nodes among community definitions in a way that optimizes modularity. This measure can be calculated on simple networks, directed networks, and weighted networks and is implemented in R through the "igraph::cluster_louvain" function.

```{r}
LV <- igraph::cluster_louvain(simple_net)
set.seed(4353)
plot(simple_net, vertex.color=LV$membership)
```

#### Calculating Modularity for Partitions

If you would like to compare modularity scores among partitions of the same graph, this can be achieved using the "igraph::modularity" function. In the modularity call you simply supply an argument indicating the partition membership for each node. Note that this can also be used for attribute data such as regional designations. In the following chunk of code we will compare modularity for each of the clustering methods described above as well using subregion designations [from the original Cibola region attribute data](data/Cibola_attr.csv)

```{r}
# Modularity for Girvan-Newman
modularity(simple_net, membership=membership(GN))

# Modularity for walktrap
modularity(simple_net, membership=membership(WT))

# Modularity for Louvain clustering
modularity(simple_net, membership=membership(LV))

# Modularity for subregion
Cibola_attr <- read.csv("data/Cibola_attr.csv")
modularity(simple_net, membership=as.factor(Cibola_attr$Region))
```

Note that although modularity can be useful in comparing among partitions like this approach has been shown to be poor at detecting small communities within a network so will not always be appropriate. 

#### Finding Edges Within and Between Communities

In many cases you may be interested in identifying edges that remain within or extend between some network partition. This can be done using the "igraph::crossing" function. This function expects a igraph cluster definition object and an igraph network and will return a list of true and false values for each edge where true indicates an edge that extends beyond the cluster assigned to the nodes. Let's take a look at the first 10 edges in our simple_net object based on the Louvain cluster definition. 

```{r}
igraph::crossing(LV, simple_net)[1:10]
```

Beyond this, if you plot an igraph object and add a cluster definition to the call it will produce a network graph with the clusters outlined and with nodes that extend between clusters shown in red.

```{r}
set.seed(54)
plot(LV, simple_net)
```

## Case Study

In the case study provided at the end of Chapter 4 of Brughmans and Peeples (2022) we take a simple network based on Roman era roads and spatial proximity of settlements in the Iberian Peninsula and calculate some basic exploratory network statistics. As described in the book, we can create different definitions and criteria for network edges and these can have impacts on the network and node level properties. In this case, we define three different networks as follows:

* A basic network where every road connecting two settlements is an edge
* A network that retains all of the ties of the above network but also connects isolated nodes that are within 50 Kms of one of the road network settlements
* A network that retains all of the ties of the first road network but connects each isolate to its nearest neighbor among the road network settlements

First let's read in the [data file](data/road_networks.RData) that contains all three networks and start by plotting them in turn on a map. For more details on how these plots work, see section 6 on network visualization. 

```{r iberian_roads, warning=F, message=F, fig.heigh=4, fig.width=12}

library(igraph)
library(ggmap)
library(sf)

load("data/road_networks.RData")

# Convert attribute location data to sf coordinates
locations_sf <- st_as_sf(nodes, coords = c("long", "lat"), crs = 4326)
coord1 <- do.call(rbind, st_geometry(locations_sf)) %>% 
  tibble::as_tibble() %>% setNames(c("lon","lat"))

xy <- as.data.frame(coord1)
colnames(xy) <- c('x','y')

myMap <- get_stamenmap(bbox = c(-9.5,36,3,43.8),maptype = "watercolor",zoom = 6)


# Extract edgelist from network object for road_net
edgelist1 <- get.edgelist(road_net)

# Create dataframe of beginning and ending points of edges
edges1 <- as.data.frame(matrix(NA,nrow(edgelist1),4))
colnames(edges1) <- c("X1","Y1","X2","Y2")
for (i in 1:nrow(edgelist1)) {
edges1[i,] <- c(nodes[which(nodes$Id==edgelist1[i,1]),3],nodes[which(nodes$Id==edgelist1[i,1]),2],
               nodes[which(nodes$Id==edgelist1[i,2]),3],nodes[which(nodes$Id==edgelist1[i,2]),2])
}

basic_net <- ggmap(myMap) +
  geom_segment(data = edges1, aes(x=X1, y=Y1, xend=X2, yend=Y2), col='black', size=1) +
  geom_point(data = xy, aes(x,y), alpha=0.8, col='black', fill="white", shape=21, size=2, show.legend=F) +
  ggtitle("Basic Network") +
  theme_void()


# Extract edgelist from network object for road_net2
edgelist2 <- get.edgelist(road_net2)

# Create dataframe of beginning and ending points of edges
edges2 <- as.data.frame(matrix(NA,nrow(edgelist2),4))
colnames(edges2) <- c("X1","Y1","X2","Y2")
for (i in 1:nrow(edgelist2)) {
edges2[i,] <- c(nodes[which(nodes$Id==edgelist2[i,1]),3],nodes[which(nodes$Id==edgelist2[i,1]),2],
               nodes[which(nodes$Id==edgelist2[i,2]),3],nodes[which(nodes$Id==edgelist2[i,2]),2])
}

basic_net_50 <- ggmap(myMap) +
  geom_segment(data = edges2, aes(x=X1, y=Y1, xend=X2, yend=Y2), col='black', size=1) +
  geom_point(data = xy, aes(x,y), alpha=0.8, col='black', fill="white", shape=21, size=2, show.legend=F) +
  ggtitle("Basic Network + 50Km Buffer") +
  theme_void()

# Extract edgelist from network object for road_net 3
edgelist3 <- get.edgelist(road_net3)

# Create dataframe of beginning and ending points of edges
edges3 <- as.data.frame(matrix(NA,nrow(edgelist3),4))
colnames(edges3) <- c("X1","Y1","X2","Y2")
for (i in 1:nrow(edgelist3)) {
edges3[i,] <- c(nodes[which(nodes$Id==edgelist3[i,1]),3],nodes[which(nodes$Id==edgelist3[i,1]),2],
               nodes[which(nodes$Id==edgelist3[i,2]),3],nodes[which(nodes$Id==edgelist3[i,2]),2])
}

basic_net_nn <- ggmap(myMap) +
  geom_segment(data = edges3, aes(x=X1, y=Y1, xend=X2, yend=Y2), col='black', size=1) +
  geom_point(data = xy, aes(x,y), alpha=0.8, col='black', fill="white", shape=21, size=2, show.legend=F) +
  ggtitle("Basic Network + Nearest Neighbor Isolates") +
  theme_void()

library(ggpubr)

ggarrange(basic_net, basic_net_50, basic_net_nn, nrow=1)
```

Now that we've replicated the visuals, we want to replicate network statistics. Since we're going to calculate several of the same network statistics for the networks in question, we can wrap this all into a function to save a bit of time. The following function expects an igraph network object and calculates each of the 10 variables show in the example in the book and returns them as a matrix.

```{r}
library(igraph)
library(intergraph)

net_stats <- function(net) {
  out <- matrix(NA,10,2)
  out[,1] <- c("Nodes", "Edges", "Isolates", "Density", "Average Degree", "Average Shortest Path",
               "Diamater", "Clustering Coefficient", "Closed Triad Count", "Open Triad Count")
  out[1,2] <- vcount(net) # number of nodes
  out[2,2] <- ecount(net) # number of edges
  out[3,2] <- length(isolates(asNetwork(net))) # number of isolates
  out[4,2] <- round(edge_density(net),3) # network density rounding to the third digit
  out[5,2] <- round(mean(igraph::degree(net)),3) # mean degree rounding to the third digit
  out[6,2] <- round(igraph::mean_distance(net),3) # mean shortest path length rounding to the third digit
  out[7,2] <- igraph::diameter(net) # network diameter
  out[8,2] <- round(igraph::transitivity(net, type='average'),3) # average global transitivity rounding to the third digit
  out[9,2] <- igraph::triad_census(net)[16] # closed triads in triad_census
  out[10,2] <- igraph::triad_census(net)[11] # open triads in triad_census
return(out)
}
```

Now let's run it for each of the three networks in turn to reproduce the results in the book.

```{r, warning=F, message=F}
net_stats(road_net)

net_stats(road_net2)

net_stats(road_net3)
```


<!--chapter:end:03-exploratory-analysis.Rmd-->

# Quantifying Uncertainty

This section provides code and examples to accompany Chapter 5 of Brughmans and Peeples (2022) and our discussions of missing and poor quality data in archaeological networks. For many of the other analyses in the book it is possible to use a number of different network software packages to conduct similar analyses. The analyses presented in Chapter 5, however, require the creation of custom scripts and procedures that are only possible in a programming language environment like R. We attempt here to not only provide information on how to replicate the examples in the book but also provide guidance on how you might modify the functions and code provided here for your own purposes. 

## A General Approach to Uncertainty

As outlined in the book, our basic approach to quantifying and dealing with uncertainty is to use the sample we have as a means for understanding the robustness or vulnerability of the population from which that sample was drawn to the kinds of variability or perturbations we might expect. The procedures we advocate primarily take the following basic form: 

* Define a network based on the available sample, calculate the metrics and characterize the properties of interest in that network. 
* Derive a large number of modified samples from the network created in step 1 (or the underlying data) that simulate the potential data problem we are trying to address. For example, if we are interested in the impact of nodes missing at random, we could randomly delete some proportion of the nodes in each sample derived from the network created in step 1. 
* Calculate the metrics and characterize the properties of the features of interest in every one of the random samples created in step 2 and assess central tendency (mean, median) and distributional properties (range, standard deviation, distribution shape, etc.) or other features of the output as appropriate. 
* Compare the distributions of metrics and properties (at the graph, node, or edge level) from the random samples to the “original” network created in step 1 to assess the potential impacts of the perturbation or data treatment. This comparison between the properties of the network created in step 1 and the distribution of properties created in step 3 will provide information directly relevant to assessing the impact of the kind of perturbation created in step 2 on the original network sample and, by extension, the complete network from which it was drawn.

The underlying assumption of the approach outlined here is that the robustness or vulnerability to a particular perturbation of the observed network data, drawn from a complete network that is unattainable, provides information about the robustness or vulnerability of that unattainable complete network to the same kinds of perturbations. For example, if we are interested in exploring the degree distribution of a network and our sampling experiments show massive fluctuations in that distribution in sub-samples with only small numbers of nodes removed at random, this would suggest that the particular properties of this network are not robust to nodes missing at random for degree calculations and we should not place much confidence in any results obtained from the original sample as indicative of the complete network from which it was drawn. On the other hand, say we instead find that in the resampling experiments the degree distributions in our sub-samples are substantially similar to that of the original network sample even when moderate or large numbers of nodes are removed. In that case, we might conclude that our network structure is such that assessments of degree distribution are robust to node missigness within the range of what we might expect for our original sample in relation to the complete network from which it was drawn. It is important to note, however, that this finding should not be transferred to any other metrics as any given network is likely to be robust to certain kinds of perturbations for certain network metrics, but not to others.

In the sub-sections below we create a basic function to conduct these analyses and show how it can be modified to fit almost any data perturbation you chose to simulate.

## Missing at Random

This sub-section accompanies the discussion of nodes or edges missing at random in Brughmans and Peeples (2022) Chapter 5.3.1. Here we take one interval of the Chaco World ceramic similarity network (ca. A.D. 1050-1100) and simulate the impact of nodes missing at random on network centrality statistics. Download the [ceramic similarity adjacency matrix](data/AD1050net.csv) to follow along.

The first thing we need to do is to initialize our required libraries and import the ceramic ware data and convert it into a network object. Here we will once again use the igraph package. For our example here we are using a simple undirected network.

```{r, message=F, warning=F}
library(igraph)
library(reshape2)
library(ggplot2)
library(ggraph)
library(tnet)
library(ggpubr)
library(dplyr)
library(statnet)

# Import adjacency matrix and covert to network
chaco <- read.csv(file='data/AD1050net.csv',row.names=1)

chaco_net <- igraph::graph_from_adjacency_matrix(as.matrix(chaco), mode="undirected")

```

Now we need to define a function that removes a specified proportion of nodes at random, assesses the specified metric of interest, and compares each sub-sample to the original sample in terms of the rank order correlation (Spearman's $\rho$) among nodes for the metric in question. We have attempted to write this function to be as general as possible so that you can modify it and use it to meet your own needs in your own research. In subsequent steps in this document we will modify this basic function to assess different data perturbations.

### Nodes Missing at Random

First, following Chapter 5.3.1, we will assess the robustness of these data to nodes missing at random for betweenness centrality.

The "nodes_missing_at_random_bw" function below requires three specific pieces of information from the user.

* net - You must include a network object in igraph format. The current version expects a simple network but the code could be modified for other types.
* nsim - You must specify the number of simulations to perform. The default is 1000.
* props - Finally, you must specify the proportion of nodes to be retained for each set of nsim runs. This should be provided as a vector of proportions ranging from > 0 to 1. By default, the script will calculate a 90% sub-sample all the way down to a 10% sub-sample at 10% intervals using props=c(0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1).

As we said, this function is designed to assess betweenness centrality but if you wish to assess another network metric, you simply need to modify the code in two places as marked below. Let's initialize the script then take a look at the example from the book first using betweenness centrality and then modifying the code for eigenvector centrality. Note that depending on the size of your network and the number of simulations you specify, this could take from several seconds to several minutes. 

To briefly describe how this works, the inner portion of this function contains two nested "for" loops which iterate across all values of "props" and for every simulation 1 to "nsim". The "sub_samp" object is a vector of random integers based on node ids that determine which nodes will be retained. The "sub_net" object is a subset of the larger graph which includes only those nodes indicated in "sub_samp." Next, we then calculate betweenness centrality for the "sub_net" object and create a vector of those values called "temp_stats." Finally, we compare rank order correlation of centrality scores in the "temp_stats" to the "met_orig" which is the vector of values in the original network and add to the output matrix. Once we run the script we can visualize the results.

```{r, warning=F, message=F}
# Function for assessing the impact of nodes missing at random on betweenness centrality
nodes_missing_at_random_bw <- function(net, nsim=1000, props=c(0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1)) {
  met_orig <- igraph::betweenness(net) # insert measure of interest here
  output <- matrix(NA,nsim,length(props))
  colnames(output) <- as.character(props)
    for (j in 1:length(props)) {
      for (i in 1:nsim) {
        sub_samp <- sample(seq(1,vcount(net)), size=round(vcount(net)*props[j], 0))
        sub_net <- igraph::induced_subgraph(net, sort(sub_samp))
        temp_stats <- igraph::betweenness(sub_net) # insert measure of interest here (same as above)
        output[i,j] <- suppressWarnings(cor(temp_stats, met_orig[sort(sub_samp)], method='spearman'))
      }
    }
  return(output)
}

# Run the function
set.seed(4561)
bw_test <- nodes_missing_at_random_bw(net=chaco_net, nsim=1000, props=c(0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1))

# visuzlize the results as a boxplot using ggplot
df <- melt(as.data.frame(bw_test)) # melt wide data format into long data format

ggplot(data=df) +
  geom_boxplot(aes(x=variable, y=value)) +
  xlab("Sub-Sample Size as Proportion of Original") +
  ylab(expression("Spearman's"~rho)) +
    theme_bw() +
  theme(axis.text.x=element_text(size=rel(2)),axis.text.y=element_text(size=rel(2)),
        axis.title.x = element_text(size=rel(2)),axis.title.y = element_text(size=rel(2)),
        legend.text = element_text(size=rel(1)))
```

Now let's run the same function for eigenvector centrality, this time using the default arguments in the function we created rather than calling them directly. Note that we modified two lines of code to change igraph::betweenness(net) to igraph::eign_centrality(net)$vector. Because the eigen_centrality function outputs more than just the centrality values, we need to include the vector call.

```{r, warning=F, message=F}
# Function for assessing the impact of nodes missing at random on betweenness centrality
nodes_missing_at_random_ev <- function(net, nsim=1000, props=c(0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1)) {
  met_orig <- igraph::eigen_centrality(net)$vector # insert measure of interest here
  output <- matrix(NA,nsim,length(props))
  colnames(output) <- as.character(props)
    for (j in 1:length(props)) {
      for (i in 1:nsim) {
        sub_samp <- sample(seq(1,vcount(net)), size=round(vcount(net)*props[j], 0))
        sub_net <- igraph::induced_subgraph(net, sort(sub_samp))
        temp_stats <- igraph::eigen_centrality(sub_net)$vector # insert measure of interest here (same as above)
        output[i,j] <- suppressWarnings(cor(temp_stats, met_orig[sort(sub_samp)], method='spearman'))
      }
    }
  return(output)
}

# Run the function
set.seed(5609)
ev_test <- nodes_missing_at_random_ev(net=chaco_net)

# visuzlize the results as a boxplot
df <- melt(as.data.frame(ev_test)) # melt wide data format into long data format

ggplot(data=df) +
  geom_boxplot(aes(x=variable, y=value)) +
  xlab("Sub-Sample Size as Proportion of Original") +
  ylab(expression("Spearman's"~rho)) +
    theme_bw() +
  theme(axis.text.x=element_text(size=rel(2)),axis.text.y=element_text(size=rel(2)),
        axis.title.x = element_text(size=rel(2)),axis.title.y = element_text(size=rel(2)),
        legend.text = element_text(size=rel(1)))
```

### Edges Missing at Random

We can also modify the function we defined above a little more to assess the impacts of edges missing at random. In this case we assess the impact of edges missing at random on degree centrality. We changed the same two lines "met_orig" and "temp_stats" to calculate degree and we also had to slightly change the lines beginning with "sub_samp," "sub_net," and "output[i,j]" to expect variation in edges rather than nodes. Specifically, in the line that starts with "sub_samp" we change "vcount" to "ecount" to get a sample of edges rather than nodes (vertices). In the next line we use that "sub_samp" object to "delete_edges" for all not in that sub sample. Finally, we remove the brackets after "met_orig" since all nodes are retained in this example. 

```{r, warning=F, message=F}
# Function for assessing the impact of edges missing at random on degree centrality
edges_missing_at_random_dg <- function(net, nsim=1000, props=c(0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1)) {
  met_orig <- igraph::degree(net) # insert measure of interest here
  output <- matrix(NA,nsim,length(props))
  colnames(output) <- as.character(props)
    for (j in 1:length(props)) {
      for (i in 1:nsim) {
        sub_samp <- sample(seq(1,ecount(net)), size=round(ecount(net)*props[j], 0)) # modify for edges
        sub_net <- igraph::delete_edges(net, which(!(seq(1,ecount(net)) %in% sub_samp))) # modify for edges
        temp_stats <- igraph::degree(sub_net) # insert measure of interest here (same as above)
        output[i,j] <- suppressWarnings(cor(temp_stats, met_orig, method='spearman')) # modify for edges
      }
    }
  return(output)
}

# Run the function
set.seed(5609)
dg_edge_test <- edges_missing_at_random_dg(net=chaco_net)

# visuzlize the results as a boxplot
df <- melt(as.data.frame(dg_edge_test)) # melt wide data format into long data format

ggplot(data=df) +
  geom_boxplot(aes(x=variable, y=value)) +
  xlab("Sub-Sample Size as Proportion of Original") +
  ylab(expression("Spearman's"~rho)) +
    theme_bw() +
  theme(axis.text.x=element_text(size=rel(2)),axis.text.y=element_text(size=rel(2)),
        axis.title.x = element_text(size=rel(2)),axis.title.y = element_text(size=rel(2)),
        legend.text = element_text(size=rel(1)))
```

## Assessing Indivdiual Nodes/Edges

This sub-section follows along with Chapter 5.3.2 in Brughmans and Peeples (2022). Here we will once again use the Cibola technological similarity network to make this assessment. This script is similar to that used above but instead of outputting correlation coefficients it outputs the specific rank order of the node in question.

The function requires four pieces of information from the user:

* net - An igraph network object. Again this is currently set up for simple networks but could easily be modified.
* target - The name of the target node you wish to assess
* prop - The proportion of nodes you wish to retain in the test.
* nsim - The number of simulations. The default is 1000.

Briefly how this function works is it first determines which node number corresponds with the "target" you wish to assess and creates a sub_sample that retains that target node. A subgraph is then induced (sub_net) and the metric of interest is calculated (betweenness in this case). The "output" object is a vector that records the specific rank order that the node in question fell in in terms of the metric in question. 

[Use these data](data/Cibola_edgelist.csv) to follow along.

```{r, warning=F, message=F}
# Read in edgelist file as dataframe and create network object
Cibola_edgelist <- read.csv(file="data/Cibola_edgelist.csv", header=TRUE) 
Cibola_net <- igraph::graph_from_edgelist(as.matrix(Cibola_edgelist), directed=FALSE)

# Function for assessing the impact of rank order correlation in betweenness centrality to nodes missing at random
individual_nodes_bw <- function(net, target, prop, nsim=1000) {
  output <- NULL
  for (i in 1:nsim) {
  target_number <- which(V(net)$name == target)
  sub_samp <- sample(setdiff(1:vcount(net),target_number), size=round(vcount(net)* (1-prop), 0)) 
  sub_net <- igraph::induced_subgraph(net, sort(setdiff(1:vcount(net),sub_samp))) 
  temp_stats <- igraph::betweenness(sub_net)
  output[i] <- which(names(sort(temp_stats, decreasing=TRUE))==target)
  }
  return(output)
}

# Run the function
set.seed(52793)
GR <- individual_nodes_bw(net=Cibola_net, target="Garcia Ranch", prop=0.8, nsim=1000)

# Visualize the results
df <- as.data.frame(GR)
colnames(df) <- "RankOrder"

ggplot(df, aes(x=RankOrder)) + 
  geom_bar() + 
  theme_bw() +
  labs(title=" ", x ="Rank Order", y = "Count")+
  theme(axis.text.x=element_text(size=rel(2)),axis.text.y=element_text(size=rel(2)),
        axis.title.x = element_text(size=rel(2)),axis.title.y = element_text(size=rel(2)))

```

## Missing Due to Biased Sampling

This sub-section follows along with Brughmans and Peeples (2022) Chapter 5.3.3. There are many situations where we are interested in modeling situations where the data that are missing are not missing at random but instead are influenced by some biased sampling process. For example, say we have a study area where there have been lots of general reconnaissance surveys that have recorded most of the large sites but few full coverage surveys that have captured smaller sites. In that case, we may wish to model missingness such that small sites would more likely be missing than large sites.

We illustrate this approach using the co-authorship network example presented in the book. In this case we start with an incidence matrix of publications and authors and we want to assess the potential impact of missing data. Since we gathered these data from digital repositories and citations, it is likely that we are missing some publication and it is reasonable to assume that we would be more likely to miss older publications than newer ones given the inclusion of newer publications in searchable digital indexes. Thus, in this example we want to assess missingness such that newer publications are more likely to be retained than older ones in our sample. We compare this to missing at random to assess how these results relate to one another. 

First we need to provide two data files. The first is the [bibliographic attribute data](data/biblio_attr.csv) which includes date, publication type, and other information on each publication designated by a unique identifier. The second is an [incidence matrix](data/biblio_dat.csv) of publications denoted by unique identifier and authors. We read this into R and then create an adjaceny matrix of author to author connections using matrix algebra, convert it into a igraph network object and then calculate betweenness centrality for all nodes. We then provide a simple network node link diagram to visualize these data.

```{r, warning=F, message=F}

# Read in publication and author attribute data
bib <- read.csv('data/biblio_attr.csv')
# Read in incidence matrix of publication and author data 
bib_dat <- as.matrix(read.csv('data/biblio_dat.csv',header=T,row.names=1))
# Create adjacency matrix from incidence matrix using matrix algebra
bib_adj <- t(bib_dat) %*% bib_dat
# Convert to igraph network object removing self loops (diag=FALSE)
bib_net <- igraph::graph_from_adjacency_matrix(bib_adj, mode="undirected", diag=FALSE)
# Calculate Betweenness Centrality
bw_all <- igraph::betweenness(bib_net)
  
# Plot network with nodes scaled based on betweenness
set.seed(346)
ggraph(bib_net, layout = "fr") +
  geom_edge_link0(width = 0.2) +
  geom_node_point(shape = 21, aes(size = bw_all*5), fill='gray', alpha=0.75) +
  theme_graph()+
  theme(legend.position = "none")
```

With these network objects created we then need to modify our "nodes_missing_at_random_bw" function from above to the specific nature of our question and these data. Indeed since our example here relies on an incidence matrix that includes information defined across multiple publications, we have to me additional changes to the structure of that function. 

We create a "nodes_missing_biased_bw" function below that requires five specific pieces of information from the user.

* net - You must include a network object in igraph format. The current version expects a simple network but the code could be modified for other types.
* inc - You must also include an incidence matrix (as an R matrix object) which describes the relationships between publications and authors
* nsim - You must specify the number of simulations to perform. The default is 1000.
* props - Finally, you must specify the proportion of nodes to be retained for each set of nsim runs. This should be provided as a vector of proportions ranging from > 0 to 1. By default, the script will calculate a 90% sub-sample all the way down to a 10% sub-sample at 10% intervals using props=c(0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1).
* lookup_dat - Finally, you must provide the lookup data which connects the publication key code to the year as that is the basis of our simulation. Note that this function is designed to work with a lookup file that has column names exactly as shown here ("Publication.Year", "prob", "Key") and this would need to be modified to work with data with different columns.

The first step is to create a new column in the lookup file called "prob" that defines the probability that a node will be retained in each random sub-sample. To do this we simply take the vector of publication years and rescale them such that the maximum value (most recent publication) equals 1 and older publications are less than 1. This will mean that older publications will more often be removed in our random sub-samples than newer ones.

```{r, warning=F, message=F}
# Create a dataframe of all unique combinations of publication code and year from attributes data
lookup <- unique(bib[,c(1,4)])
# Assign a probability for a publication to be retained inverse to the year it was published
lookup$prob <- (lookup$Publication.Year-min(lookup$Publication.Year))/
                (max(lookup$Publication.Year)-min(lookup$Publication.Year))
head(lookup)
```

Next we create a function that wraps all of this together. This is similar to the "nodes_missing_at_random_bw" function with a few key differences. Specifically:

* The line starting with "sub_samp" includes an additional argument "prob" which is assigned to the probability variable we created in the last step such that higher probability (newer) publications will be more likely to be retained.
* Next, since the network of co-authorship includes connections that could be made by more than one publication we actually need to sub-sample from the incidence matrix. The line begining with "sub" finds all publications that were retained in the "sub_samp" object.
* Next we convert "sub" to an adjacency matrix called "sub_adj" using matrix algebra and then a network object called "sub_net"
* Finally, we calculate betweenness centrality and rank order correlations and put the results in the output object.

Here we are going to run the function for nsim=1000 and for 3 sampling fractions (0.9, 0.8, 0.7).

```{r, warning=F, message=F}
# Function for assessing the impact of data missing due to biased process on betweenness centrality
nodes_missing_biased_bw <- function(net, inc, nsim=1000, props=c(0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1), lookup_dat) {
  met_orig <- igraph::betweenness(net) # insert measure of interest here
  output <- matrix(NA,nsim,length(props))
  colnames(output) <- as.character(props)
    for (j in 1:length(props)) {
      for (i in 1:nsim) {
        sub_samp <- sample(seq(1,nrow(lookup_dat)), size=round(nrow(lookup_dat)*props[j], 0), prob=lookup_dat$prob) # added prob argument
        sub <- which(rownames(bib_dat) %in% lookup$Key[sub_samp]) 
        sub_adj <- t(inc[sub,]) %*% inc[sub,]
        sub_net <- igraph::graph_from_adjacency_matrix(sub_adj)
        temp_stats <- igraph::betweenness(sub_net) # insert measure of interest here (same as above)
        output[i,j] <- suppressWarnings(cor(temp_stats, met_orig, method='spearman'))
      }
    }
  return(output)
}

# Run fuction
set.seed(4634)
bib_bias <- nodes_missing_biased_bw(net=bib_net, inc=bib_dat, lookup_dat=lookup, props=c(0.9,0.8,0.7))
head(bib_bias)
```

With this in place, we now need a function that deals with our incidence matrix data but simulates missigness at random. This only requires a single argument to change from our last function. Specifically, all we need to do is remove the "prob=lookup_dat$prob" argument from the line beginning with "sub_samp" and we're ready to go.

```{r, warning=F, message=F}
# Function for assessing the impact of nodes missing at random on betweenness centrality
nodes_missing_at_random_inc_bw <- function(net, inc, nsim=1000, props=c(0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1), lookup_dat) {
  met_orig <- igraph::betweenness(net) # insert measure of interest here
  output <- matrix(NA,nsim,length(props))
  colnames(output) <- as.character(props)
    for (j in 1:length(props)) {
      for (i in 1:nsim) {
        sub_samp <- sample(seq(1,nrow(lookup_dat)), size=round(nrow(lookup_dat)*props[j], 0)) # removed prob argument
        sub <- which(rownames(bib_dat) %in% lookup$Key[sub_samp])
        sub_adj <- t(inc[sub,]) %*% inc[sub,]
        sub_net <- igraph::graph_from_adjacency_matrix(sub_adj)
        temp_stats <- igraph::betweenness(sub_net) # insert measure of interest here (same as above)
        output[i,j] <- suppressWarnings(cor(temp_stats, met_orig, method='spearman'))
      }
    }
  return(output)
}

# Run the function
set.seed(4363)
bib_rand <- nodes_missing_at_random_inc_bw(net=bib_net, inc=bib_dat, lookup_dat=lookup, props=c(0.9,0.8,0.7))
head(bib_rand)
```

Now we can combine the results into a single dataframe and plot them as paired boxplots for comparison. 

```{r}
df1 <- melt(bib_rand) # convert wide data to long format
df2 <- melt(bib_bias) # convert wide data to long format

# Add a variable denoting which sample it came from
df1$Treatment <- rep("Random", nrow(df1))
df2$Treatment <- rep("Biased", nrow(df2))

# Bind into a single dataframe, convert sampling faction to factor and change order of levels for plotting
df <- rbind(df1,df2)
df$Var2 <- as.factor(df$Var2)
df$Var2 <- factor(df$Var2, levels = c("0.9", "0.8", "0.7"))

# Plot the results
ggplot(data=df) +
  geom_boxplot(aes(x=Var2, y=value, fill=Treatment)) +
  scale_fill_manual(values=c("white", "gray")) +
  xlab("Sub-Sample Size as Proportion of Original") +
  ylab(expression("Spearman's"~rho)) +
  theme_bw() +
  theme(axis.text.x=element_text(size=rel(2)),axis.text.y=element_text(size=rel(2)),
        axis.title.x = element_text(size=rel(2)),axis.title.y = element_text(size=rel(2)),
        legend.text = element_text(size=rel(2)))


```

## Edge Probability Modeling

In this section we take inspiration from some recent work in the area of "Dark Networks" (see Everton 2012). In this field, a number of methods have recently been developed that allow us to more directly incorporate our assessments of the reliability of specific edges into our analysis. This can be done in a number of different ways. Perhaps the most common approach for networks based on data gathered from intelligence sources (such as studies of terrorist networks) is to qualitatively assign different levels of confidence to ties between pairs of actors using an ordinal scale determined based on the source of the information (reliable, usually reliable,... unreliable). This ordinal scale of confidence can then be converted into a probability (from 0 to 1) and that probability value could be used to inform the creation of a range of "possible" networks given the underlying data.

We are not aware of any archaeological examples where edges have been formally/qualitatively assigned "confidence levels" in exactly this way, but we think there are potential applications of this method. For example, we could define a network where we assign a low probability of a tie between two archaeological sites if they share an import from a third site/region and a higher probability for a tie between two sites if they share imports from each others region. Importantly, such methods can be used to combine information from different sources into a single assessment of the likelihood of connection. 

Since we do not have any data structured in exactly this way, we will again simulate a small example and then analyze it. Let's create a network with ties associated with "probabilities" and the plot it. We use the "rg_w" function within the tnet package to simulate a random weighted network in this way.


```{r, warning=F, message=F, fig.height=6,fig.width=6}
# Create random weighted network edgelist with weights from list
sim_edge <- as.matrix(rg_w(nodes=20,arcs=80,weights=c(0.2,0.4,0.6,0.8,1),directed=F,seed=41267))

# Create network object and assign edge weights and node names
sim_net <- igraph:: graph_from_edgelist(sim_edge[,1:2])
E(sim_net)$weight <- sim_edge[order(sim_edge[,3]),3]
V(sim_net)$name <- seq(1:20)

# Create color ramp palette
edge_cols <- colorRampPalette(c('gray','darkblue'))(5)

# Plot the resulting network
set.seed(4364672)
ggraph(sim_net, layout = "fr") +
  geom_edge_link0(aes(width = E(sim_net)$weight*5), edge_colour=edge_cols[E(sim_net)$weight*5], show.legend=F) +
  geom_node_point(shape = 21, size=igraph::degree(sim_net)+3, fill='red') +
  geom_node_text(aes(label = as.character(name)), col='white', size=3.5, repel=F) +
  theme_graph()
```

In the next chunk of code we define a function that iterates over every edge in the simulated network we just created and defines each edge as either present or absent using a simple random binomial with the probability set by the edge weight as described above. The output of this function (edge_liklihood) is a list object that contains "nsim" igraph network objects that are candidate networks of the original.

Next, in order to extract values of interest from these candidate networks, we created another function called "compile_stat" that could be modified for any measure of interest. This function iterates over all "nsim" networks in the "net_list" list object and calculates "degree" in this case returning the results as a simple matrix. It is then possible to compare things like average degree or the distribution of degree for particular nodes across all of the canddiate networks.

```{r}
# Define function for assessing and retaining edges based on edge weight probabilities
edge_prob <- function(net, nsim) {
  net_list <- list()
  for (i in 1:nsim) {
    sub_set <- NULL
    for (j in 1:ecount(net)) {
      temp <- rbinom(1,1,prob=sim_edge[j,3])
      if (temp==1) {sub_set <- c(sub_set,j)}
    }
    net_list[[i]] <- igraph::delete_edges(net, which(!(seq(1,ecount(net)) %in% sub_set)))
  }
  return(net_list)
}

# Define function for assessing statistic of interest
compile_stat <- function(net_list, nsim) {
  out <- matrix(NA,length(net_list),nsim)
  for (i in 1:nsim) {
  out[,i] <- igraph::degree(net_list[[i]])} # degree could be changed to any other igraph function that outputs a vector of length vcount
  return(out)
}

```

Now we run the edge_prob function for nsim=1000 and display a few candidate networks. 

```{r, fig.width=8, fig.height=8}
EL_test <- edge_prob(sim_net, nsim=1000)

set.seed(9651)
comp1 <- ggraph(EL_test[[1]], layout = "fr") +
  geom_edge_link0(aes(width = E(EL_test[[1]])$weight), edge_colour=edge_cols[E(EL_test[[1]])$weight*5], show.legend=F) +
  geom_node_point(shape = 21, size=igraph::degree(sim_net), fill='red') +
  geom_node_text(aes(label = as.character(name)), col='white', size=2.5, repel=F) +
  theme_graph()

comp2 <- ggraph(EL_test[[2]], layout = "fr") +
  geom_edge_link0(aes(width = E(EL_test[[2]])$weight), edge_colour=edge_cols[E(EL_test[[2]])$weight*5], show.legend=F) +
  geom_node_point(shape = 21, size=igraph::degree(sim_net), fill='red') +
  geom_node_text(aes(label = as.character(name)), col='white', size=2.5, repel=F) +
  theme_graph()

comp3 <- ggraph(EL_test[[3]], layout = "fr") +
  geom_edge_link0(aes(width = E(EL_test[[3]])$weight), edge_colour=edge_cols[E(EL_test[[3]])$weight*5], show.legend=F) +
  geom_node_point(shape = 21, size=igraph::degree(sim_net), fill='red') +
  geom_node_text(aes(label = as.character(name)), col='white', size=2.5, repel=F) +
  theme_graph()

ggarrange(comp1, comp2, comp3)
```

We then use the compile_stat function to assess degree centrality for one particular node, displaying a histogram of values with mean indicated.

```{r}
dg_stat <- compile_stat(EL_test, nsim=1000)

dg_20 <- dg_stat[20,]

tibble(val = dg_20) %>%
          ggplot(., aes(val)) + 
                geom_histogram(binwidth = 1) +
                xlab("Degree Centrality of Node 20") +
                geom_vline(xintercept = mean(dg_20), col='red')
```

## Small or Variable Sample Size

This section follows Brughmans and Peeples (2022) Chapter 5.3.5 to provide an example of how you can use the simulation approach outlined here to assess sampling variability in the data underlying archaeological networks. In this example, we use apportioned ceramic frequency data from the Chaco World portion of the Southwest Social Networks database. You can [download the data here](data/AD1050cer.csv) to follow along.

The goal of this sub-section is to illustrate how you can use a bootstrappping approach to assess variability in network properties based on sampling error in the raw data underlying archaeological networks. In our example based on ceramic similarity networks here this involves creating a large number of random replicates of each row of our raw ceramic data with sample size held constant (as the observed sample size for that site) and with the probabilities that a given sherd will be a given type determined by the underlying multinomial frequency distribition of types at that site. In other words, we pull a bunch of random samples from the site with the probability that a given sample is a given type determined by the relative frequency of that type in the actual data. Once this procedure has been completed, we can then assess centrality metrics or any other graph, node, or edge level property and determine the degree to which absolute values and relative ranks are potentially influenced by sampling error.

There are many ways to set up such a resampling procedure and many complications (for example, how do we deal with limited diversity of small samples?). For the purposes of illustration here, we will implement a very simple procedure where we simply generate new samples of a fixed size based on our observed data and determine the degree to which our network measures are robust to this perturbation. In the chunk of code below we create 1000 replicates based on our original ceramic data.

The following chunk of code first reads in the ceramic data, converts it to a Brainerd-Robinson similarity matrix and then defines a function called "sampling_error_sim" which creates "nsim" random replciates of the ceramic data, converts them to similarity matrices, and ouputs those results as a list object.

```{r}
# Read in raw ceramic data 
ceramic <- read.csv(file="data/AD1050cer.csv", header=TRUE, row.names=1)
# Convert to proportion
ceramic_p <- prop.table(as.matrix(ceramic), margin = 1) 
# Convert to Brainerd-Robinson similarity matrix
ceramic_BR <- (2-as.matrix(vegan::vegdist(ceramic_p, method='manhattan')))/2

# Create function for assessing impact of sampling error on weighted degree for similarity network
sampling_error_sim <- function(cer, nsim=1000) {
    sim_list <- list()
    for (i in 1:nsim) {
    data_sim <-  NULL
      # the for-loop below creates a random multinomial replicate of the ceramic data
      for (j in 1:nrow(cer)) {
        data_sim <- rbind(data_sim,t(rmultinom(1,rowSums(cer)[j],prob=cer[j,])))
      }
    # Convert simulated data to proportion, create similarity matrix, calculate degree, and assess correlation
    temp_p <- prop.table(as.matrix(data_sim), margin=1)
    sim_list[[i]] <- (2-as.matrix(vegan::vegdist(temp_p, method='manhattan')))/2
    }
  return(sim_list)
}
```

The following chunk of code runs the "sampling_error_sim" function defined above for our Chaco ceramic data and then defines a new fucntion called "sim_cor" which takes the output of "sampling_error_sim" and the original ceramic similarity matrix (ceramic_BR) and calculates weighted degree centrality and the Speraman's $\rho$ correlations between the original similarity matrix and each random replicate. This "sim_cor" script could be modified to use any network metric that outputs a vector. Once these results are returned we visualize the results as a histogram.

Note that this could take several seconds to a few minutes depending on your computer.

```{r, warning=F, message=F}
set.seed(4634)
sim_nets <- sampling_error_sim(cer=ceramic, nsim=1000)

sim_cor <- function(sim_nets, sim) {
  dg_orig <- rowSums(sim) # change this line to use a different metric
  dg_cor <- NULL
  for (i in 1:length(sim_nets)) {
    dg_temp <- rowSums(sim_nets[[i]]) # change this line to use a different metric
    dg_cor[i] <- suppressWarnings(cor(dg_orig, dg_temp, method="spearman"))
  }
  return(dg_cor)
}

dg_cor <- sim_cor(sim_nets, ceramic_BR)

df <- as.data.frame(dg_cor)

ggplot(df, aes(x=dg_cor)) +
  geom_histogram(bins=100, color='white',fill='black') +
  theme_bw() + 
  scale_x_continuous(name='Correlation in Degree Centraility',limits=c(0.9,1)) +
  theme(axis.text.x=element_text(size=rel(1.5)),axis.text.y=element_text(size=rel(1.5)),
        axis.title.x = element_text(size=rel(1.5)),axis.title.y = element_text(size=rel(1.5)),
        legend.text = element_text(size=rel(1.5)))
```

As described in Chapter 5.3.5, in some cases we want to observe patterns of variation due to sampling error for individual sites or sets of sites. In the next chunk of code we illustrate how to produce figure 5.14 from the Brughmans and Peeples (2022) book. Specifically, this plot consists of a series of line plots where the x axis represents each node in the network ordered by degree centrality in the original observed network. For each node there is a vertical line which represents the 95% confidence interval around degree across the "nsim" random replicates produced to evaluate sampling error. The blue line represents degree in the original network and the red line represents median degree in the resampled networks.

To create this plot, we first iterate through every object in "sim_nets" and calculate weighted degree centrality and then add that to a two-column matrix along with a node id. Once we have done this for all simulations, we use the "summarise" function to calculate the Mean and 


```{r, warning=F, message=F}
# Create data frame containing degree and site id for nsim random similarity matrices
df <- matrix(NA,1,2) # define empty matrix
# calculate degree centrality for each random run and bind in matrix along with id
for(i in 1:length(sim_nets)) {
  temp <- cbind(seq(1,nrow(sim_nets[[i]])),rowSums(sim_nets[[i]]))
  df <- rbind(df,temp)
}
df <- as.data.frame(df[-1,]) # remove first row in initial matrix
colnames(df) <- c("site", "degree") # add column names

# Use summarise function to create median, confidence intervals, and other statistics for degree by site.
out <- df%>%
  group_by(site)%>% 
  summarise(Mean=mean(degree), Median=median(degree), Max=max(degree), Min=min(degree), Conf=sd(degree)*1.96) 
out$site <- as.numeric(out$site)
out <- out[order(rowSums(ceramic_BR)),]

# Create dataframe of degree centrality for the original ceramic similarity matrix
dg_wt <- as.data.frame(rowSums(ceramic_BR))
colnames(dg_wt) <- "dg.wt"

# Plot the results
ggplot() +
  geom_line(data=out, aes(x=reorder(site,Median), y=Median, group=1), col='red', lwd=1.5, alpha=0.5) +
  geom_errorbar(data=out, aes(x = reorder(site,Median), ymin = Median-Conf, ymax = Median+Conf)) +
  geom_path(data=sort(dg_wt), aes(x=order(dg.wt), y=dg.wt), col='blue', lwd=1.5, alpha=0.5) +
   theme_bw() +
  ylab('Degree') +
  scale_x_discrete(name='Sites in Rank Order of Degree') +
  theme(axis.text.x=element_blank(),axis.ticks.x=element_blank(), axis.text.y=element_text(size=rel(2)),
        axis.title.x = element_text(size=rel(2)),axis.title.y = element_text(size=rel(2)),
        legend.text = element_text(size=rel(2)))
```



<!--chapter:end:04-uncertainty.Rmd-->

# Network Visualization

This section follows along with Brughmans and Peeples (2022) chapter 6 to illustrate the wide variety of techniques which can be used for network visualization. We begin with some general examples of network plotting and then demonstrate how to replicate all of the specific examples that appear in the book. For most of the examples below we rely on R but in a few cases we use other software and provide additional details and data formats. 

There are already some excellent resources online for learning how to create beautiful and informative network visuals. We recommend the excellent online materials produced by Dr. Katherine Ognyanova [available on her website](https://kateto.net/) and her [Static and dynamic network visualization with R](https://kateto.net/network-visualization) workshop materials in particular. Many of the examples here and in the book take inspiration from her work. In addition to this, the [R Graph Gallery](https://www.r-graph-gallery.com/) website created by [Holtz Yan](https://github.com/holtzy) provides numerous excellent examples of plots in R using the ggplot2 and ggraph packages among many others. If you are new to R, it will probably be helpful for you to read a bit about basic graphic functions (including in the tutorials listed here) before getting started.

## Datasets and R Setup

In order to make it as easy as possible for users to replicate specific visuals from the book and the other examples in this tutorial we have tried to make the examples as modular as possible. This means that we provide calls to initialize the required libraries for each plot within each relevant chunk of code (so that you can more easily tell what package does what) and we also provide links to download the data required to replicate each figure in the description of that figure below. The datasets we use here include both .csv and other format files as well as .Rdata files that contain sets of specific R objects formatted as required for individual chunks of code.

If you plan on working through this entire tutorial and would like to download all of the associated data at once [you can download this zip file](All_data.zip). Simply extract this zip folder into your R working directory and the examples below will then work. Note that all of the examples below are setup such that the data should be contained in a sub-folder of your working directory called "data" (note that directories and file names are case sensitive).

## Visualizing Networks in R

There are many tools available for creating network visualizations in R including functions built directly into the igraph and statnet packages. Before we get into the details, we first briefly illustrate the primary network plotting options for igraph statnet and a visualization package called ggraph. We start here by initializing our required libraries and reading in an adjacency matrix and creating network objects in both the igraph and network/statnet format. These will be the basis for all examples in this section.

```{r Chapter6_read_data, warning=F, message=F}
library(igraph)
library(statnet)
library(ggraph)
library(intergraph)

Cibola <- read.csv(file="data/Cibola_adj.csv", header=TRUE, row.names=1)
Cibola_attr <- read.csv(file="data/Cibola_attr.csv", header=TRUE)

# Create network in igraph format
Cibola_i <- igraph::graph_from_adjacency_matrix(as.matrix(Cibola), mode="undirected")
Cibola_i

# Create network object in statnet/network format
Cibola_n <- asNetwork(Cibola_i)
Cibola_n
```

### network/statnet

All you need to do to plot a network/statnet network object is to simply type plot(nameofnetwork). By default, this creates a network plot where all nodes and edges are shown the same color and weight using the Fruchterman-Reingold graph layout by default. There are, however, many options that can be altered for this basic plot. In order to see the details you can type ?plot.network at the console for the associated document. 

```{r Fig_net_simple}
set.seed(6332)
plot(Cibola_n)
```

In order to change the color of nodes, the layout, symbols, or any other features, you can add arguments as detailed in the help document. These arguments can include calls to other functions, mathematical expressions, or even additional data in other attribute files. For example in the following plot, we calculate degree centrality directly within the plot call and then divide the result by 10 to ensure that the nodes are a reasonable size in the plot. We use the "vertex.cex" argument to set node size based on the results of that expression. Further we change the layout using the "mode" argument to produce a network graph using the Kamada-Kawai layout. We change the color of the nodes so that they represent the "Region" variable in the associated attribute file using the "vertex.col" argument and and set change all edge colors using the "edge.col" argument. Finally, we use "displayisolates=FALSE" to indicate that we do not want the single isolated node to be plotted. These are but a few of the many options.

```{r Fig_network_net}
set.seed(436)
plot(Cibola_n, vertex.cex=sna::degree(Cibola_n)/10, mode="kamadakawai", 
     vertex.col=as.factor(Cibola_attr$Region), edge.col="darkgray", displayisolates=FALSE)
```

### igraph

The igraph package also has a built in plotting function called plot.igraph. To call this you again just need to type plot(yournetworkhere) and provide an igraph object (R can tell what kind of object you have if you simply type plot). The default igraph plot again uses a Fruchterman-Reingold layout just like statnet/network but by default each node is labeled. 

```{r Fig_igraph_simple}
set.seed(435)
plot(Cibola_i)
```

Let's take a look at a few of the options we can alter to change this plot. There are again many options to explore here and the help documents for igraph.plotting describe them in detail (type ?igraph.plotting at the console for more). If you want to explore igraph further, we suggest you check the [Network Visualization](https://kateto.net/network-visualization) tutorial linked above which provides a discussion of the wide variety of options. 

```{r Fig_igraph}
set.seed(3463)
plot(Cibola_i, vertex.size=igraph::eigen_centrality(Cibola_i)$vector*20, layout=layout_with_kk,
     vertex.color=as.factor(Cibola_attr$Great.Kiva), edge.color="darkblue", vertex.frame.color="red", vertex.label=NA)
```

### ggraph

The ggraph package provides a powerful set of tools for plotting and visualizing network data in R. The format used for this package is a bit different from what we saw above and instead relies on the ggplot2 style of plots where a plot type is called and modifications are made with sets of lines with additional arguments separated by "+". Although this takes a bit of getting used to we have found that the ggplot format is often more intuitive for making complex graphics once you understand the basics.

Essentially, the way the ggraph call works is you start with a ggraph function call which includes the network object and the layout information. You then provide lines specifying the edges "geom_edge_link" and nodes "geom_node_point" features and so on. Conveniently the ggraph function call will take either an igraph or a network/statnet object so you do not need to convert.

Here is an example. Here we first the call for the igraph network object "Cibola_i" and specify the Fruchterman-Reingold layout using layout="fr". Next, we call the "geom_edge_link" and specify edge colors. The "geom_node_point" call then specifies many attributes of the nodes including the fill color, outline color, transparency (alpha), shape, and size using the igraph::degree function). The "scale_size" call then tells the plot to scale the node size specified in the previous line to range between 1 and 4. Finally "theme_graph" is a basic call to the ggraph theme that tells the plot to make the background white and to remove the margins around the edge of the plot. Let's see how this looks. 

In the next section we go over the most common options in ggraph in detail.

```{r Fig_ggraph}
set.seed(4368)
ggraph(Cibola_i, layout="fr") + # Specify network to use and layout
  geom_edge_link(color="darkgray") + # Specify edge features
  geom_node_point(fill="blue", color="red", alpha=0.5, shape = 22, size = igraph::degree(Cibola_i)) + # Specify node features
  scale_size(range=c(1,4)) + # Set the upper and lower limit of the "size" variable
  theme_graph() # Set the theme "theme_graph" is the default theme for networks
```

There are many options for the ggraph package and we recommend exploring the help document (?ggraph) as well as the [Data Imaginist](https://www.data-imaginist.com/tags/visualization) ggraph tutorial online for more. Most of the examples below will use the ggraph format.

## Network Visualization Options

In this section we illustrate some of the most useful graphical options for visualizing networks, focusing in particular on the ggraph format. In most cases there are similar options available in the plotting functions for both statnet and igraph. Where relevant we reference specific figures from the book and this tutorial and the code for all of the figures produced in R is presented in the next session. For all of the examples in this section we will use the [Cibola technological similarity data (click here to download)](data/Peeples2018.Rdata). First we call the required packages and import the data.

```{r graph_layout, message=F, warning=FALSE}

library(igraph)
library(statnet)
library(intergraph)
library(ggraph)

load("data/Peeples2018.Rdata")

# Create igraph object for plots below
net <- asIgraph(BRnet)

```

### Graph Layout

Graph layout simply refers to the placement and organization in 2-dimensional or 3-dimensional space of nodes and edges in a network. 

#### Manual or User Defined Layouts

There are a few options for manually defining node placement and graph layout in R and the easiest is to simply provide x and y coordinates directly. In this example, we plot the Cibola technological similarity network with a set of x and y coordinates that group sites in the same region in a grid configuration. For another example of this approach see [Figure 6.1 below](#Figure_6_1). For an example of how you can interactively define a layout see [Figure 6.5](#Figure_6_5) 

```{r manual_layout, fig.width=5, fig.height=5}
# site_info - site location and attribute data

# Create xy coordinates grouped by region
xy <- matrix(c(1,1,3,3,2,1,2,1.2,3,3.2,2,1.4,1,1.2,2,2.2,3,2,3,1,2.2,1,
             2,3,2,3.2,3,1.2,3,3.4,1,2,3.2,3.2,3,1.4,3,2.2,2,2,3.2,3.4,
             2.2,1.2,3.4,3.2,3.2,1,2,3.4,3.4,3.4,2.2,3,2.2,3.2,2.2,3.4,
             1,1.4,3,2.4), nrow=31, ncol=2, byrow=TRUE)

# Plot using "manual" layout and specify xy coordinates
ggraph(net, layout="manual",
       x=xy[,1], y=xy[,2]) +
  geom_edge_link(edge_color="gray") +
  geom_node_point(aes(size = 4,col=site_info$Region), show.legend = FALSE) +
  theme_graph()

```

#### Geographic Layouts

Plotting networks using a a geographic layout is essentially the same as plotting with a manual layout except that you specify geographic coordinates instead of other coordinates. See [Figure 6.2](#Figure_6_2) for another example.

```{r map1, fig.width=5, fig.height=5}
ggraph(net, layout="manual",
       x=site_info$x, y=site_info$y) +
  geom_edge_link(edge_color="gray") +
  geom_node_point(aes(size=4, col=site_info$Region), show.legend=F) +
  theme_graph()
```

When working with geographic data, it is also sometimes useful to plot directly on top of some sort of base map. There are many options for this but one of the most convenient is to use the "sf" and "ggmap" packages to directly download the relevant base map layer and plot directly on top of it. This first requires converting points to latitude and longitude in decimal degrees if they are not already in that format. See the details on the [sf package](https://r-spatial.github.io/sf/) and [ggmap package](https://github.com/dkahle/ggmap) for more details. In addition to this example [Figure 6.7 in the book](#Figure_6_7) provides another example.


```{r geo_layout, warning=F, message=F, fig.heigh=8, fig.width=8}
library(sf)
library(ggmap)

# Convert attribute location data to sf coordinates and change map projection
locations_sf <- st_as_sf(site_info, coords = c("x", "y"), crs = 26912)
loc_trans <- st_transform(locations_sf,crs=4326)
coord1 <- do.call(rbind, st_geometry(loc_trans)) %>% 
  tibble::as_tibble() %>% setNames(c("lon","lat"))

xy <- as.data.frame(coord1)
colnames(xy) <- c('x','y')

# Get basemap "terrain-background" data for map in black and white 
# the bbox argument is used to specify the corners of the box to be used and
# zoom determines the detail. 
base_cibola <- get_stamenmap(bbox=c(-110.2,33.4,-107.8,35.3),zoom=10,maptype="terrain-background",color="bw")

# Extract edgelist from network object
edgelist <- get.edgelist(net)

# Create dataframe of beginning and ending points of edges
edges <- data.frame(xy[edgelist[,1],], xy[edgelist[,2],])
colnames(edges) <- c("X1","Y1","X2","Y2")

# Plot original data on map
ggmap(base_cibola,darken=0.35) +
  geom_segment(data = edges, aes(x=X1, y=Y1, xend=X2, yend=Y2), col='white', alpha=0.8, size=1) +
  geom_point(data = xy,aes(x,y, col=site_info$Region), alpha=0.8, size=5, show.legend=F) +
  theme_void()
```

#### Shape-Based and Algorithmic Layouts

There are a wide variety of shape-based and algorithmic layouts available for use in R. In most cases, all it takes to change layouts is to simply modify a single line the ggraph call to specify our desired layout. The ggraph package can use any of the igraph layouts as well as many that are built directly into the package. See ?ggraph for more details and to see the options. Here we show a few examples. Note that we leave the figures calls the same except for the argument layout="yourlayout" in each ggraph call and the ggtitle name. For the layouts that involve randomization, we use the "set.seed()" function to make sure they will always plot the same. See the discussion of [Figure 6.8](#Figure_6_8) below for more details. Beyond this [Figure 6.9](#Figure_6_9) provides additional options that can be used for hierarchical network data.

```{r layouts, message=F, warning=F, fig.width=14, fig.height=5}
# circular layout
circ_net <- ggraph(net, layout="circle") +
  geom_edge_link(edge_color="gray") +
  geom_node_point(aes(size=4, col=site_info$Region), show.legend=F) +
  ggtitle("Circle") +
  theme_graph()

# Fruchcterman-Reingold layout
set.seed(4366)
fr_net <- ggraph(net, layout="fr") +
  geom_edge_link(edge_color="gray") +
  geom_node_point(aes(size=4, col=site_info$Region), show.legend=F) +
  ggtitle("Fruchterman-Reingold") +
  theme_graph()

# Davidsons and Harels annealing algorithm layout
set.seed(3467)
dh_net <- ggraph(net, layout="dh") +
  geom_edge_link(edge_color="gray") +
  geom_node_point(aes(size=4, col=site_info$Region), show.legend=F) +
  ggtitle("Davidson-Harel") +
  theme_graph()

library(ggpubr)
ggarrange(circ_net, fr_net, dh_net, nrow=1, ncol=3)

```

### Node and Edge Options

There are many options for altering color and symbol for nodes and edges within R. In this section we very briefly discuss some of the most common options. For more details see the discussion of [figures 6.10 through 6.16](#Figure_6_10) below.

#### Nodes

In ggraph changing node options mostly consists of changing options within the "geom_node_point" call within the ggraph figure call. As we have already seen it is possible to set color for all nodes or by some variable, to change the size of points, and we can also scale points by some metric like centrality. Indeed, it is even possible to make the call to the centrality function in question directly within the figure code. 

When selecting point shapes you can use any of the shapes available in base R using pch point codes. Here are all of the available options:

```{r pch_points, warning=F, message=F}
library(ggpubr)
ggpubr::show_point_shapes()
```

There are many options for selecting colors for nodes and edges. These can be assigned using standard color names or can be assigned using rgb or hex codes. It is also possible to use standard palettes in packages like RColorBrewer or scales to specify categorical or continuous color schemes. This is often done using either the "scale_fill_brewer" or "scale_color_brewer" calls from RColorBrewer. Here are a couple of examples. In these examples, colors are grouped by site region, node size is scaled to degree centrality, and node and edge color and shape are specified in each call. Note the "alpha" command which controls the transparency of the relevant part of the plot. The scale_size call specifies the maximum and minimum size of points in the plot.

The [R Graph Gallery](https://www.r-graph-gallery.com/38-rcolorbrewers-palettes.html) has a good overview of the available color palettes in RColorBrewer and when the can be used. 

```{r color_brewer, fig.width=12, fig.height=5, warning=F, message=F}
library(RColorBrewer)

set.seed(347)
g1 <- ggraph(net, layout = "kk") +
  geom_edge_link(edge_color="gray", alpha=0.7) +
  geom_node_point(aes(fill = site_info$Region), shape = 21, size = igraph::degree(net), alpha=0.5) +
  scale_size(range=c(1,3)) +
  scale_fill_brewer(palette = "Set2") +
  theme_graph()+
  theme(legend.position = "none")

set.seed(347)
g2 <- ggraph(net, layout = "kk") +
  geom_edge_link(edge_color="blue", alpha=0.3) +
  geom_node_point(aes(col = site_info$Region), shape = 15, size = igraph::degree(net), alpha=1) +
  scale_size(range=c(1,3)) +
  scale_color_brewer(palette = "Set1") +
  theme_graph()+
  theme(legend.position = "none")

ggarrange(g1, g2, nrow=1)
```

There are also a number of more advanced methods for displaying nodes including displaying figures or other data visualizations in the place of nodes or using images for nodes. There are examples of each of these in the book and code outlining how to create such visuals in the discussions of [Figure 6.3](#Figure_6_3) and [Figure 6.12](#Figure_6_12) below. 

#### Edges

Edges can be modified in terms of color, line type, thickness and many other features just like nodes and this is typically done using the "geom_edge_link" call within ggraph. Let's take a look at a couple of additional examples. In this case we're going to use a weighted network object in the original [Peeples2018.Rdata](data/Peeples2018.Rdata) file to show how we can vary edges in relation to edge attributes like weight. 

In the example here we plot both the line thickness and transparency using the edge weights associated with the network object. We also are using the "scale_edge_color_viridis" to specify a continuous edge color scheme. For more details see ?scale_edge_colour

```{r edge_options1, message=F, warning=F}
library(intergraph)
net2 <- asIgraph(BRnet_w)

set.seed(436)
ggraph(net2, "stress") +
  geom_edge_link(aes(width = weight, alpha= weight, col=weight)) +
  scale_edge_color_viridis() +
  scale_edge_width(range=c(1,5)) +
  geom_node_point(size=4, col="blue") +
  labs(edge_color="Edge Weight Color Scale") +
  theme_graph()
```

Another feature of edges that is often important in visualizations is the presence or absence and type of arrows. Arrows can be modified in ggraph using the "arrow" argument within a "geom_edge_link" call. The most relevant options are the length of the arrow (which determines size), the "type" argument which specifies an open or closed arrow, and the spacing of the arrow which can be set by the "end_cap" and "start_cap" respectively which define the gap between the arrow point and the node. These values can all be set using absolute measurements as shown in the example below. Since this is an undirected network we use the argument "ends='first'" to simulated a directed network so that arrowheads will only be drawn the first time an edge appears in the edge list. See ?arrow for more details on options. 

```{r edge_options2, message=F, warning=F}
set.seed(436)
ggraph(net, "stress") +
  geom_edge_link(arrow = arrow(length = unit(2, 'mm'), ends="first", type="closed"),
                 end_cap = circle(0, 'mm'), start_cap = circle(3, 'mm'), 
                 edge_colour = "black") +
  geom_node_point(size=4, col="blue") +
  theme_graph()
```

Another common consideration with edges is the shape of the edges themselves. So far we have used examples where the edges are all straight lines, but it is also possible to draw them as arcs or so that they fan out from nodes so that multiple connections are visible. In general, all you need to do to change this option is to use another command in the "geom_edge_" family of commands. For example, in the following chunk of code we produce a network with arcs rather than straight lines. In this case the argument "strength" controls the amount of bend in the lines.

```{r edge_arc}
set.seed(436)
ggraph(net, "kk") +
  geom_edge_arc(edge_colour = "black", strength=0.1) +
  geom_node_point(size=4, col="blue") +
  theme_graph()
```

It is also possible to not show edges at all but instead just a gradient scale representing the density of edges using the "geom_edge_density" call. This could be useful in very large and complex networks.

```{r edge_density}
set.seed(436)
ggraph(net2, "kk") +
  geom_edge_density() +
  geom_node_point(size=4, col="blue") +
  theme_graph()
```

### Label Options

In many cases you may want to label either the nodes, edges, or other features of a network. This is relatively easy to do in ggraph with the "geom_node_text()" command. This will place labels as specified on each node. If you use the "repel = TRUE" argument it will repel the names slightly from the node to make them more readable. As shown in the example for [Figure 6.4](#Figure_6_4) it is also possible to filter labels to label only certain nodes.

```{r node_label}
# first set a node attribute called name based on site names
V(net2)$name <- get.vertex.attribute(BRnet_w, attr="vertex.names")

set.seed(436)
ggraph(net2, "fr") +
  geom_edge_link() +
  geom_node_point(size=4, col="blue") +
  geom_node_text(aes(label = name), size=3, repel = TRUE)+
  theme_graph()
```

It is also possible to label edges by adding an argument directly into the "geom_link_" command. In practice, this really only works with very small networks. In the next chunk of code, we create a small network and demonstrate this function.

```{r edge_label}
g <- graph( c("A", "B",
              "B", "C",
              "A", "C",
              "A", "A",
              "C","B",
              "D","C"))

E(g)$weight <- c(3,1,6,8,4,2)

set.seed(4351)
ggraph(g, layout='stress') +
  geom_edge_fan(aes(label=weight)) +
  geom_node_point(size=20, col='lightblue') +
  geom_node_text(label=V(g)$name) +
  theme_graph()
```

### Be Kind to the Color Blind

When selecting your color schemes, it is important to consider the impact of a particular color scheme on color blind readers. There is an excellent set of R scripts on GitHub in a package called [colorblindr](https://github.com/clauswilke/colorblindr) which can help you do just that. I have slightly modified the code from the colorblindr package and created a script called [colorblindr.R](data/colorblindr.R) which you can download and use to test out your network. Simply run the code in the script and then use the cvd_grid2() function on a ggplot or ggraph object to see simulated colors.

The chunk of code below loads the colorblindr.R script and then plots a figure using RColorBrewer color "Set2" in its original unmodified format and then as it might look to readers with some of the most common forms of color vision issues.

```{r colorblind, warning=F, message=F, fig.height=10, fig.width=10}
library(colorspace)
source("data/colorblindr.R")
cvd_grid2(g1)
```

### Communities and Groups

Showing communities or other groups in network visualizations can be as simple as color coding nodes or edges as we have seen in many examples here. It is sometimes also useful to highlight groups by creating a convex hull or circle around the relevant points. This can be done in ggraph using the "geom_mark_hull" command within the ggforce package. 

The following chunk of code provides a simple example using the Louvain clustering algorithm.

```{r ggforce, warning=F, message=F, fig.width=8, fig.height=8}

library(ggforce)

# Define clusters
grp <- as.factor(cluster_louvain(net2)$membership)

set.seed(4343)
ggraph(net2, layout = "fr") +
  geom_edge_link0(width = 0.2) +
  geom_node_point(aes(fill = grp), shape = 21, size = 5, alpha=0.75) +
  # Create hull around points within group and label
  geom_mark_hull(
    aes(x, y, group = grp, fill = grp, label=grp),
    concavity = 4,
    expand = unit(2, "mm"),
    alpha = 0.25, label.fontsize=10) +
  scale_fill_brewer(palette = "Set2") +
  theme_graph()
```

The discussion of [Figure 6.4](#Figure_6_4) below provides another similar example. There are many more complicated ways of showing network groups provided by the examples covering figures from the book. For example, [Figure 6.17](#Figure_6_17) provides an example of the "group-in-a-box" technique using the NodeXL software package. [Figure 6.18](#Figure_6_18) illustrates the use of matrices as visualization tools and [Figure 6.19](#Figure_6_19) provides links to the Nodetrix hybrid visualization software. 

## Replicating the Book Figures

In this section we go through each figure in Chapter 6 of Brughmans and Peeples (2022) and detail how the final graph was created for all figures that were created using R. For those figures not created in R we describe what software and data were used and provide additional resources where available. We hope these examples will serve as inspiration for your own network visualization experiments. Some of these figures are relatively simple while others are quite complex. They are presented in the order they appear in the book. 

### Figure 6.1: Manual Layout {#Figure_6_1}

Figure 6.1. An example of an early hand drawn network graph (sociogram) published by Moreno (1932: 101). Moreno noted that the nodes at the top and bottom of the sociogram have the most connections and therefore represent the nodes of greatest importance. These specific “important” points are emphasized through both their size and their placement.

Note that the hand drawn version of this figure is presented in the book and this digital example is presented only for illustrative purposes. This shows how you can employ user defined layouts by directly supplying coordinates for the nodes in the plot. [Download the Moreno data to follow along]("data/Moreno.csv").

```{r Fig6_1, message=F, warning=F, fig.width=2, fig.height=3}
library(igraph)
library(ggraph)

# Read in adjacency matrix of Moreno data and covert to network
Moreno <- as.matrix(read.csv('data/Moreno.csv',header=T,row.names=1))
g.Moreno <- graph_from_adjacency_matrix(Moreno)

# Create xy coordinates associated with each node
xy <- matrix(c(4,7,1,5,6,5,2,4,3,4,5,4,1,2.5,6,2.5,4,1),nrow=9,ncol=2,byrow=T)

# Plot the network using layout = "manual" to place nodes using xy coordinates
ggraph(g.Moreno, layout = "manual",
       x=xy[,1], y=xy[,2]) +
  geom_edge_link() +
  geom_node_point(fill='white', shape = 21, size = igraph::degree(g.Moreno)) +
  scale_size(range=c(2,3)) +
  theme_graph()

```

### Figure 6.2: Examples of Common Network Plot Formats {#Figure_6_2}

Figure 6.2. These plots are all different visual representations of the same network data from Peeples’s (2018) data where edges are defined based on the technological similarities of cooking pots from each node which represent archaeological settlements. 

The code below creates each of the individual figures and then compiles them into a single composite figure for plotting. 

First read in the data ([all data are combined in a single RData file here](data/Peeples2018.Rdata)).

```{r Fig6_2_dat, message=F, warning=F, fig.height=8, fig.width=8}
library(igraph)
library(statnet)
library(intergraph)
library(ggplotify)
library(ggraph)
library(ggpubr)

load(file="data/Peeples2018.Rdata")
## contains objects
# site_info - site locations and attributes
# ceramicBR - raw Brainard-Robinson similarity among sites
# BRnet - binary network with similarity values > 0.65 defined as edges in statnet/network format
# BRnet_w - weighted network with edges (>0.65) given weight values based on BR similarity in statnet/network format
##
```

Fig 6.2a - A simple network graph with nodes placed based on the Fruchterman-Reingold algorithm

```{r Fig6_2a, message=F, warning=F, fig.width=6, fig.height=6}
## create simple graph with Fruchterman-Reingold layout
set.seed(423)
F6.2a <- ggraph(BRnet, "fr") +
  geom_edge_link(edge_colour = "grey66") +
  geom_node_point(aes(size = 5), col = "red", show.legend = FALSE) +
  theme_graph()
F6.2a
```

Fig 6.2b - Network graph nodes with placed based on the real geographic locations of settlements and are color coded based on sub-regions.

```{r Fig6_2b, message=F, warning=F, fig.width=6, fig.height=6}
## create graph with layout determined by site location and nodes color coded by region
F6.2b <- ggraph(BRnet, "manual",
       x = site_info$x,
       y = site_info$y) +
  geom_edge_link(edge_colour = "grey66") +
  geom_node_point(aes(size = 2,col=site_info$Region), show.legend = FALSE) +
  theme_graph()
F6.2b
```

Fig 6.2c - A graph designed to show how many different kinds of information can be combined in a single network plot. In this network graph node placement is defined by the stress majorization algorithm (see below), with nodes color coded based on region, with different symbols for different kinds of public architectural features found at those sites, and with nodes scaled based on betweenness centrality scores. The line weight of each edge is used to indicate relative tie-strength.

```{r Fig6_2c, message=F, warning=F, fig.width=6, fig.height=6}
# create vectors of attributes and betweenness centrality and plot network
# with nodes color coded by region, sized by betweenness, with symbols representing
# public architectural features, and with edges weighted by BR similarity
col1 <- as.factor((site_info$Great.Kiva))
col2 <- as.factor((site_info$Region))
bw <- sna::betweenness(BRnet_w)

F6.2c <- ggraph(BRnet_w, "stress") +
  geom_edge_link(aes(width = weight, alpha=weight), edge_colour = "black", show.legend=F) +
  scale_edge_width(range=c(1,2)) +
  geom_node_point(aes(size = bw, shape= col1, fill=col1, col=site_info$Region), show.legend=F) +
  scale_fill_discrete() +
  scale_size(range = c(4, 12)) +
  theme_graph()
F6.2c
```

Fig. 6.2d - This network graph is laid out using the Kamada-Kawai force directed algorithm with nodes color coded based on communities detected using the Louvain community detection algorithm. Each community is also indicated by a circle highlighting the relevant nodes. Edges within communities are shown in black and edges between communities are shown in red.

In this plot we use the "as.ggplot" function to convert a traditional igraph plot to a ggraph plot to illustrate how this can be done.

```{r Fig6_2d, message=F, warning=F, fig.width=6, fig.height=6}
# convert network object to igraph object and calculate Louvain cluster membership plot and convert to grob 
# to combine in ggplot
g <- asIgraph(BRnet_w)
clst <- cluster_louvain(g)

F6.2d <- as.ggplot(~plot(clst, g, layout=layout_with_kk, vertex.label=NA, vertex.size=10, col=rainbow(4)[clst$membership]))
F6.2d
```

Finally, we use the "ggarrange" function from the "ggpubr" package to combine all of these plots into a single composite plot.

```{r Fig6_2_all, message=F, warning=F, fig.height=8, fig.width=8}
# Combine all plots into a single figure using ggarrange
figure_6_2 <- ggarrange(F6.2a,F6.2b,F6.2c,F6.2d,nrow=2,ncol=2,labels=c('(a)','(b)','(c)','(d)'), font.label=list(size=22))

figure_6_2
  
```

### Figure 6.3: Examples of Rare Network Plot Formats {#Figure_6_3}

Figure 6.3. More visualizations using the Cibola technological similarity data. 

Fig 6.3a - A weighted heat plot of the underlying similarity matrix with hierarchical clusters shown on each axis. This plot relies on a packages called "superheat" that produces plots formatted as we see here.

```{r Fig6_3a, message=F, warning=F, fig.width=6, fig.height=6}

library(igraph)
library(statnet)
library(intergraph)
library(ggraph)
library(ggplotify)
library(superheat)

ceramicBRa <- ceramicBR
diag(ceramicBRa) <- NA

F6.3a <- as.ggplot(~superheat(ceramicBRa, 
          row.dendrogram = T, 
          col.dendrogram = T,
          grid.hline.col = "white",
          grid.vline.col = "white",
          legend=F,
          left.label.size=0,
          bottom.label.size=0))
F6.3a
```

Fig. 6.3b - An arcplot with within group ties shown above the plot and between group ties shown below.

For this plot, we read in a adjacency matrix that is ordered in the order we want it to show up in the final plot. [Download the file here](data/Peeples_arcplot.csv) to follow along.


```{r Fig6_3b, message=F, warning=F, fig.width=6, fig.height=6}

arc_dat <- read.csv('data/Peeples_arcplot.csv',header=T,row.names=1)
g <- graph_from_adjacency_matrix(as.matrix(t(arc_dat)))

grp <- as.factor(c(2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1)) # set groups for color

# Make the graph
F6.3b <- ggraph(g, layout="linear") + 
  geom_edge_arc(edge_colour="black", edge_alpha=0.2, edge_width=0.7, fold=F, strength=1, show.legend=F) +
  geom_node_point(aes(size=igraph::degree(g), color=grp, fill=grp), alpha=0.5, show.legend=F) +
  scale_size_continuous(range=c(4,8)) +
  theme_graph() 
F6.3b
```

Fig. 6.3c - Network plot with sites in geographic locations and edges bundled using the edge bundling hammer routine.

This function requires the "edgebundle" package be installed and uses the [Cibola technological similarity data](data/Peeples2018.Rdata).

```{r Fig6_3c, message=F, warning=F, fig.width=6, fig.height=6}
library(edgebundle)
load("data/Peeples2018.Rdata")

# Create attribute file with rquired data
xy<- as.data.frame(site_info[,1:2])
xy <- cbind(xy,site_info$Region)
colnames(xy) <- c('x','y','Region')

# Run hammer bundling routine 
g <- asIgraph(BRnet)
hbundle <- edge_bundle_hammer(g,xy,bw = 5, decay = 0.3)
  
F6.3c <-   ggplot()+
    geom_path(data = hbundle,aes(x,y,group=group),col="gray66",size=0.5)+
    geom_point(data = xy,aes(x,y,col=Region),size=5,alpha=0.75, show.legend=F)+
    theme_void()
F6.3c
```

Fig. 6.3d - Network graph where nodes are replaced by waffle plots that show relative frequencies of the most common ceramic technological clusters.

This is a somewhat complicated plot that requires a couple of specialized libraries and additional steps along the way. We provide comments in the code below to help you follow along. Essentially the routine creates a series of waffle plots and then uses them as annotation to replace the nodes in the final ggraph.

```{r Fig6_3d, message=F, warning=F, fig.width=6, fig.height=6}
# Initialize libraries
library(ggwaffle)
library(tidyverse)

# Create igraph object from data imported above
Cibola_adj <- read.csv(file="data/Cibola_adj.csv", header=TRUE, row.names=1)
g <- graph_from_adjacency_matrix(as.matrix(Cibola_adj), mode="undirected")

# Import raw ceramic data and convert to proportions
ceramic_clust <- read.csv(file="data/Cibola_clust.csv", header=T, row.names=1)
ceramic.p <- prop.table(as.matrix(ceramic_clust), margin=1)

# Assign vertex attributes to the network object g which represent columns in the ceramic.p table
V(g)$C1 <- ceramic.p[,1]
V(g)$C2 <- ceramic.p[,2]
V(g)$C3 <- ceramic.p[,3]
V(g)$C4 <- ceramic.p[,4]
V(g)$C5 <- ceramic.p[,5]
V(g)$C6 <- ceramic.p[,6]
V(g)$C7 <- ceramic.p[,7]
V(g)$C8 <- ceramic.p[,8]
V(g)$C9 <- ceramic.p[,9]
V(g)$C10 <- ceramic.p[,10]
  
# Precompute the layout and assign coordinates as x and y in network g
set.seed(345434534)
xy <- layout_with_fr(g)
V(g)$x <- xy[, 1]
V(g)$y <- xy[, 2]

# Create a data frame that contains the 4 most common categories in the ceramic table,
# the node id, and the proportion of that ceramic category at that node
nodes_wide <- igraph::as_data_frame(g, "vertices")
nodes_long <- nodes_wide %>% dplyr::select(C1:C4) %>%
  mutate(id = 1:nrow(nodes_wide)) %>%
  gather("attr", "value", C1:C4)
nodes_out <- NULL
for (j in 1:nrow(nodes_long)) {
  temp <- do.call("rbind", replicate(round(nodes_long[j,]$value*50,0), nodes_long[j,], simplify = FALSE))
  nodes_out <- rbind(nodes_out,temp)
}
  
# Create a list object for the call to each bar chart by node
bar_list <- lapply(1:vcount(g), function(i) {
  gt_plot <- ggplotGrob(
    ggplot(waffle_iron(nodes_out[nodes_out$id == i, ], aes_d(group=attr))) +
      geom_waffle(aes(x, y, fill = group), size=0.1) +
      coord_equal() +
      labs(x = NULL, y = NULL) +
      theme(
        legend.position = "none",
        panel.background = element_rect(fill = "white", colour = NA),
        line = element_blank(),
        text = element_blank()
      )
  )
  panel_coords <- gt_plot$layout[gt_plot$layout$name == "panel", ]
  gt_plot[panel_coords$t:panel_coords$b, panel_coords$l:panel_coords$r]
})

# Convert the results above into custom annotation
annot_list <- lapply(1:vcount(g), function(i) {
  xmin <- nodes_wide$x[i] - .2
  xmax <- nodes_wide$x[i] + .2
  ymin <- nodes_wide$y[i] - .2
  ymax <- nodes_wide$y[i] + .2
  annotation_custom(
    bar_list[[i]],
    xmin = xmin,
    xmax = xmax,
    ymin = ymin,
    ymax = ymax
  )
})

# create basic network
p <- ggraph(g, "manual", x = V(g)$x, y = V(g)$y) +
  geom_edge_link0() +
  theme_graph() +
  coord_fixed()

# put everything together by combining with the annotation (bar plots + network)
F6.3d<- Reduce("+", annot_list, p)
F6.3d
```

Combine all of the plots into a single figure

```{r Fig6_3_all, fig.width=8, fig.height=8, eval=F}
library(ggpubr)
figure_6_3 <- ggarrange(F6.3a,F6.3b,F6.3c,F6.3d, nrow=2,ncol=2,labels=c('(a)','(b)','(c)','(d)'), font.label=list(size=22))

figure_6_3
```

![](images/Figure_6_3.jpg.jpeg){width=100%}

### Figure 6.4: Simple Network with Clusters {#Figure_6_4}

Figure 6.4 is a network of shared lithic material sources among Clovis sites in western North America. 
 
This example shows how to define and indicate groups and label points.

```{r Fig6_4, warning=F, message=F, fig.width=8, fig.height=8}
library(ggforce)
library(ggraph)
library(statnet)
library(igraph)

Clovis <- read.csv("data/Clovis.csv", header=T, row.names=1)
colnames(Clovis) <- row.names(Clovis)
graph <- graph_from_adjacency_matrix(as.matrix(Clovis),mode="undirected", diag=F)

bw <- igraph::betweenness(graph)

grp <- as.factor(cluster_louvain(graph)$membership)

set.seed(43643548)
ggraph(graph, layout = "fr") +
  geom_edge_link(edge_width=1, color='gray') +
  geom_node_point(aes(fill = grp, size=bw, color=grp), shape = 21, alpha=0.75) +
  scale_size(range=c(2,20)) +
  geom_mark_hull(
    aes(x, y, group = grp, fill = grp, label=grp, color=NA),
    concavity = 4,
    expand = unit(2, "mm"),
    alpha = 0.25, label.fontsize=12) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3), rgb(0, 0, 0, 1))) +
  geom_node_text(aes(label = ifelse(bw > 40, as.character(name), NA_character_)), size=4) +
  theme_graph()+
  theme(legend.position = "none")
```

### Figure 6.5: Interactive Layout {#Figure_6_5}

Figure 6.5 was produced in NetDraw by creating a simple network and just creating two configurations of nodes. There are a few options for creating a similar figure in R. The simplest is to use an igraph network object and the "tkplot" function. This function brings up a window that lets you drag and move nodes (with or without an initial algorithmic layout) and when you're done you can assign the new positions to a variable to use for plotting. [Use these data](data/Peeples2018.Rdata) to follow along.

```{r Fig6_5a, message=F, warning=F, eval=F}
library(igraph)
library(intergraph)

load("data/Peeples2018.Rdata")

Cibola_i <- asIgraph(BRnet)

locs <- tkplot(Cibola_i)
Coords <- tkplot.getcoords(locs)

```

This will bring up a window like the example below and when you click "Close" it will automatically create the variables with the locational information for plotting.

![](images/interactive.jpg){width=80%}
```{r Fig6_5b, echo=F}
load(file="data/Coords.Rdata")

```

```{r Fig6_5c}
plot(Cibola_i, layout=Coords)
```

### Figure 6.6: Absolute Geographic Layout {#Figure_6_6}

Fig. 6.6. Map of major Roman roads and major settlements on the Iberian Peninsula, (a) with roads mapped along their actual geographic paths and (b) roads shown as simple line segments between nodes. 

The figure that appears in the book was originally created using GIS software but it is possible to prepare a quite similar figure in R using the tools we outlined above. To reproduce the results presented here you will need to download [the node information file](data/Hispania_nodes.csv) and the [road edge list](data/Hispania_roads.csv).

```{r Fig6_6, warning=F, message=F}

library(igraph)
library(ggmap)
library(sf)

edges1 <- read.csv("data/Hispania_roads.csv", header=T)
edges1 <- edges1[which(edges1$Weight>25),]
nodes <- read.csv("data/Hispania_nodes.csv", header=T)
nodes <- nodes[which(nodes$Id %in% c(edges1$Source,edges1$Target)),]

road_net <- graph_from_edgelist(as.matrix(edges1[,1:2]), directed=FALSE)

# Convert attribute location data to sf coordinates
locations_sf <- st_as_sf(nodes, coords = c("long", "lat"), crs = 4326)
coord1 <- do.call(rbind, st_geometry(locations_sf)) %>% 
  tibble::as_tibble() %>% setNames(c("lon","lat"))

xy <- as.data.frame(coord1)
colnames(xy) <- c('x','y')

# Extract edgelist from network object
edgelist <- get.edgelist(road_net)

# Create dataframe of beginning and ending points of edges
edges <- as.data.frame(matrix(NA,nrow(edgelist),4))
colnames(edges) <- c("X1","Y1","X2","Y2")
for (i in 1:nrow(edgelist)) {
edges[i,] <- c(nodes[which(nodes$Id==edgelist[i,1]),3],nodes[which(nodes$Id==edgelist[i,1]),2],
               nodes[which(nodes$Id==edgelist[i,2]),3],nodes[which(nodes$Id==edgelist[i,2]),2])
}

myMap <- get_stamenmap(bbox = c(-9.5,36,3,43.8),maptype = "watercolor",zoom = 6)

ggmap(myMap) +
  geom_segment(data = edges, aes(x=X1, y=Y1, xend=X2, yend=Y2), col='black', size=1) +
  geom_point(data = xy, aes(x,y), alpha=0.8, col='black', fill="white", shape=21, size=1.5, show.legend=F) +
  theme_void()
```

### Figure 6.7: Distorted Geographic Layout {#Figure_6_7}

Fig. 6.7. This ceramic similarity network of the San Pedro River Valley in Arizona shows the challenges of creating geographic network layouts. Figure 6.7a shows sites in their original locations whereas figure 6.7b shifts locations to improve the visibility of network structure. Note how the distorted geographic layout retains the basic relationships among the nodes while altering their locations slightly.

Unfortunately as the first map contains real site locations we cannot share those data here. The second map can still be reproduced given nothing but the code below. The only difference required to produce Figure 6.7a would be to replace the "coord" site coordinates with the actual site locations.

```{r, message=F, warning=F, fig.height=6, fig.width=6}
library(igraph)
library(sf)
library(ggmap)
library(ggsn)
library(ggrepel)
library(ggpubr)

load("data/Figure6_7.Rdata")
# g.net - igraph network object of San Pedro sites based on ceramic similarity

# Define coordinates of "jittered" points
# These points were originally created using the "jitter" function
# until a reasonable set of points were found.
coord <- c(-110.7985, 32.97888,
-110.7472, 32.89950,
-110.6965, 32.83496,
-110.6899, 32.91499,
-110.5508, 32.72260,
-110.4752, 32.60533,
-110.3367, 32.33341,
-110.5930, 32.43487,
-110.8160, 32.86185,
-110.6650, 32.64882,
-110.4558, 32.56866,
-110.6879, 32.60055,
-110.7428, 32.93124,
-110.4173, 32.34401,
-110.7000, 32.73344)

attr <- c("Swingle's Sample","Ash Terrace","Lost Mound","Dudleyville Mound","Leaverton",        
          "High Mesa","Elliott Site","Bayless Ruin","Flieger","Big Bell","111 Ranch",
          "Twin Hawks","Artifact Hill","Jose Solas Ruin","Wright")

# Convert coordinates to data frame
zz <- as.data.frame(matrix(coord,nrow=15,byrow=TRUE))
colnames(zz) <- c('x','y')

# Get basemap "terrain-background" data for map in black and white
base3 <- get_stamenmap(bbox=c(-111,32.2,-110,33.1),zoom=10,maptype="terrain-background",color="bw")

# Extract edgelist from network object
edgelist <- get.edgelist(g.net)

# Create dataframe of beginning and ending points of edges
edges2 <- data.frame(zz[edgelist[,1],], zz[edgelist[,2],])
colnames(edges2) <- c("X1","Y1","X2","Y2")

# Plot jittered coordinates on map
figure_6_7 <- ggmap(base3,darken=0.35) +
  geom_segment(data = edges2, aes(x=X1, y=Y1, xend=X2, yend=Y2), col='white',size=1) +
  geom_point(data = zz,aes(x,y),alpha=0.8, col='red', size=5, show.legend=F) +
  geom_text_repel(aes(x=x, y=y, label=attr), data=zz, size=3) +
  scalebar(x.min = -111, x.max = -110.75,
           y.min = 32.25, y.max = 33,
           dist = 10, dist_unit = "km",
           st.bottom = FALSE, transform = TRUE, 
           model = "WGS84") +
  theme_void()

figure_6_7
```

### Figure 6.8: Graph Layout Algorithms {#Figure_6_8}

Fig. 6.8. Several different graph layouts all using the same “Zachary karate” network. In each graph, nodes are scale based on betweenness centrality and color coded based on optimal clusters based on modularity maximization.

```{r Fig6_8, warning=F, message=F, fig.width=10, fig.height=16}

library(igraph)
library(ggraph)
library(ggpubr)
library(igraphdata)
library(graphlayouts)
library(sf)
library(ggmap)

# Load igraph aegean_net data
#data(aegean_net)
aegean <- read.csv("data/aegean.csv",row.names=1, header=T)
aegean_dist <- aegean
aegean_dist[aegean_dist>124] <- 0
aegean_dist[aegean_dist>0] <- 1
aegean_net <- graph_from_adjacency_matrix(as.matrix(aegean_dist))

# Define cluster membership and betweenness centrality for plotting
grp <- as.factor(cluster_optimal(aegean_net)$membership)
bw <- as.numeric(igraph::betweenness(aegean_net))

# Multidimensional Scaling Layout with color by cluster and node size by betweenness
set.seed(435353)
g.mds <- ggraph(aegean_net, layout = "mds") +
  geom_edge_link0(width = 0.2) +
  geom_node_point(aes(fill = grp, size = bw), shape=21 ,show.legend=F) +
  scale_size(range=c(4,15)) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3), rgb(0, 0, 0, 1))) +
  theme_graph()+
  theme(plot.title = element_text(size=22)) +
  ggtitle("Multi-Dimensional Scaling") +
  theme(legend.position = "none")

# Fruchterman-Reingold Layout with color by cluster and node size by betweenness
set.seed(435353)
g.fr <- ggraph(aegean_net, layout = "fr") +
  geom_edge_link0(width = 0.2) +
  geom_node_point(aes(fill = grp, size = bw), shape=21 ,show.legend=F) +
  scale_size(range=c(4,15)) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3), rgb(0, 0, 0, 1))) +
  theme_graph()+
  theme(plot.title = element_text(size=22)) +
  ggtitle("Fruchterman-Reingold") +
  theme(legend.position = "none")

# Kamada-Kawai Layout with color by cluster and node size by betweenness
set.seed(435353)
g.kk <- ggraph(aegean_net, layout = "kk") +
  geom_edge_link0(width = 0.2) +
  geom_node_point(aes(fill = grp, size = bw), shape=21 ,show.legend=F) +
  scale_size(range=c(4,15)) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3), rgb(0, 0, 0, 1))) +
  theme_graph()+
  theme(plot.title = element_text(size=22)) +
  ggtitle("Kamada-Kawai") +
  theme(legend.position = "none")

# Radial Centrality Layout with color by cluster and node size by betweenness
set.seed(435353)
g.cent <- ggraph(aegean_net, layout = "centrality", centrality=igraph::betweenness(aegean_net)) +
  geom_edge_link0(width = 0.2) +
  geom_node_point(aes(fill = grp, size = bw), shape=21 ,show.legend=F) +
  scale_size(range=c(4,15)) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3), rgb(0, 0, 0, 1))) +
  theme_graph()+
  theme(plot.title = element_text(size=22)) +
  ggtitle("Radial Centrality") +
  theme(legend.position = "none")

# Spectral Layout with color by cluster and node size by betweenness
u1 <- layout_with_eigen(aegean_net)
g.spec <- ggraph(aegean_net, layout = "manual",
                 x=u1[,1],
                 y=u1[,2]) +
  geom_edge_link0(width = 0.2) +
  geom_node_point(aes(fill = grp, size = bw), shape=21 ,show.legend=F) +
  scale_size(range=c(4,15)) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  scale_edge_color_manual(values = c(rgb(0, 0, 0, 0.3), rgb(0, 0, 0, 1))) +
  
  theme_graph()+
  theme(plot.title = element_text(size=22)) +
  ggtitle("Spectral") +
  theme(legend.position = "none")


# Create geographic network and plot

nodes <- read.csv('data/aegean_locs.csv')

# Convert attribute location data to sf coordinates
locations_sf <- st_as_sf(nodes, coords = c("Longitude", "Latitude"), crs = 4326)
coord1 <- do.call(rbind, st_geometry(locations_sf)) %>% 
  tibble::as_tibble() %>% setNames(c("lon","lat"))

xy <- as.data.frame(coord1)
colnames(xy) <- c('x','y')

myMap <- get_stamenmap(bbox=c(22,34.5,29,38.8),zoom=8,maptype="terrain-background")

# Extract edgelist from network object for road_net
edgelist1 <- get.edgelist(aegean_net)

# Create dataframe of beginning and ending points of edges
edges1 <- as.data.frame(matrix(NA,nrow(edgelist1),4))
colnames(edges1) <- c("X1","Y1","X2","Y2")
for (i in 1:nrow(edgelist1)) {
  edges1[i,] <- c(nodes[which(nodes$Name==edgelist1[i,1]),]$Longitude,nodes[which(nodes$Name==edgelist1[i,1]),]$Latitude,
                  nodes[which(nodes$Name==edgelist1[i,2]),]$Longitude,nodes[which(nodes$Name==edgelist1[i,2]),]$Latitude)
}

geo_net <- ggmap(myMap) +
  geom_segment(data = edges1, aes(x=X1, y=Y1, xend=X2, yend=Y2), col='black', size=1) +
  geom_point(data = xy, aes(x,y,size=bw,fill=grp), alpha=0.8, shape=21, show.legend=F) +
  scale_size(range=c(4,15)) +
  scale_color_brewer(palette = "Set2") +
  scale_fill_brewer(palette = "Set2") +
  theme_graph() +
  ggtitle("Geographic") +
  theme(plot.title = element_text(size=22)) 
  

figure_6_8a <- ggarrange(geo_net, g.mds, g.fr, g.kk, g.cent, g.spec, ncol = 2, nrow = 3)
figure_6_8a
```

### Figure 6.9: Heirarchical Graph Layouts {#Figure_6_9}

Fig. 6.9. Examples of visualizations based on hierarchical graph data. A) Graph with nodes color coded by hierarchical level. B) Bubble plot where nodes are scaled proportional to the sub-group size. C) Dendrogram of hierarchical cluster data. D) Radial graph with edges bundled based on similarity in relations. Edges are color coded such that they are red at the origin and purple at the destination to help visualize direction.

These graphs are based on a hierarchical graph that was created by assigning nodes to the leaves of a hierarchical cluster analysis performed on the Cibola ceramic technological cluster data. The data for 6.9d were randomly generated following an example on the R Graph Gallery. [Use these data](data/Figure6_9.Rdata) to follow along.

```{r Fig6_9, warning=F, message=F, fig.height=8, fig.width=8}
# initialize libraries
library(igraph)
library(ggraph)
library(ape)
library(RColorBrewer)
library(ggpubr)

load(file="data/Figure6_9.Rdata")

set.seed(4353543)
h1 <- ggraph(h_graph, 'circlepack') + 
  geom_edge_link() + 
  geom_node_point(aes(colour = depth, size=(max(depth)-depth)/2), show.legend=F) +
  scale_color_viridis() +
  theme_graph() +
  coord_fixed()

set.seed(643346463)
h2 <- ggraph(h_graph, 'circlepack') + 
  geom_node_circle(aes(fill=depth), size = 0.25, n = 50, show.legend=F) + 
  scale_fill_viridis() +
  theme_graph() +
  coord_fixed()

h3 <- ggraph(h_graph, 'dendrogram') + 
  geom_node_point(aes(filter=leaf),color='blue' , alpha=0.7, size=3) +
  theme_graph()+
  geom_edge_link()

h4 <- ggraph(sub_grp_graph, layout = 'dendrogram', circular = TRUE) + 
  geom_conn_bundle(data = get_con(from = from, to = to), alpha=0.2, width=0.9, tension=0.9, aes(colour=..index..)) +
  scale_edge_colour_distiller(palette = "RdPu") +
  geom_node_point(aes(filter = leaf, x = x*1.05, y=y*1.05, colour=group),size=3) +
  scale_colour_manual(values= rep(brewer.pal(9,"Paired") , 30)) +
  theme_graph() +
  theme(legend.position = "none") 

figure_6_9 <- ggarrange(h1,h2,h3,h4, ncol = 2, nrow = 2, labels=c('(a)','(b)','(c)','(d)'))
figure_6_9
```

### Figure 6.10: Be kind to the color blind {#Figure_6_10}

```{r Fig6_10, warning=F, message=F, fig.height=7, fig.width=7}
library(igraph)
library(statnet)
library(intergraph)
library(ggraph)
library(RColorBrewer)
library(colorspace)
source("data/colorblindr.R")

load("data/Peeples2018.Rdata")

# Create igraph object for plots below
net <- asIgraph(BRnet)

set.seed(347)
g1 <- ggraph(net, layout = "kk") +
  geom_edge_link(edge_color="gray", alpha=0.7) +
  geom_node_point(aes(fill = site_info$Region), shape = 21, size = igraph::degree(net), alpha=0.5) +
  scale_size(range=c(1,3)) +
  scale_fill_brewer(palette = "Set2") +
  theme_graph()+
  theme(legend.position = "none")

cvd_grid2(g1)

```


### Figure 6.11: Node Symbol and Color Schemes {#Figure_6_11}

Fig. 6.11. Examples of different node color and symbol schemes. Note how adding color and size eases the identification of particular values, in particular with closely spaced points. Using transparency can similarly aid in showing multiple overlapping nodes.

The version that appears in the book was compiled and labeled in Adobe Illustrator.

```{r Fig6_11, warning=F, message=F}
library(scales)

plot(x=1:5, y=rep(2,5), pch=16, cex=seq(5:10), col="blue", ylim=c(0,4), bty='n', xaxt='n', yaxt='n', xlab='', ylab='')
points(x=1:5, y=rep(1.5,5), pch=21, cex=seq(5:10), bg=heat.colors(5, rev=T))
points(x=1:5, y=rep(1,5), pch=c(1,2,3,4,5), cex=seq(5:10), bg='skyblue', col='blue', lwd=2)

set.seed(34456)
x <- rnorm(15,1,0.5)
y <- rnorm(15,1,0.5)
xy <- cbind(x,y)
xy2 <- cbind(x+5,y)
xy3 <- cbind(x+10,y)
xy4 <- cbind(x+15,y)
xy5 <- cbind(x+20,y)

size <- sample(c(5,6,7,8,9),size=15,replace=T)
size <- size-4

h.col <- heat.colors(5,rev=T)

plot(xy[order(size,decreasing=T),], pch=16, col='blue', cex=size[order(size,decreasing=T)], xlim=c(0,22),ylim=c(-1,3),bty='n', xaxt='n', yaxt='n', xlab='', ylab='')
points(xy2[order(size,decreasing=T),], pch=21, bg=h.col[size[order(size,decreasing=T)]], cex=size[order(size,decreasing=T)])
points(xy3[order(size,decreasing=T),], pch=size[order(size,decreasing=T)], col='blue', cex=size[order(size,decreasing=T)])
points(xy4[order(size,decreasing=T),], pch=21, col='gray66', bg=alpha('blue',0.7), cex=size[order(size,decreasing=T)])
points(xy5[order(size,decreasing=T),], pch=21, bg=alpha(h.col[size[order(size,decreasing=T)]],0.7), cex=size[order(size,decreasing=T)])
```


### Figure 6.12: Image for Node {#Figure_6_12}

Fig. 6.12. Network graph showing similarity among carved faces from Banés, Holguín province, Cuba. Nodes are depicted as the objects in question themselves and edges represent shared attributes with numbers indicating the number of shared attributes for each pair of faces.

Figure 6.12 was used with permission by Angus Mol and the original was produced for his 2014 book. 

### Figure 6.13: Images for Nodes {#Figure_6_13}

Fig. 6.13. Two-mode network of ceramics and sites in the San Pedro Valley with ceramic ware categories represented by a graphic example of each type.

The version of Figure 6.13 in the Brughmans and Peeples (2022) book was originally created in NetDraw and modified to add the node pictures in Adobe Photoshop. This approach was preferred as it produced higher resolution and more consistent images than the graphics we could produce directly in R for this particular feature. It is, however, possible to use images in the place of nodes in R networks as the example below illustrates. 

We have found in practice that this feature in R works best for simple icons. If you are using high resolution images or lots of color or detail in your images it works better to create an initial image format in something like R or NetDraw and then to modify the network in a graphical editing software after the fact. You can [download the data](data/Figure6_13.Rdata) to follow along.

```{r Fig6_13, fig.height=8, fig.width=8, warning=F, message=F}
library(png)
library(igraph)

load("data/Figure6_13.Rdata")
# two_mode_net - igraph two mode network object
# img.1 <- readPNG("images/site.png")
#img.2 <- readPNG("images/pot.png")

V(two_mode_net)$raster <- list(img.1, img.2)[V(two_mode_net)$type+1]

set.seed(34673)
plot(two_mode_net, vertex.shape="raster", vertex.label=NA,
vertex.size=16, vertex.size2=16, edge.width=2, edge.color="red")

```

### Figure 6.14: Edge Thickness and Color {#Figure_6_14}

Fig. 6.14. A random weighted graph where edge line thickness and color are both used to indicate weight in 5 categories. 

You can [download the data and images](data/Figure6_14.Rdata) to follow along.

```{r Fig6_14, warning=F, message=F, fig.width=6, fig.height=6}

library(igraph)
library(ggraph)

load("data/Figure6_14.Rdata")

edge.cols <- colorRampPalette(c('gray','darkblue'))(5)

set.seed(43644)
ggraph(g.net, layout = "fr") +
  geom_edge_link0(aes(width = E(g.net)$weight), edge_colour=edge.cols[E(g.net)$weight]) +
  geom_node_point(shape = 21, size=igraph::degree(g.net)+3, fill='red') +
  theme_graph() +
  theme(legend.title = element_blank()) 
```

### Figure 6.15: Edge Direction {#Figure_6_15}

Fig. 6.15. Two methods of displaying directed ties using arrows (a) and arcs (c). Both of these simple networks represent the same relationships shown in the adjacency matrix in the center (b).

See the tutorial above for more details on using arrows in ggraph.

```{r Fig6_15, warning=F, message=F}

library(igraph)
library(grid)
library(gridExtra)

g <- graph( c("A", "B",
              "B", "C",
              "A", "C",
              "A", "A",
              "C","B",
              "D","C"))

layout(matrix(c(1,1,2,3,3), 1, 5, byrow = TRUE))

set.seed(4355467)
plot(g, edge.arrow.size=1, vertex.color="black", vertex.size=50, 
     vertex.frame.color="gray", vertex.label.color="white", edge.width=2, 
     vertex.label.cex=2.75, vertex.label.dist=0, vertex.label.family='Helvetica') 

plot.new()
adj1 <- as.data.frame(as.matrix(as_adjacency_matrix(g)))
tt2 <- ttheme_minimal(base_size=25)
grid.table(adj1,theme=tt2) 

plot(g, edge.arrow.size=1.25, vertex.color="black", vertex.size=50, 
     vertex.frame.color="gray", vertex.label.color="white", edge.width=2, 
     edge.curved=0.3,
     vertex.label.cex=2.75, vertex.label.dist=0, vertex.label.family='Helvetica') 
```

### Figure 6.16: Edge Binarization{#Figure_6_16}

Fig. 6.16. These networks all show the same data based on similarity scores among sites in the U.S. Southwest (ca. A.D. 1350-1400) but each has a different cutoff for binarization.

The following chunk of code uses [ceramic similarity data from the SWSN database](data/Figure6_16.Rdata) and defines three different cutoff thresholds for defining edges.

```{r Fig6_16, warning=F, message=F, fig.height=4, fig.width=12}

library(igraph)
library(statnet)
library(intergraph)
library(ggraph)
library(ggpubr)

load("data/Figure6_16.Rdata")
# Contains similarity matrix AD1350sim

AD1350sim_cut0_5 <- asIgraph(network(event2dichot(AD1350sim, method="absolute", thresh=0.25), directed=FALSE))
AD1350sim_cut0_75 <- asIgraph(network(event2dichot(AD1350sim, method="absolute", thresh=0.5), directed=FALSE))
AD1350sim_cut0_9 <- asIgraph(network(event2dichot(AD1350sim, method="absolute", thresh=0.75), directed=FALSE))

set.seed(4637)
g0.50 <- ggraph(AD1350sim_cut0_5, layout="fr") +
  geom_edge_link0(edge_colour="black") +
  geom_node_point(shape = 21, fill='gray') +
  ggtitle("0.25") +
  theme_graph() 

set.seed(574578)
g0.75 <- ggraph(AD1350sim_cut0_75, layout="fr") +
  geom_edge_link0(edge_colour="black") +
  geom_node_point(shape = 21, fill='gray') +
  ggtitle("0.50") +
  theme_graph() 

set.seed(7343)
g0.90 <- ggraph(AD1350sim_cut0_9, layout="fr") +
  geom_edge_link0(edge_colour="black") +
  geom_node_point(shape = 21, fill='gray') +
  ggtitle("0.75") +
  theme_graph() 

ggarrange(g0.50, g0.75, g0.90, nrow=1, ncol=3)

```

### Figure 6.17: Edge Bundling {#Figure_6_17}

Fig. 6.17. Network map of ceramic similarity from the U.S. Southwest/Mexican Northwest ca. A.D. 1350-1400 based on the hammer bundling algorithm. 

This function relies on the "edgebundle" package to combine sets of nodes with similar relations into single paths. [Use these data](data/Figure6_17.Rdata) to follow along. Note that this procedure can take several seconds to a few minutes depending on the speed of your computer. Note that this figure will look somewhat different from the one in the book as the locations of sites have been jittered for data security

```{r Fig6_17, fig.width=8, fig.height=8, warning=F, message=F}

library(igraph)
library(ggraph)
library(edgebundle)
library(ggmap)
library(sf)

load('data/Figure6_17.Rdata')
# attr.dat - site attribute data
# g.net - igraph network object
load('data/map.RData')
# map3 - state outlines
# base2 - terrain basemap in black and white

locations_sf <- st_as_sf(attr.dat, coords = c("V3", "V4"), crs = 26912)
z <- st_transform(locations_sf,crs=4326)
coord1 <- do.call(rbind, st_geometry(z)) %>% 
  tibble::as_tibble() %>% setNames(c("lon","lat"))

xy <- as.data.frame(coord1)
colnames(xy) <- c('x','y')

hbundle <- edge_bundle_hammer(g.net,xy,bw =0.9, decay = 0.2)

ggmap(base2,darken=0.15) +
  geom_polygon(data=map3, aes(x, y, group=Group.1),col="black",size=0.5,fill=NA) +
  geom_path(data = hbundle,aes(x,y,group=group),color="white", show.legend = F) +
  geom_path(data = hbundle,aes(x,y,group=group),color="darkorchid4",  show.legend = F) +
  geom_point(data = xy,aes(x,y),alpha=0.4, size=2.5, show.legend=F) +
  theme_graph()
```

### Figure 6.18: Group-in-a-box {#Figure_6_18}

Fig. 6.18. Example of a group-in-a-box custom graph layout created in NodeXL based on ceramic similarity data from the U.S. Southwest/Mexican Northwest ca. AD 1350-1400. 

The group-in-a-box network format is, as far as we are aware, currently only implemented in the [NodeXL](https://www.smrfoundation.org/nodexl/) platform. This software package is an add-in for Microsoft Excel that allows for the creation and analysis of network graphs using a wide variety of useful visualization tools. To produce a "Group-in-a-box" layout you simply need to paste a set of edge list values into the NodeXL Excel Template, define groups (based on an algorithm or some vertex attribute), and the be sure to select "Layout each of the graph's groups in its own box" in the layout options. 

For more details on how to use NodeXL see the extensive documentation online. There are commercial versions of the software available but the group-in-a-box example shown here can be produced in the free version.

![](images/group-in-a-box.jpg) 

To download an Excel workbook set up for the example provided in the book [click here]("data/NodeXLGraph1.xlsx").

### Figure 6.19: Weighted Adjacency Matrix {#Figure_6_19}

Fig. 6.19. Dual display of a network graph and associated weighted adjacency matrix based on Peeples (2018) ceramic technology data.

This plot uses a sub-set of the Cibola technological similarity network data to produce both a typical node-link diagram and an associated weighted adjacency matrix. [Use these data](data/Figure6_19.Rdata) to follow along.

```{r Fig6_18, fig.width=12, fig.height=6, warning=F, message=F}

library(igraph)
library(ggraph)
library(ggpubr)

load("data/Figure6_19.Rdata")
# graph6.18 - graph object in igraph format
# node_list - dataframe with node details
# edge_list - edge_list which contains information on groups and edge weight

set.seed(343645)
coords <- layout_with_fr(graph6.18)
g1 <- ggraph(graph6.18, "manual",
       x=coords[,1],
       y=coords[,2]) +
  geom_edge_link(aes(),color='gray75',alpha=0.5,show.legend=F) +
  geom_node_point(aes(color=as.factor(V(graph6.18)$comm), size=5), show.legend=F) +
  scale_color_manual(values=c('#8da0cb','#66c2a5','#fc8d62'), guide=F) +
  theme_graph()

# Set order of nodes to order in which they appear in the y axis in the network graph above
name_order <- node_list[order(coords[,2]),]$name

# Adjust the 'to' and 'from' factor levels so they are equal
# to this complete list of node names
plot_data <- edge_list %>% mutate(
  to = factor(to, levels = name_order),
  from = factor(from, levels = rev(name_order)))

# Now run the ggplot code again
# Create the adjacency matrix plot
g2 <- ggplot(plot_data, aes(x = from, y = to, fill = group, alpha = (weight*1.5))) +
  geom_tile() +
  theme_bw() +
  scale_x_discrete(drop = FALSE) +
  scale_y_discrete(drop = FALSE) +
  theme(axis.text.x = element_text(angle = 270, hjust = 0, size=10),
        axis.text.y = element_text(size=10),
        aspect.ratio = 1, 
        legend.position = "none") +
  xlab('') +
  ylab('') +
  scale_fill_manual(values=c('#8da0cb','#66c2a5','#fc8d62','black'), guide=F)

# Combine into a single figure
figure6_19 <- ggarrange(g1,g2,nrow=1)

figure6_19
```

### Figure 6.20: Nodetrix Diagram {#Figure_6_20}

Fig. 6.20. Nodetrix visualization of the Peeples (2018) ceramic technological data showing one dense cluster as an adjacency matrix and the remainder of the graph as a node-link diagram.

This Nodetrix interactive visualization was created using the Javascript implementation available on [GitHub](https://github.com/IRT-SystemX/nodetrix) by user [jdfekete](https://github.com/jdfekete/), Jean-Daniel Fekete who was one of the original authors of the method (Henry et al. 2007). 

The details of running the Javascript program are described on the GitHub page and are beyond this scope of this tutorial. We do illustrate below, however, how you can export R in the *.json format required by this program using the "d3r" and "rjson" packages. 

```{r Fig6_20, warning=F, message=F, eval=F}

library(d3r)
library(rjson)

# net <- igraph network object

data_json <- d3_igraph(net)


  dj <- jsonlite::fromJSON(data_json)
  dj$links[[1]] <- as.numeric(dj$links[[1]]) 
  dj$links[[2]] <- as.numeric(dj$links[[2]]) 
  dj <- jsonlite::toJSON(dj)

write(dj, "network.json")
```

### Figure 6.21: The Filmstrip Approach {#Figure_6_21}

Fig. 6.21. A demonstration of the filmstrip approach to plotting longitudinal network data. These data represent networks of ceramic similarity in the San Pedro Valley of Arizona for three consecutive 50-year intervals. 

[Use these data](data/Figure6_21.Rdata) to replicate the figures shown here.

```{r Fig6_21, fig.width=16, fig.height=6, warning=F, message=F}
library(igraph)
library(ggraph)
library(ggpubr)

load("data/Figure6_21.Rdata")

set.seed(4543)
g1 <- ggraph(AD1250net, "kk") +
  geom_edge_link(aes(),color='gray75',show.legend=F) +
  geom_node_point(aes(), size=5, show.legend=F, color="blue") +
  ggtitle("AD1250-1300") +
  theme_graph()

set.seed(4543)
g2 <- ggraph(AD1300net, "kk") +
  geom_edge_link(aes(),color='gray75',show.legend=F) +
  geom_node_point(aes(), size=5, show.legend=F, color="blue") +
  ggtitle("AD1300-1350") +
  theme_graph()


set.seed(4543)
g3 <- ggraph(AD1350net, "kk") +
  geom_edge_link(aes(),color='gray75',show.legend=F) +
  geom_node_point(aes(), size=5, show.legend=F, color="blue") +
  ggtitle("AD1350-1400") +
  theme_graph()

figure6_21 <- ggarrange(g1,g2,g3, nrow=1)

figure6_21
```

### Figure 6.22: Similtaneous Display {#Figure_6_22}

Fig. 6.22. Examples of simultaneous display of two consecutive intervals for the San Pedro valley ceramic similarity network. A) A network using the Kamada-Kawai algorithm with edges color coded based on time period. B) An arc plot showing ties in consecutive intervals above and below the line.

[Use these data](data/Figure6_22.Rdata) to follow along.

```{r, warning=F, message=F, fig.height=6, fig.width=16}

library(igraph)
library(ggraph)
library(ggpubr)
library(ggrepel)

load("data/Figure6_22.Rdata")

graph <- graph_from_data_frame(net.all)

xy <- layout_with_kk(graph)
xy <- cbind(sites,xy)
xy <- as.data.frame(xy)
colnames(xy) <- c('site','x','y')
xy$x <- as.numeric(xy$x)
xy$y <- as.numeric(xy$y)

set.seed(6436)
similt.net <- ggraph(graph,layout="manual",
                     x=xy$x, y=xy$y) + 
  geom_edge_link(aes(colour = Period), alpha=0.3, width=1.5) + 
    geom_node_point(size=8) +
  geom_text_repel(aes(x=x, y=y, label=site), data=xy, size=5) +
  theme_graph() +
  theme(legend.title = element_text(size=14),
        legend.text = element_text(size=14),
        legend.key.height= unit(1, 'cm'),
        legend.key.width= unit(2, 'cm'))

# Make the graph
lin.net <- ggraph(SPgraph, layout="linear") + 
  geom_edge_arc(edge_colour="black", edge_alpha=0.4, edge_width=0.3, fold=F, strength=1) +
  geom_node_point(aes(size=igraph::degree(SPgraph)), col='red', alpha=0.5) +
  scale_size_continuous(range=c(4,8)) +
  theme_graph() +
  theme(legend.title=element_blank(), plot.margin=unit(c(0,0,0.4,0), "null"),
    panel.spacing=unit(c(0,0,3.4,0), "null")) +
  annotate("text", x = 3, y = 3, label = "AD 1250-1300",size=6) +
  annotate("text", x = 3, y = -3, label = "AD 1300-1350",size=6) 


figure6_22 <- ggarrange(similt.net,lin.net, labels=c('(a)','(b)'), font.label=list(size=28))

figure6_22
```

### Figure 6:23: Timelines and Time Prisms {#Figure_6_23}

Fig. 6.23. This plot shows two displays of the same ceramic similarity data from the Sonoran Desert in the U.S. Southwest as a time prism (top) and timeline (bottom).

[Use these data](data/Figure6_23.Rdata) to follow along.

```{r Fig6_23, warning=F, message=F}

library(networkDynamic)
library(ndtv)
library(GISTools)
library(statnet)

load("data/Figure6_23.Rdata")

# create networkDynamic object from list containing multiple sna network objects
SanPedro <- networkDynamic(network.list=SP_nets)

# Compute animation
compute.animation(SanPedro,default.dist=7,animation.mode='MDSJ')

# Define colors for regions
mycol <- c(add.alpha('#1b9e77',0.75),add.alpha('#d95f02',0.75),add.alpha('#7570b3',0.75),
           add.alpha('#e7298a',0.75),add.alpha('#66a61e',0.75),add.alpha('#e6ab02',0.75))

# Plot time prism
set.seed(364467)
timePrism(SanPedro,at=c(1,2,3),
          displaylabels=F,planes = TRUE, display.isolates=F,
          label.cex=0.5, usearrows=F,vertex.cex=0.5, edge.col='gray50',vertex.col=mycol[factor(SP_attr$SWSN_MacroGroup)])

# Plot proximity timeline
set.seed(235254)
proximity.timeline(SanPedro,default.dist=10,
                   mode='sammon',labels.at=17,vertex.cex=4,render.edges=F, vertex.col=mycol[factor(SP_attr$SWSN_MacroGroup)],
                   chain.direction = 'reverse',xaxt='n')
```

### Figure 6.24: Animation {#Figure_6_24}

Fig. 6.24. An example of three frames from a network animation. 

Figure 6.24 was created using the ndtv package and the same data produced above for figure 6.23. We simply rendered the animation as above and then output to an interactive html widget. The figure in the book represents 3 screen shots from the video. See the ndtv documentation for more details.

```{r Fig6_24, warning=F, message=F, eval=T, results='asis'}
render.d3movie(SanPedro, vertex.col=mycol[factor(SP_attr$SWSN_MacroGroup)], output.mode = "inline")
```

### Figure 6.25: Interactive Networks {#Figure_6_25}

Fig. 6.25. An example of a dynamic network visual created in R. Notice how the nodes and edges are responding to the movement of the edge under the cursor and the drop down menu that allows selection of nodes by group.

For this example we closely follow an example provided on the [Static and dynamic network visualization with R](https://kateto.net/network-visualization) workshop documents online but using the [Cibola technological similarity data](data/Figure6_25.Rdata) instead.

```{r Fig6_25, warning=F, message=F, fig.height=8, fig.width=8}

library(visNetwork)
library(networkD3)
library(igraph)

load("data/Figure6_25.Rdata") # Contains an igraph graph object

# Use igraph to make the graph and find membership
clust <- cluster_louvain(graph)
members <- membership(clust)

# Convert to object suitable for networkD3
graph_d3 <- igraph_to_networkD3(graph, group = members)

# Create force directed network plot
forceNetwork(Links = graph_d3$links, Nodes = graph_d3$nodes, 
             Source = 'source', Target = 'target', 
             NodeID = 'name', Group = 'group')


# Modify interactive network to allow highlighting by groups, etc.
links <- graph_d3$links
colnames(links) <- c('from','to')
links[,1] <- links[,1]+1
links[,2] <- links[,2]+1
nodes <- graph_d3$nodes
colnames(nodes)[1] <- 'id'

vis.nodes <- nodes
vis.links <- links

vis.nodes$shape  <- "dot"  
vis.nodes$shadow <- TRUE # Nodes will drop shadow
vis.nodes$borderWidth <- 2 # Node border width

vis.nodes$color.background <- c("slategrey", "tomato", "gold", "purple")[nodes$group]
vis.nodes$color.border <- "black"
vis.nodes$color.highlight.background <- "orange"
vis.nodes$color.highlight.border <- "darkred"

visnet <- visNetwork(vis.nodes, vis.links)

visOptions(visnet, highlightNearest = TRUE, selectedBy = "group")
```

### Figure 6.26: SWSN Example 1

Fig. 6.26. Networks by time for the SWSN project area (from Mills et al. 2013).

The figure for the original plot in Mills et al. 2013 was produced in R and then compiled and modified using Adobe Illustrator. First a regional color scheme was defined and then each time period was plotted using this color scheme. In Illustrator components were arranged in rough geographic positions and isolates were placed at the margin.

The following chunk of code reproduces Figure 6.26 for one time period (AD1300-1350). [Download these data](data/Figure6_26.Rdata) to follow along.

```{r, warning=F, message=F, fig.width=10, fig.height=10}

library(statnet)
library(ggraph)

load("data/Figure6_26.Rdata")

# Create sna network object
net <- network(event2dichot(sim, method="absolute", thresh=0.75), directed=F)

# define color scheme. colors listed in order based on the factor attr$Macro
myCols <- c("#000738", "#ffa1a1", "#ad71d8", "#016d1b", "#00ff30", "#92d8ff", "#ffffff",
            "#adadad", "#846b00", "#ff0000", "#5273dd", "#946a43", "#a00000", "#f97c00",
            "#00ffec", "#ffff3e", "#824444", "#00ba89", "#00ba89", "#0303ff")

# Plot network
set.seed(235)
ggraph(net, layout="fr") +
  geom_edge_link(alpha=0.5)+
  geom_node_point(aes(fill=as.factor(attr$Macro), size=evcent(net)), shape=21, show.legend = F) +
  scale_size(range=c(1.5,3)) +
  scale_fill_manual(values = myCols) +
  theme_graph()


```

### Figure 6.27: SWSN Example 2

Fig. 6.27. An explicit geographic map network of the SWSN project area through time (Mills et al. 2013).

The original version of this figure was produced in ArcGIS using data prepared in R. Here we show how these same network maps with edges color coded by geogrpahic length can be produced in R. We provide code to prepare a map for one time period (AD1300-1350). [Use these data](data/Figure6_27.Rdata) to follow along. Note that this figure will differ slightly from the one in the book and in the original Mills et al. 2013 publication as site locations have been jittered. 

```{r, warning=F, message=F, fig.width=12, fig.height=12}
library(statnet)
library(igraph)
library(intergraph)
library(ggmap)
library(sf)

# Load in network and map data
load("data/Figure6_27.Rdata")

# prepare network object
net <- network(event2dichot(sim,method='absolute',thresh=0.75),directed=F)
r.net <- asIgraph(net)

# convert coordinates to lat/long and covert to sf object
locations_sf <- st_as_sf(attr, coords = c("EASTING", "NORTHING"), crs = 26912)
z <- st_transform(locations_sf,crs=4326)
coord1 <- do.call(rbind, st_geometry(z)) %>% 
  tibble::as_tibble() %>% setNames(c("lon","lat"))

# output coordinates in dataframe
xy <- as.data.frame(coord1)
colnames(xy) <- c('x','y')

# Create edgelist with xy coordinates for each source and target
edgelist2 <- get.edgelist(r.net)
edges2 <- data.frame(xy[edgelist2[,1],], xy[edgelist2[,2],])
colnames(edges2) <- c("X1","Y1","X2","Y2")

# Determine the geographic distances of edges
dist.meas <- NULL
for (i in 1:nrow(edges2)) {
  temp <- as.matrix(edges2[i,])
  dist.meas[i] <- as.numeric(dist(rbind(temp[1,1:2],temp[1,3:4])))/0.009
}

# Order edges so shorest will plot last
net.dat <- as.data.frame(cbind(edges2,dist.meas))
net.dat <- net.dat[order(net.dat$dist.meas,decreasing=T),]

# Create bins in distance measurement
net.dat <- net.dat %>% mutate(DistBins = cut(dist.meas, breaks = c(-Inf,25,100,250,Inf)))

# Plot network map
ggmap(base2,darken=0.5) +
  geom_polygon(data=map3, aes(x, y, group=Group.1),col="black",size=0.5,fill=NA) +
  geom_segment(data = net.dat, aes(x=X1, y=Y1, xend=X2, yend=Y2,col=DistBins), size=0.15, show.legend=F) +
  scale_color_manual(values = c("white","skyblue","dodgerblue","darkblue")) +
  theme_graph()
```


<!--chapter:end:05-visualization.Rmd-->

# Spatial Networks

This section follows along with Chapter 7 of Brughmans and Peeples (2022) to provide information on how to implement spatial network models and analyses in R.

## Dataset and Setup

For the initial examples in this section we will use the Roman Road data from the Iberian Penninsula. This dataset consists of a [csv file of a set of Roman settlements](data/Hispania_nodes.csv) and a [csv file of an edge list](data/Hispania_roads) defining connections among those settlements in terms of roads.

```{r spatial_networks, warning=F, message=F, fig.height=6, fig.width=8}

library(igraph)
library(ggmap)
library(sf)

edges1 <- read.csv("data/Hispania_roads.csv", header=T)
nodes <- read.csv("data/Hispania_nodes.csv", header=T)

road_net <- graph_from_edgelist(as.matrix(edges1[,1:2]), directed=FALSE)

# Convert attribute location data to sf coordinates
locations_sf <- st_as_sf(nodes, coords = c("long", "lat"), crs = 4326)
coord1 <- do.call(rbind, st_geometry(locations_sf)) %>% 
  tibble::as_tibble() %>% setNames(c("lon","lat"))

xy <- as.data.frame(coord1)
colnames(xy) <- c('x','y')

# Extract edgelist from network object
edgelist <- get.edgelist(road_net)

# Create dataframe of beginning and ending points of edges
edges <- as.data.frame(matrix(NA,nrow(edgelist),4))
colnames(edges) <- c("X1","Y1","X2","Y2")
for (i in 1:nrow(edgelist)) {
edges[i,] <- c(nodes[which(nodes$Id==edgelist[i,1]),3],nodes[which(nodes$Id==edgelist[i,1]),2],
               nodes[which(nodes$Id==edgelist[i,2]),3],nodes[which(nodes$Id==edgelist[i,2]),2])
}

myMap <- get_stamenmap(bbox = c(-9.5,36,3,43.8),maptype = "watercolor",zoom = 6)

ggmap(myMap) +
  geom_segment(data = edges, aes(x=X1, y=Y1, xend=X2, yend=Y2), col='black', size=1) +
  geom_point(data = xy, aes(x,y), alpha=0.8, col='black', fill="white", shape=21, size=2, show.legend=F) +
  theme_void()
```

## Planar Networks and Trees

### Evaluating Planarity

A planar network is a network that can be drawn on a plane where the edges do not cross but instead always end in nodes. In many small networks it is relatively easy to determine whether or not a network is planar by simply viewing a network graph. In larger graphs, this can sometimes be difficult. 

There is a package available for R called RBGL which is an R implementation of something called the Boost Graph Library. This set of routines includes many powerful tools for characterizing network topology including planarity. This package is not, however, in the CRAN archive where the packages we have worked with so far reside so it needs to be installed from another archive called Bioconductor. In order to install this libary, run the following lines of code.

```{r, eval=F, fig.height=6, fig.width=8, warning=F, message=F}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("RBGL")
```

With this in place we can now preform an analysis called the Boyer-Myrvold planarity test (Boyer and Myrvold 2004). This analysis performs a set of operations on a graph structure to evaluate whether or not it can be defined as a planar graph (see publication for more details).

Let's take a look at our Roman Road data.

```{r, warning=F, message=F, fig.height=6, fig.width=8}
library(RBGL)

# First convert to a graphNEL object for planarity test
g <- as_graphnel(road_net)
# Implement test
boyerMyrvoldPlanarityTest(g)
```

This results suggests that our Roman Road data is not planar. We can plot the data to evaluate this and do see crossed edges that could not be repositioned. 

```{r, warning=F, message=F, fig.height=6, fig.width=8}
library(ggraph)

set.seed(5364)
ggraph(road_net, layout='kk') +
  geom_edge_link() +
  geom_node_point(size=3) +
  ggtitle("Network of Roman Roads") +
  theme_graph()
```

Now, by way of example, we can generate a small random network that is planar and see the results of the test. Note that in the network graph that is produced the visual is not planar but could be a small number of nodes were moved. Unfortunately planar graph drawing is not currently implemented into igraph or other packages so you cannot automatically plot a graph as planar even if it meets the criteria of a planar graph. 

```{r, fig.height=6, fig.width=8}
set.seed(49)
g <- erdos.renyi.game(20, 1/8)

set.seed(939)
ggraph(g, layout="stress") +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()

g <- as_graphnel(g)
boyerMyrvoldPlanarityTest(g)
```

Here is another example where the graph layout algorithm happens to produce a planar graph.

```{r, fig.height=6, fig.width=8}
set.seed(4957)
g <- erdos.renyi.game(20, 1/8)

set.seed(939)
ggraph(g, layout="stress") +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()

g <- as_graphnel(g)
boyerMyrvoldPlanarityTest(g)
```

### Defining Trees

A tree is a network that is connected and acyclic. Trees contain the minimum number of edges for a set of nodes to be connected, which results in an acyclic network with some interesting properties:

* Every edge in a tree is a bridge, in that its removal would increase the number of components (see section 4.4.5).
* The number of edges in a tree is equal to the number of nodes minus one.
* There can be only one single path between every pair of nodes in a tree.

In R using the igraph package it is possible to both generate trees and also to take an existing network and define what is called the minimum spanning tree of that graph or the minimum acyclic component. 

Let's create a simple tree using the "make_tree" function in igraph.

```{r, fig.height=6, fig.width=8}
tree1 <- make_tree(n=50, children=5, mode="undirected")
tree1

plot(tree1)
```

In the example here you can see the branch and leaf structure of the network where there are central nodes that are hubs to a number of other nodes and so on, but there are no cycles back to the previous nodes. Thus, such a tree is inherently hierarchical.In the next sub-section, we will discuss the use of minimum spanning trees.

It is also possible plot trees with a heirarchical network layout where nodes are arranged at levels of the hierarchy. In this case you need to specify the node or nodes that represent the first layer using the "root" call within the ggraph call. 

```{r, warning=F, message=F,fig.height=6, fig.width=8}
ggraph(tree1, layout = 'igraph', algorithm = 'tree', root=1) + 
  geom_edge_diagonal(edge_width = 0.5, alpha =.4) +
  geom_node_text(aes(label = V(tree1)), size=3.5) +
  theme_void() 
```



## Spatial Network Models

In Chapter 7.5 in Brughmans and Peeples (2022) we go over a series of spatial network models that provide a number of different ways of defining networks from spatial data. In this sub-section we demonstrate how to define and analyze networks using these approaches. 

### Relative Neighborhood Networks 

Relative neighborhood graph: a pair of nodes are connected if there are no other nodes in the area marked by the overlap of a circle around each node with a radius equal to the distance between the nodes.

The R package cccd contains functions to define relative neighborhood networks from distance data using the "rng" function. This function can either take a distance matrix object as created above or a set of coordinates to calculate the distance within the call. The output of this function is an igraph object. For large graphs it is also possible to limit the search for possible neighbors to k neighbors. 

Let's use our previously created distance matrix and plot the results. 


```{r, message=F, warning=F, fig.height=6, fig.width=8}
library(cccd)

rng1 <- rng(nodes[,c(3,2)])

ggraph(rng1, layout="kk") +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()
```

We can also plot the results using geographic coordinates.

```{r, fig.height=6, fig.width=8}
ggraph(rng1, layout="manual",
       x=nodes[,3], y=nodes[,2]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()
```

### Gabriel Graphs

Gabriel graph: a pair of nodes are connected in a Gabriel graph if no other nodes lie within the circular region with a diameter equal to the distance between the pair of nodes.

Again we can use a function in the cccd package to define Gabriel Graph igraph objects from x and y coordinates. Let's take a look using the Roman Road data. See ?gg for details on the options including different algorithms for calculating Gabriel Graphs. We define a Gabriel graph here and plot it using an algorithmic layout and then geographic coordinates.

```{r, fig.height=6, fig.width=8}
gg1 <- gg(x=nodes[,c(3,2)])

ggraph(gg1, layout="stress") +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()

ggraph(gg1, layout="manual",
       x=nodes[,3], y=nodes[,2]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()
```

### Beta Skeletons

Beta skeleton: a Gabriel graph in which the diameter of the circle is controlled by a parameter beta.

In R the gg function for producing Gabriel Graphs has the procedure for beta skeletons built directly in. The argument r in the gg function controls the beta parameter. When r=1 a traditional Gabriel graph is returned. When the parameter r > 1 there is a stricter definition of connection resulting in fewer ties and when r < 1 link criteria are loosened. See ?gg for more details.

```{r, fig.height=6, fig.width=8}
beta_s <- gg(x=nodes[,c(3,2)], r=1.5)

ggraph(beta_s, layout="manual",
       x=nodes[,3], y=nodes[,2]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()
```

### Minimum Spanning Trees

Minimum spanning tree: in a set of nodes in the Euclidean plane, edges are created between pairs of nodes to form a tree where each node can be reached by each other node, such that the sum of the Euclidean edge lengths is less than the sum for any other spanning tree.

Perhaps the most common use-case for trees in archaeological networks is to define the minimum spanning tree of a given graph or the minimum set of nodes and edges required for a fully connected graph. The igraph package has a built-in function that defines the minimum spanning tree for a given graph. Let's try this with the Roman Road and then plot it as a node-link diagram and a map.

```{r, fig.height=6, fig.width=8}
mst_net <- igraph::mst(road_net)

set.seed(4643)
ggraph(mst_net, layout="kk") +
  geom_edge_link() +
  geom_node_point(size=4) +
  theme_graph()


# Extract edgelist from network object
edgelist <- get.edgelist(mst_net)

# Create dataframe of beginning and ending points of edges
edges <- as.data.frame(matrix(NA,nrow(edgelist),4))
colnames(edges) <- c("X1","Y1","X2","Y2")
for (i in 1:nrow(edgelist)) {
edges[i,] <- c(nodes[which(nodes$Id==edgelist[i,1]),3],nodes[which(nodes$Id==edgelist[i,1]),2],
               nodes[which(nodes$Id==edgelist[i,2]),3],nodes[which(nodes$Id==edgelist[i,2]),2])
}

ggmap(myMap) +
  geom_segment(data = edges, aes(x=X1, y=Y1, xend=X2, yend=Y2), col='black', size=1) +
  geom_point(data = nodes[,c(3,2)], aes(long,lat), alpha=0.8, col='black', fill="white", shape=21, size=1.5, show.legend=F) +
  theme_void()
```

Note that minimum spanning trees can also be used for weighted graphs such that weighted connections will be preferred in defining tree structure. See ?mst for more details.

### Delaunay Triangulation

Delaunay triangulation: a pair of nodes are connected by an edge if and only if their corresponding regions in a Voronoi diagram share a side.

Voronoi diagram or Thiessen polygons: for each node in a set of nodes in a Euclidean plane, a region is created covering the area that is closer or equidistant to that node than it is to any other node in the set.

The package deldir in R allows for the calculation of Delaunay triangles with x and y coordinates as input. By default the deldir function will define a boundary that extends slightly beyond the xy coordinates of all points included in the analysis. This boundary can also be specified within the call using the "rw" argument. See ?deldir for more details. 

The results of this function can be directly plotted and the output also contains coordinates necessary to integrate the results into another type of figure like a ggmap. Let's take a look.

```{r, warning=F, message=F, fig.height=6, fig.width=8}
library(deldir)

dt1 <- deldir(nodes[,3],nodes[,2])

plot(dt1)

# Extract Voronoi polygons for plotting
mapdat <- as.data.frame(dt1$dirsgs)
# Extract network for plotting
mapdat2 <- as.data.frame(dt1$delsgs)

ggmap(myMap) +
  geom_segment(data=mapdat, aes(x=x1, y=y1, xend=x2, yend=y2), col='black', size=1) +
  geom_segment(data=mapdat2, aes(x=x1, y=y1, xend=x2, yend=y2), col='red', size=1) +
  geom_point(data = nodes, aes(long,lat), alpha=0.8, col='black', fill="white", shape=21, size=3, show.legend=F) +
  theme_void()
```

### K-nearest Neighbors

K-nearest neighbor network: each node is connected to K other nodes closest to it.

The cccd package has a routine that allows for the calculation of K-nearest neighbor graphs from geographic coordinates or a precomputed distance matrix. In this example we use the Roman Road data and calculate K=1 and K=6 nearest neighbor networks and plot the both simultaneously.

```{r, warning=F, message=F, fig.height=6, fig.width=8}
# Calculate k=1 nearest neighbor graph
nn1 <- nng(x=nodes[,c(3,2)], k=1)

# Calculate k=6 nearest neighbor graph
nn6 <- nng(x=nodes[,c(3,2)], k=6)

EL1 <- as.data.frame(rbind(cbind(get.edgelist(nn6), rep("K=6", nrow(get.edgelist(nn1)))),
cbind(get.edgelist(nn1), rep("K=1", nrow(get.edgelist(nn1))))))
colnames(EL1) <- c("from","to","K")

g <- graph_from_data_frame(EL1)

# Plot both graphs
ggraph(g, layout="manual",
       x=nodes[,3], y=nodes[,2]) +
  geom_edge_link(aes(color=factor(K)), width=1.5) +
  geom_node_point(size=2) +
  labs(edge_color="K") +
  theme_graph()
```

### Maximum Distance Networks

Maximum distance network: each node is connected to all other nodes at a distance closer than or equal to a threshold value. In order define a maximum distance network we simply need to define a threshold distance and define all nodes greater than that distance as unconnected and nodes within that distance as connected. This can be done in base R using the dist function we used above.

Since the coordinates we are using here are in decimal degrees we need to calculate distances based on "great circles" across the globe rather than Euclidean distances on a projected plane. There is a function called "distm" in the "geosphere" package that allows us to do this. If you are working with projected data, you can simply use the "dist" function in the place of "distm" like the example below. 

Next, in order to define a minimum distance network we simply binarize this matrix. We can do this using the "event2dichot" function within the statnet package and easily create an R network objects. Let's try it out with the Roman Road data for thresholds of 100,000 and 250,000 meters.

```{r, warning=F, message=F, fig.height=6, fig.width=8}
library(statnet)
library(geosphere)

d1 <- distm(nodes[,c(3,2)])

# Note we use the leq=TRUE argument here as we want nodes less than the threshold to count.
net100 <- network(event2dichot(d1, method='absolute', thresh=100000, leq=TRUE), directed=F)
net250 <- network(event2dichot(d1, method='absolute', thresh=250000, leq=TRUE), directed=F)

# Plot 100 Km network
ggraph(net100, layout="manual",
       x=nodes[,3], y=nodes[,2]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()

# Plot 250 Km network
ggraph(net250, layout="manual",
       x=nodes[,3], y=nodes[,2]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()
```

## Case Studies

### Proximity of Iron Age sites in Southern Spain

The first case study in Chapter 7 of Brughmans and Peeples (2022) is an example of several of the methods for defining networks using spatial data outlined above using the locations of 86 sites in the Guadalquivir river valley in Southern Spain. In the code chunks below, we replicate the analyses presented in the book.

First we read in the data which represents site location information in lat/long decimal degrees.

```{r}
guad <- read.csv("data/Guadalquivir.csv", header=TRUE)
```

Next we create a distance matrix based on the decimal degrees locations using the "distm" function.

```{r, message=F, warning=F, fig.height=6, fig.width=8}
library(geosphere)

g_dist1 <- as.matrix(distm(guad[,c(2,3)]))

g_dist1[1:4,1:4]
```

From here we can create maximum distance networks at both the 10km and 18km distance and plot it using the geographic location of nodes for node placement.

```{r, message=F, warning=F, fig.height=6, fig.width=8}
library(intergraph)

# Note we use the leq=TRUE argument here as we want nodes less than the threshold to count.
net10 <- asIgraph(network(event2dichot(g_dist1, method='absolute', thresh=10000, leq=TRUE), directed=F))
net18 <- asIgraph(network(event2dichot(g_dist1, method='absolute', thresh=18000, leq=TRUE), directed=F))

g10_deg <- as.data.frame(igraph::degree(net10))
colnames(g10_deg) <- 'degree'
g18_deg <- as.data.frame(igraph::degree(net18))
colnames(g18_deg) <- 'degree'

# Plot histogram of degree for 10km network
h10 <- ggplot(data=g10_deg) +
  geom_histogram(aes(x=degree),bins=15)

# Plot histogram of degree for 18km network
h18 <- ggplot(data=g18_deg) +
  geom_histogram(aes(x=degree),bins=15)

# Plot 10 Km network
g10 <- ggraph(net10, layout="manual",
       x=guad[,2], y=guad[,3]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()

# Plot 18 Km network
g18 <- ggraph(net18, layout="manual",
       x=guad[,2], y=guad[,3]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()

g18
```

If we want to combine the degree distribution plot and the network into the same frame, we can use the "inset_element" function in the "patchwork" library.

```{r, message=F, warning=F, fig.height=6,fig.width=10}
library(patchwork)
plot_a <- g10 + inset_element(h10, left = 0, bottom = 0.7, right = 0.25, top = 0.99)
plot_b <- g18 + inset_element(h18, left = 0, bottom = 0.7, right = 0.25, top = 0.99)
plot_a
plot_b
```

Next, we calculate a relative neighborhood graph for the site locations and plot it with nodes positioned in geographic space.

```{r, fig.height=6, fig.width=8}
rng1 <- rng(guad[,2:3])

g_rng <- ggraph(rng1, layout="manual",
       x=guad[,2], y=guad[,3]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()

g_rng_deg <- as.data.frame(igraph::degree(rng1))
colnames(g_rng_deg) <- 'degree'

# Plot histogram of degree for relative neighborhood network
h_rng <- ggplot(data=g_rng_deg) +
  geom_histogram(aes(x=degree),bins=3)

plot_c <- g_rng + inset_element(h_rng, left = 0, bottom = 0.7, right = 0.25, top = 0.99)

plot_c
```

The chunk of code below then calculates and plots the Gabrial graph with the associated degree distribution plot.

```{r, fig.height=6, fig.width=8}
gg1 <- gg(x=guad[,2:3])

g_gg <- ggraph(gg1, layout="manual",
       x=guad[,2], y=guad[,3]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()

g_gg_deg <- as.data.frame(igraph::degree(gg1))
colnames(g_gg_deg) <- 'degree'

# Plot histogram of degree for relative neighborhood network
h_gg <- ggplot(data=g_gg_deg) +
  geom_histogram(aes(x=degree),bins=5)

plot_d <- g_gg + inset_element(h_gg, left = 0, bottom = 0.7, right = 0.25, top = 0.99)

plot_d
```

And we'll combine these four plots into a single figure.

```{r, message=F, warning=F, fig.width=12, fig.height=10}
library(ggpubr)

ggarrange(plot_a,plot_b,plot_c,plot_d,nrow=2,ncol=2)
```

Next, we'll plot the K-nearest neighbors graphs for k= 2, 3, 4, and 6 with the associated degree distribution for each.

```{r, warning=F, message=F, fig.height=10, fig.width=12}
# Calculate k=2,3,4, and 6 nearest neighbor graphs
nn2 <- nng(x=guad[,2:3], k=2)
nn3 <- nng(x=guad[,2:3], k=3)
nn4 <- nng(x=guad[,2:3], k=4)
nn6 <- nng(x=guad[,2:3], k=6)

# Initialiize network graph for each k value
g_nn2 <- ggraph(nn2, layout="manual",
       x=guad[,2], y=guad[,3]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()

g_nn3 <- ggraph(nn3, layout="manual",
       x=guad[,2], y=guad[,3]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()

g_nn4 <- ggraph(nn4, layout="manual",
       x=guad[,2], y=guad[,3]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()

g_nn6 <- ggraph(nn6, layout="manual",
       x=guad[,2], y=guad[,3]) +
  geom_edge_link() +
  geom_node_point(size=2) +
  theme_graph()

# Set up dataframes of degree distribution for each network
nn2_deg <- as.data.frame(igraph::degree(nn2))
colnames(nn2_deg) <- 'degree'
nn3_deg <- as.data.frame(igraph::degree(nn3))
colnames(nn3_deg) <- 'degree'
nn4_deg <- as.data.frame(igraph::degree(nn4))
colnames(nn4_deg) <- 'degree'
nn6_deg <- as.data.frame(igraph::degree(nn6))
colnames(nn6_deg) <- 'degree'

# Initialize histogram plot for each degree distribution
h_nn2 <- ggplot(data=nn2_deg) +
  geom_histogram(aes(x=degree),bins=5) +
  scale_x_continuous(limits = c(0, max(nn2_deg)))
h_nn3 <- ggplot(data=nn3_deg) +
  geom_histogram(aes(x=degree),bins=6)+
  scale_x_continuous(limits = c(0, max(nn3_deg)))
h_nn4 <- ggplot(data=nn4_deg) +
  geom_histogram(aes(x=degree),bins=6)+
  scale_x_continuous(limits = c(0, max(nn4_deg)))
h_nn6 <- ggplot(data=nn6_deg) +
  geom_histogram(aes(x=degree),bins=5)+
  scale_x_continuous(limits = c(0, max(nn6_deg)))

plot_a <- g_nn2 + inset_element(h_nn2, left = 0, bottom = 0.7, right = 0.25, top = 0.99)
plot_b <- g_nn3 + inset_element(h_nn3, left = 0, bottom = 0.7, right = 0.25, top = 0.99)
plot_c <- g_nn4 + inset_element(h_nn4, left = 0, bottom = 0.7, right = 0.25, top = 0.99)
plot_d <- g_nn6 + inset_element(h_nn6, left = 0, bottom = 0.7, right = 0.25, top = 0.99)


library(ggpubr)

ggarrange(plot_a,plot_b,plot_c,plot_d,nrow=2,ncol=2)
```


### Networks in Space in the U.S. Southwest

The second case study in Chapter 7 of Brughmans and Peeples (2022) provides an example of how we can use spatial network methods to analyze material cultural network data. We use the Chaco World data here and you can download the [map data](data/map.RData), [the site attribute data](data/AD1050attr.csv), and [the ceramic frequency data](data/AD1050cer.csv) to follow along.

The first analysis expores the degree to which similarities in ceramics (in terms of Brainerd-Robinson similarity based on wares) can be explained by spatial distance. To do this we simply define a ceramic similarity matrix, a Euclidean distance matrix, and the fit a model using distance to explain ceramic similarity using a general additive model (gam) approach. The gam function we use here is in the mgcv package. Note that the object "dmat" is created using the "dist" function as the data we started with are already projected site locations using UTM coordinates. 

```{r, warning=F, message=F}
library(mgcv)

load('data/map.RData')
attr <- read.csv('data/AD1050attr.csv',row.names=1)
cer <- read.csv('data/AD1050cer.csv', header=T, row.names=1)
sim <- (2-as.matrix(vegan::vegdist(prop.table(as.matrix(cer),1), method='manhattan')))/2
dmat <- as.matrix(dist(attr[,9:10]))

fit <- gam(as.vector(sim)~as.vector(dmat))
summary(fit)
```

As these results show and as described in the book, spatial distance is a statistically significant predictor of ceramic similarity and distance appear to explain about 37.2% of the variation in ceramic similarity.

The next analysis presented the book creates a series of minimum distance networks from 36Kms all the way out to nearly 400Kms in concentric days travel (36Kms is about one day of travel on foot) and explore the proportion of variance explained by networks constrained on each distance.

```{r, warning=F, message=F, fig.width=8, fig.height=6}
# Create a sequence of distances from 36km to 400kms by concentric days travel on foot
kms <- seq(36000,400000,by=36000)

# Define minimum distance networks for each item in "kms" and the calculate variance explained 
temp.out <- NULL
for(i in 1:length(kms)) {
dmat.temp <- dmat
dmat.temp[dmat>kms[i]] <- 0
dmat.temp[dmat.temp>0] <- 1
# Calculate gam model and output r^2 value
temp <- gam(as.vector(sim[lower.tri(sim)])~as.vector(dmat.temp[lower.tri(dmat.temp)]))
temp.out[i] <- summary(temp)$r.sq}

# Create data frame of output
dat <- as.data.frame(cbind(kms/1000,temp.out))
colnames(dat) <- c('Dist','Cor')

library(ggplot2)

# Plot the results
ggplot(data=dat) +
  geom_line(aes(x=Dist, y=Cor)) +
  geom_point(aes(x=Dist, y=Cor),size=3) +
  xlab("Maximum Distance Network Threshold (Km)") +
  ylab("Proportion of Variance Explained") +
  theme_bw() +
  theme(axis.text.x=element_text(size=rel(1.5)),axis.text.y=element_text(size=rel(1.5)),
        axis.title.x = element_text(size=rel(1.5)),axis.title.y = element_text(size=rel(1.5)))
```


Finally, let's recreate figure 7.8 from the book to display the 36km minimum distance network for the Chaco region ca. AD 1050-1100. This follows the same basic format for plotting minimum distance networks we defined above.

```{r, warning=F, message=F, fig.height=10, fig.width=10}
d36 <- as.matrix(dist(attr[,9:10]))
d36[d36<36001] <- 1
d36[d36>1] <- 0
g36.net <- graph_from_adjacency_matrix(d36, mode="undirected")

locations_sf <- st_as_sf(attr, coords = c("EASTING", "NORTHING"), crs = 26912)
z <- st_transform(locations_sf,crs=4326)
coord1 <- do.call(rbind, st_geometry(z)) %>% 
  tibble::as_tibble() %>% setNames(c("lon","lat"))

xy <- as.data.frame(cbind(attr$SWSN_Site, coord1))
colnames(xy) <- c('site','x','y')

base <- get_stamenmap(bbox=c(-110.75,33.5,-107,38),zoom=8,maptype="terrain-background",color="bw")


# Extract edgelist from network object
edgelist <- get.edgelist(g36.net)

# Create dataframe of beginning and ending points of edges
edges <- as.data.frame(matrix(NA,nrow(edgelist),4))
colnames(edges) <- c("X1","Y1","X2","Y2")
for (i in 1:nrow(edgelist)) {
edges[i,] <- c(xy[which(xy$site==edgelist[i,1]),2],xy[which(xy$site==edgelist[i,1]),3],
               xy[which(xy$site==edgelist[i,2]),2],xy[which(xy$site==edgelist[i,2]),3])
}


m1 <- ggmap(base,darken=0.15) +
  geom_segment(data = edges, aes(x=X1, y=Y1, xend=X2, yend=Y2), col='white', size=0.10, show.legend=F) +
  geom_point(data = xy,aes(x,y),alpha=0.65, size=1, col='red', show.legend=F) +
  theme_void()
m1
```



<!--chapter:end:06-spatial-networks.Rmd-->

---
nocite: '@*'
---

`r if (knitr::is_html_output()) '
# References and R Packages {-}
'`

<!--chapter:end:07-references.Rmd-->

